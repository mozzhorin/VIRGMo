{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4. Karate club network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we fit SBMs to the famous Zachary's Karate Club network[1]. The university's karate club has split up into two groups due to the internal conflict. The available information is the social interactions of 34 participants outside the club. The task is to separate the individuals into groups using this data, and the members of each faction are known. As the number of connections significantly varies among the persons, it was demonstrated that DCSBM better describes this network as the standard SBM, those treat the node's degree as the main feature[2].\n",
    "\n",
    "![](karate_dcsbm.png)\n",
    "#### Zachary's Karate club network divided into groups by DCSBM [2]\n",
    "\n",
    "[1] W. W. Zachary, An information flow model for conflict and fission in small groups, Journal of Anthropological Research 33, 452-473 (1977).\n",
    "\n",
    "[2] Brian Karrer and M. E. J. Newman, Stochastic blockmodels and community structure in networks, Phys. Rev. E 83, 016107 (2011)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f59f6016770>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from vi_sbm import *\n",
    "from graph_models import SBM, DCSBM, EdgesDataset\n",
    "import seaborn as sns\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the data import and aggregate the links into the adjacency matrix $A$. The true group assignments `z_true` are known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "karate = pd.read_csv('../data/karate', sep=' ')\n",
    "N = 34\n",
    "num_classes = 2\n",
    "A = torch.zeros((N,N))\n",
    "for e in np.array(karate):\n",
    "    A[e[0]-1,e[1]-1] = 1\n",
    "    A[e[1]-1,e[0]-1] = 1\n",
    "    \n",
    "z_true = torch.tensor([\n",
    "    [0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,1,0,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "    [1,1,1,1,1,1,1,1,0,0,1,1,1,1,0,0,1,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0]]).t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the network's adjacency matrix $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_class0 = z_true.sum(dim=0)[0].int().item()\n",
    "order = z_true.argmax(dim=1).argsort()\n",
    "A_ordered = A[order,:][:,order]\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "axs[0].imshow(A) \n",
    "axs[1].imshow(A_ordered) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we try the standard SBM. The default prior distribution in `VIRGMo` is quite flat but for this example we may use a more sharp one. We assume that the sizes of both groups are similar, and the nodes are connected densely within the groups as outside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>> Training iteration #1 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 871.85 | Epoch time 0.11\n",
      "Epoch 2 | LR: 0.10 | Total loss: 645.17 | Epoch time 0.07\n",
      "Epoch 3 | LR: 0.10 | Total loss: 604.40 | Epoch time 0.12\n",
      "Epoch 4 | LR: 0.10 | Total loss: 576.89 | Epoch time 0.08\n",
      "Epoch 5 | LR: 0.10 | Total loss: 553.51 | Epoch time 0.08\n",
      "Epoch 6 | LR: 0.10 | Total loss: 533.84 | Epoch time 0.10\n",
      "Epoch 7 | LR: 0.10 | Total loss: 517.78 | Epoch time 0.09\n",
      "Epoch 8 | LR: 0.10 | Total loss: 505.07 | Epoch time 0.09\n",
      "Epoch 9 | LR: 0.10 | Total loss: 494.73 | Epoch time 0.15\n",
      "Epoch 10 | LR: 0.10 | Total loss: 486.17 | Epoch time 0.16\n",
      "Epoch 11 | LR: 0.10 | Total loss: 479.02 | Epoch time 0.19\n",
      "Epoch 12 | LR: 0.10 | Total loss: 473.04 | Epoch time 0.09\n",
      "Epoch 13 | LR: 0.10 | Total loss: 467.91 | Epoch time 0.09\n",
      "Epoch 14 | LR: 0.10 | Total loss: 463.69 | Epoch time 0.17\n",
      "Epoch 15 | LR: 0.10 | Total loss: 459.99 | Epoch time 0.13\n",
      "Epoch 16 | LR: 0.10 | Total loss: 456.78 | Epoch time 0.14\n",
      "Epoch 17 | LR: 0.10 | Total loss: 454.08 | Epoch time 0.15\n",
      "Epoch 18 | LR: 0.10 | Total loss: 451.44 | Epoch time 0.14\n",
      "Epoch 19 | LR: 0.10 | Total loss: 449.32 | Epoch time 0.16\n",
      "Epoch 20 | LR: 0.10 | Total loss: 447.64 | Epoch time 0.18\n",
      "Epoch 21 | LR: 0.05 | Total loss: 445.70 | Epoch time 0.15\n",
      "Epoch 22 | LR: 0.05 | Total loss: 444.32 | Epoch time 0.17\n",
      "Epoch 23 | LR: 0.05 | Total loss: 442.85 | Epoch time 0.11\n",
      "Epoch 24 | LR: 0.05 | Total loss: 441.69 | Epoch time 0.10\n",
      "Epoch 25 | LR: 0.05 | Total loss: 440.78 | Epoch time 0.12\n",
      "Epoch 26 | LR: 0.05 | Total loss: 439.69 | Epoch time 0.10\n",
      "Epoch 27 | LR: 0.05 | Total loss: 438.60 | Epoch time 0.12\n",
      "Epoch 28 | LR: 0.05 | Total loss: 437.66 | Epoch time 0.13\n",
      "Epoch 29 | LR: 0.05 | Total loss: 436.86 | Epoch time 0.09\n",
      "Epoch 30 | LR: 0.05 | Total loss: 436.10 | Epoch time 0.09\n",
      "Epoch 31 | LR: 0.05 | Total loss: 435.42 | Epoch time 0.12\n",
      "Epoch 32 | LR: 0.05 | Total loss: 435.15 | Epoch time 0.09\n",
      "Epoch 33 | LR: 0.05 | Total loss: 434.30 | Epoch time 0.08\n",
      "Epoch 34 | LR: 0.05 | Total loss: 433.75 | Epoch time 0.10\n",
      "Epoch 35 | LR: 0.05 | Total loss: 432.98 | Epoch time 0.11\n",
      "Epoch 36 | LR: 0.05 | Total loss: 432.75 | Epoch time 0.38\n",
      "Epoch 37 | LR: 0.05 | Total loss: 432.12 | Epoch time 0.34\n",
      "Epoch 38 | LR: 0.05 | Total loss: 431.50 | Epoch time 0.15\n",
      "Epoch 39 | LR: 0.05 | Total loss: 431.31 | Epoch time 0.16\n",
      "Epoch 40 | LR: 0.05 | Total loss: 430.95 | Epoch time 0.15\n",
      "Epoch 41 | LR: 0.01 | Total loss: 430.70 | Epoch time 0.17\n",
      "Epoch 42 | LR: 0.01 | Total loss: 430.39 | Epoch time 0.13\n",
      "Epoch 43 | LR: 0.01 | Total loss: 430.08 | Epoch time 0.09\n",
      "Epoch 44 | LR: 0.01 | Total loss: 429.52 | Epoch time 0.11\n",
      "Epoch 45 | LR: 0.01 | Total loss: 429.28 | Epoch time 0.15\n",
      "Epoch 46 | LR: 0.01 | Total loss: 429.13 | Epoch time 0.09\n",
      "Epoch 47 | LR: 0.01 | Total loss: 428.66 | Epoch time 0.09\n",
      "Epoch 48 | LR: 0.01 | Total loss: 428.71 | Epoch time 0.10\n",
      "Epoch 49 | LR: 0.01 | Total loss: 428.55 | Epoch time 0.09\n",
      "Epoch 50 | LR: 0.01 | Total loss: 428.10 | Epoch time 0.08\n",
      "Epoch 51 | LR: 0.01 | Total loss: 427.95 | Epoch time 0.10\n",
      "Epoch 52 | LR: 0.01 | Total loss: 427.59 | Epoch time 0.09\n",
      "Epoch 53 | LR: 0.01 | Total loss: 427.56 | Epoch time 0.08\n",
      "Epoch 54 | LR: 0.01 | Total loss: 427.49 | Epoch time 0.10\n",
      "Epoch 55 | LR: 0.01 | Total loss: 427.23 | Epoch time 0.10\n",
      "Epoch 56 | LR: 0.01 | Total loss: 427.16 | Epoch time 0.10\n",
      "Epoch 57 | LR: 0.01 | Total loss: 426.79 | Epoch time 0.09\n",
      "Epoch 58 | LR: 0.01 | Total loss: 426.65 | Epoch time 0.10\n",
      "Epoch 59 | LR: 0.01 | Total loss: 426.59 | Epoch time 0.09\n",
      "Epoch 60 | LR: 0.01 | Total loss: 426.49 | Epoch time 0.13\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #2 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 755.59 | Epoch time 0.09\n",
      "Epoch 2 | LR: 0.10 | Total loss: 604.02 | Epoch time 0.07\n",
      "Epoch 3 | LR: 0.10 | Total loss: 571.80 | Epoch time 0.11\n",
      "Epoch 4 | LR: 0.10 | Total loss: 549.17 | Epoch time 0.15\n",
      "Epoch 5 | LR: 0.10 | Total loss: 530.89 | Epoch time 0.14\n",
      "Epoch 6 | LR: 0.10 | Total loss: 516.29 | Epoch time 0.08\n",
      "Epoch 7 | LR: 0.10 | Total loss: 503.90 | Epoch time 0.07\n",
      "Epoch 8 | LR: 0.10 | Total loss: 493.76 | Epoch time 0.10\n",
      "Epoch 9 | LR: 0.10 | Total loss: 485.01 | Epoch time 0.09\n",
      "Epoch 10 | LR: 0.10 | Total loss: 478.08 | Epoch time 0.07\n",
      "Epoch 11 | LR: 0.10 | Total loss: 472.68 | Epoch time 0.12\n",
      "Epoch 12 | LR: 0.10 | Total loss: 467.02 | Epoch time 0.07\n",
      "Epoch 13 | LR: 0.10 | Total loss: 463.02 | Epoch time 0.07\n",
      "Epoch 14 | LR: 0.10 | Total loss: 459.38 | Epoch time 0.10\n",
      "Epoch 15 | LR: 0.10 | Total loss: 456.25 | Epoch time 0.10\n",
      "Epoch 16 | LR: 0.10 | Total loss: 453.41 | Epoch time 0.09\n",
      "Epoch 17 | LR: 0.10 | Total loss: 451.20 | Epoch time 0.11\n",
      "Epoch 18 | LR: 0.10 | Total loss: 448.90 | Epoch time 0.09\n",
      "Epoch 19 | LR: 0.10 | Total loss: 446.95 | Epoch time 0.08\n",
      "Epoch 20 | LR: 0.10 | Total loss: 445.22 | Epoch time 0.08\n",
      "Epoch 21 | LR: 0.05 | Total loss: 443.79 | Epoch time 0.09\n",
      "Epoch 22 | LR: 0.05 | Total loss: 442.46 | Epoch time 0.09\n",
      "Epoch 23 | LR: 0.05 | Total loss: 441.39 | Epoch time 0.11\n",
      "Epoch 24 | LR: 0.05 | Total loss: 439.97 | Epoch time 0.09\n",
      "Epoch 25 | LR: 0.05 | Total loss: 439.38 | Epoch time 0.08\n",
      "Epoch 26 | LR: 0.05 | Total loss: 438.39 | Epoch time 0.09\n",
      "Epoch 27 | LR: 0.05 | Total loss: 437.36 | Epoch time 0.13\n",
      "Epoch 28 | LR: 0.05 | Total loss: 436.68 | Epoch time 0.10\n",
      "Epoch 29 | LR: 0.05 | Total loss: 435.91 | Epoch time 0.09\n",
      "Epoch 30 | LR: 0.05 | Total loss: 435.38 | Epoch time 0.08\n",
      "Epoch 31 | LR: 0.05 | Total loss: 434.95 | Epoch time 0.10\n",
      "Epoch 32 | LR: 0.05 | Total loss: 433.93 | Epoch time 0.07\n",
      "Epoch 33 | LR: 0.05 | Total loss: 433.73 | Epoch time 0.08\n",
      "Epoch 34 | LR: 0.05 | Total loss: 433.18 | Epoch time 0.10\n",
      "Epoch 35 | LR: 0.05 | Total loss: 432.50 | Epoch time 0.08\n",
      "Epoch 36 | LR: 0.05 | Total loss: 432.23 | Epoch time 0.09\n",
      "Epoch 37 | LR: 0.05 | Total loss: 431.58 | Epoch time 0.11\n",
      "Epoch 38 | LR: 0.05 | Total loss: 431.61 | Epoch time 0.09\n",
      "Epoch 39 | LR: 0.05 | Total loss: 430.97 | Epoch time 0.09\n",
      "Epoch 40 | LR: 0.05 | Total loss: 430.79 | Epoch time 0.11\n",
      "Epoch 41 | LR: 0.01 | Total loss: 430.51 | Epoch time 0.08\n",
      "Epoch 42 | LR: 0.01 | Total loss: 430.08 | Epoch time 0.07\n",
      "Epoch 43 | LR: 0.01 | Total loss: 429.73 | Epoch time 0.10\n",
      "Epoch 44 | LR: 0.01 | Total loss: 429.37 | Epoch time 0.10\n",
      "Epoch 45 | LR: 0.01 | Total loss: 429.17 | Epoch time 0.08\n",
      "Epoch 46 | LR: 0.01 | Total loss: 428.95 | Epoch time 0.10\n",
      "Epoch 47 | LR: 0.01 | Total loss: 428.92 | Epoch time 0.08\n",
      "Epoch 48 | LR: 0.01 | Total loss: 428.42 | Epoch time 0.08\n",
      "Epoch 49 | LR: 0.01 | Total loss: 428.20 | Epoch time 0.09\n",
      "Epoch 50 | LR: 0.01 | Total loss: 428.29 | Epoch time 0.08\n",
      "Epoch 51 | LR: 0.01 | Total loss: 427.73 | Epoch time 0.09\n",
      "Epoch 52 | LR: 0.01 | Total loss: 427.46 | Epoch time 0.11\n",
      "Epoch 53 | LR: 0.01 | Total loss: 427.25 | Epoch time 0.09\n",
      "Epoch 54 | LR: 0.01 | Total loss: 427.27 | Epoch time 0.08\n",
      "Epoch 55 | LR: 0.01 | Total loss: 427.25 | Epoch time 0.09\n",
      "Epoch 56 | LR: 0.01 | Total loss: 427.00 | Epoch time 0.09\n",
      "Epoch 57 | LR: 0.01 | Total loss: 426.62 | Epoch time 0.08\n",
      "Epoch 58 | LR: 0.01 | Total loss: 426.26 | Epoch time 0.10\n",
      "Epoch 59 | LR: 0.01 | Total loss: 426.35 | Epoch time 0.07\n",
      "Epoch 60 | LR: 0.01 | Total loss: 426.36 | Epoch time 0.08\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #3 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 812.87 | Epoch time 0.09\n",
      "Epoch 2 | LR: 0.10 | Total loss: 632.13 | Epoch time 0.09\n",
      "Epoch 3 | LR: 0.10 | Total loss: 602.74 | Epoch time 0.08\n",
      "Epoch 4 | LR: 0.10 | Total loss: 584.95 | Epoch time 0.10\n",
      "Epoch 5 | LR: 0.10 | Total loss: 567.94 | Epoch time 0.08\n",
      "Epoch 6 | LR: 0.10 | Total loss: 551.17 | Epoch time 0.07\n",
      "Epoch 7 | LR: 0.10 | Total loss: 535.51 | Epoch time 0.10\n",
      "Epoch 8 | LR: 0.10 | Total loss: 521.23 | Epoch time 0.09\n",
      "Epoch 9 | LR: 0.10 | Total loss: 508.91 | Epoch time 0.08\n",
      "Epoch 10 | LR: 0.10 | Total loss: 498.26 | Epoch time 0.10\n",
      "Epoch 11 | LR: 0.10 | Total loss: 489.74 | Epoch time 0.09\n",
      "Epoch 12 | LR: 0.10 | Total loss: 482.40 | Epoch time 0.08\n",
      "Epoch 13 | LR: 0.10 | Total loss: 475.92 | Epoch time 0.11\n",
      "Epoch 14 | LR: 0.10 | Total loss: 470.72 | Epoch time 0.09\n",
      "Epoch 15 | LR: 0.10 | Total loss: 465.74 | Epoch time 0.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | LR: 0.10 | Total loss: 461.52 | Epoch time 0.10\n",
      "Epoch 17 | LR: 0.10 | Total loss: 458.50 | Epoch time 0.08\n",
      "Epoch 18 | LR: 0.10 | Total loss: 454.93 | Epoch time 0.08\n",
      "Epoch 19 | LR: 0.10 | Total loss: 452.17 | Epoch time 0.09\n",
      "Epoch 20 | LR: 0.10 | Total loss: 449.79 | Epoch time 0.08\n",
      "Epoch 21 | LR: 0.05 | Total loss: 447.27 | Epoch time 0.07\n",
      "Epoch 22 | LR: 0.05 | Total loss: 445.67 | Epoch time 0.09\n",
      "Epoch 23 | LR: 0.05 | Total loss: 443.93 | Epoch time 0.08\n",
      "Epoch 24 | LR: 0.05 | Total loss: 442.26 | Epoch time 0.08\n",
      "Epoch 25 | LR: 0.05 | Total loss: 440.87 | Epoch time 0.09\n",
      "Epoch 26 | LR: 0.05 | Total loss: 439.63 | Epoch time 0.09\n",
      "Epoch 27 | LR: 0.05 | Total loss: 438.65 | Epoch time 0.07\n",
      "Epoch 28 | LR: 0.05 | Total loss: 437.16 | Epoch time 0.11\n",
      "Epoch 29 | LR: 0.05 | Total loss: 436.61 | Epoch time 0.07\n",
      "Epoch 30 | LR: 0.05 | Total loss: 435.40 | Epoch time 0.08\n",
      "Epoch 31 | LR: 0.05 | Total loss: 434.87 | Epoch time 0.09\n",
      "Epoch 32 | LR: 0.05 | Total loss: 433.76 | Epoch time 0.09\n",
      "Epoch 33 | LR: 0.05 | Total loss: 433.22 | Epoch time 0.08\n",
      "Epoch 34 | LR: 0.05 | Total loss: 433.13 | Epoch time 0.09\n",
      "Epoch 35 | LR: 0.05 | Total loss: 431.96 | Epoch time 0.08\n",
      "Epoch 36 | LR: 0.05 | Total loss: 431.82 | Epoch time 0.08\n",
      "Epoch 37 | LR: 0.05 | Total loss: 431.17 | Epoch time 0.10\n",
      "Epoch 38 | LR: 0.05 | Total loss: 430.80 | Epoch time 0.09\n",
      "Epoch 39 | LR: 0.05 | Total loss: 430.53 | Epoch time 0.08\n",
      "Epoch 40 | LR: 0.05 | Total loss: 430.02 | Epoch time 0.09\n",
      "Epoch 41 | LR: 0.01 | Total loss: 429.61 | Epoch time 0.08\n",
      "Epoch 42 | LR: 0.01 | Total loss: 429.35 | Epoch time 0.08\n",
      "Epoch 43 | LR: 0.01 | Total loss: 429.13 | Epoch time 0.10\n",
      "Epoch 44 | LR: 0.01 | Total loss: 428.75 | Epoch time 0.11\n",
      "Epoch 45 | LR: 0.01 | Total loss: 428.40 | Epoch time 0.08\n",
      "Epoch 46 | LR: 0.01 | Total loss: 428.25 | Epoch time 0.08\n",
      "Epoch 47 | LR: 0.01 | Total loss: 427.92 | Epoch time 0.12\n",
      "Epoch 48 | LR: 0.01 | Total loss: 427.52 | Epoch time 0.13\n",
      "Epoch 49 | LR: 0.01 | Total loss: 427.87 | Epoch time 0.15\n",
      "Epoch 50 | LR: 0.01 | Total loss: 427.34 | Epoch time 0.14\n",
      "Epoch 51 | LR: 0.01 | Total loss: 427.31 | Epoch time 0.15\n",
      "Epoch 52 | LR: 0.01 | Total loss: 426.76 | Epoch time 0.16\n",
      "Epoch 53 | LR: 0.01 | Total loss: 426.68 | Epoch time 0.16\n",
      "Epoch 54 | LR: 0.01 | Total loss: 426.36 | Epoch time 0.14\n",
      "Epoch 55 | LR: 0.01 | Total loss: 426.31 | Epoch time 0.16\n",
      "Epoch 56 | LR: 0.01 | Total loss: 426.48 | Epoch time 0.19\n",
      "Epoch 57 | LR: 0.01 | Total loss: 426.32 | Epoch time 0.15\n",
      "Epoch 58 | LR: 0.01 | Total loss: 425.86 | Epoch time 0.19\n",
      "Epoch 59 | LR: 0.01 | Total loss: 425.69 | Epoch time 0.17\n",
      "Epoch 60 | LR: 0.01 | Total loss: 425.73 | Epoch time 0.12\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #4 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 730.43 | Epoch time 0.11\n",
      "Epoch 2 | LR: 0.10 | Total loss: 604.30 | Epoch time 0.13\n",
      "Epoch 3 | LR: 0.10 | Total loss: 575.21 | Epoch time 0.11\n",
      "Epoch 4 | LR: 0.10 | Total loss: 555.50 | Epoch time 0.11\n",
      "Epoch 5 | LR: 0.10 | Total loss: 538.39 | Epoch time 0.12\n",
      "Epoch 6 | LR: 0.10 | Total loss: 523.59 | Epoch time 0.11\n",
      "Epoch 7 | LR: 0.10 | Total loss: 510.92 | Epoch time 0.12\n",
      "Epoch 8 | LR: 0.10 | Total loss: 499.64 | Epoch time 0.14\n",
      "Epoch 9 | LR: 0.10 | Total loss: 490.51 | Epoch time 0.11\n",
      "Epoch 10 | LR: 0.10 | Total loss: 482.57 | Epoch time 0.12\n",
      "Epoch 11 | LR: 0.10 | Total loss: 475.81 | Epoch time 0.11\n",
      "Epoch 12 | LR: 0.10 | Total loss: 470.25 | Epoch time 0.13\n",
      "Epoch 13 | LR: 0.10 | Total loss: 465.38 | Epoch time 0.11\n",
      "Epoch 14 | LR: 0.10 | Total loss: 461.38 | Epoch time 0.13\n",
      "Epoch 15 | LR: 0.10 | Total loss: 457.84 | Epoch time 0.12\n",
      "Epoch 16 | LR: 0.10 | Total loss: 454.36 | Epoch time 0.12\n",
      "Epoch 17 | LR: 0.10 | Total loss: 451.54 | Epoch time 0.11\n",
      "Epoch 18 | LR: 0.10 | Total loss: 449.14 | Epoch time 0.12\n",
      "Epoch 19 | LR: 0.10 | Total loss: 446.87 | Epoch time 0.11\n",
      "Epoch 20 | LR: 0.10 | Total loss: 445.09 | Epoch time 0.12\n",
      "Epoch 21 | LR: 0.05 | Total loss: 443.35 | Epoch time 0.11\n",
      "Epoch 22 | LR: 0.05 | Total loss: 441.84 | Epoch time 0.12\n",
      "Epoch 23 | LR: 0.05 | Total loss: 440.67 | Epoch time 0.12\n",
      "Epoch 24 | LR: 0.05 | Total loss: 439.26 | Epoch time 0.12\n",
      "Epoch 25 | LR: 0.05 | Total loss: 437.92 | Epoch time 0.11\n",
      "Epoch 26 | LR: 0.05 | Total loss: 437.10 | Epoch time 0.12\n",
      "Epoch 27 | LR: 0.05 | Total loss: 436.31 | Epoch time 0.12\n",
      "Epoch 28 | LR: 0.05 | Total loss: 435.26 | Epoch time 0.13\n",
      "Epoch 29 | LR: 0.05 | Total loss: 434.62 | Epoch time 0.11\n",
      "Epoch 30 | LR: 0.05 | Total loss: 433.94 | Epoch time 0.14\n",
      "Epoch 31 | LR: 0.05 | Total loss: 433.34 | Epoch time 0.10\n",
      "Epoch 32 | LR: 0.05 | Total loss: 432.59 | Epoch time 0.12\n",
      "Epoch 33 | LR: 0.05 | Total loss: 431.93 | Epoch time 0.11\n",
      "Epoch 34 | LR: 0.05 | Total loss: 431.62 | Epoch time 0.13\n",
      "Epoch 35 | LR: 0.05 | Total loss: 431.34 | Epoch time 0.11\n",
      "Epoch 36 | LR: 0.05 | Total loss: 430.87 | Epoch time 0.12\n",
      "Epoch 37 | LR: 0.05 | Total loss: 430.27 | Epoch time 0.12\n",
      "Epoch 38 | LR: 0.05 | Total loss: 430.13 | Epoch time 0.11\n",
      "Epoch 39 | LR: 0.05 | Total loss: 429.49 | Epoch time 0.12\n",
      "Epoch 40 | LR: 0.05 | Total loss: 429.31 | Epoch time 0.13\n",
      "Epoch 41 | LR: 0.01 | Total loss: 428.96 | Epoch time 0.10\n",
      "Epoch 42 | LR: 0.01 | Total loss: 428.93 | Epoch time 0.13\n",
      "Epoch 43 | LR: 0.01 | Total loss: 428.73 | Epoch time 0.12\n",
      "Epoch 44 | LR: 0.01 | Total loss: 428.04 | Epoch time 0.14\n",
      "Epoch 45 | LR: 0.01 | Total loss: 428.17 | Epoch time 0.20\n",
      "Epoch 46 | LR: 0.01 | Total loss: 427.85 | Epoch time 0.20\n",
      "Epoch 47 | LR: 0.01 | Total loss: 427.65 | Epoch time 0.18\n",
      "Epoch 48 | LR: 0.01 | Total loss: 427.23 | Epoch time 0.16\n",
      "Epoch 49 | LR: 0.01 | Total loss: 427.01 | Epoch time 0.18\n",
      "Epoch 50 | LR: 0.01 | Total loss: 426.98 | Epoch time 0.16\n",
      "Epoch 51 | LR: 0.01 | Total loss: 426.94 | Epoch time 0.12\n",
      "Epoch 52 | LR: 0.01 | Total loss: 426.60 | Epoch time 0.11\n",
      "Epoch 53 | LR: 0.01 | Total loss: 426.75 | Epoch time 0.11\n",
      "Epoch 54 | LR: 0.01 | Total loss: 426.50 | Epoch time 0.12\n",
      "Epoch 55 | LR: 0.01 | Total loss: 426.29 | Epoch time 0.11\n",
      "Epoch 56 | LR: 0.01 | Total loss: 425.98 | Epoch time 0.11\n",
      "Epoch 57 | LR: 0.01 | Total loss: 425.70 | Epoch time 0.13\n",
      "Epoch 58 | LR: 0.01 | Total loss: 425.71 | Epoch time 0.12\n",
      "Epoch 59 | LR: 0.01 | Total loss: 425.50 | Epoch time 0.11\n",
      "Epoch 60 | LR: 0.01 | Total loss: 425.45 | Epoch time 0.11\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #5 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 719.81 | Epoch time 0.10\n",
      "Epoch 2 | LR: 0.10 | Total loss: 607.52 | Epoch time 0.13\n",
      "Epoch 3 | LR: 0.10 | Total loss: 582.06 | Epoch time 0.12\n",
      "Epoch 4 | LR: 0.10 | Total loss: 566.20 | Epoch time 0.11\n",
      "Epoch 5 | LR: 0.10 | Total loss: 554.26 | Epoch time 0.12\n",
      "Epoch 6 | LR: 0.10 | Total loss: 544.83 | Epoch time 0.11\n",
      "Epoch 7 | LR: 0.10 | Total loss: 537.17 | Epoch time 0.12\n",
      "Epoch 8 | LR: 0.10 | Total loss: 530.89 | Epoch time 0.12\n",
      "Epoch 9 | LR: 0.10 | Total loss: 525.53 | Epoch time 0.12\n",
      "Epoch 10 | LR: 0.10 | Total loss: 520.50 | Epoch time 0.13\n",
      "Epoch 11 | LR: 0.10 | Total loss: 516.52 | Epoch time 0.12\n",
      "Epoch 12 | LR: 0.10 | Total loss: 513.44 | Epoch time 0.11\n",
      "Epoch 13 | LR: 0.10 | Total loss: 510.45 | Epoch time 0.11\n",
      "Epoch 14 | LR: 0.10 | Total loss: 507.70 | Epoch time 0.11\n",
      "Epoch 15 | LR: 0.10 | Total loss: 505.61 | Epoch time 0.10\n",
      "Epoch 16 | LR: 0.10 | Total loss: 504.08 | Epoch time 0.13\n",
      "Epoch 17 | LR: 0.10 | Total loss: 502.52 | Epoch time 0.12\n",
      "Epoch 18 | LR: 0.10 | Total loss: 501.23 | Epoch time 0.11\n",
      "Epoch 19 | LR: 0.10 | Total loss: 500.62 | Epoch time 0.11\n",
      "Epoch 20 | LR: 0.10 | Total loss: 499.35 | Epoch time 0.10\n",
      "Epoch 21 | LR: 0.05 | Total loss: 498.63 | Epoch time 0.10\n",
      "Epoch 22 | LR: 0.05 | Total loss: 497.84 | Epoch time 0.13\n",
      "Epoch 23 | LR: 0.05 | Total loss: 496.92 | Epoch time 0.10\n",
      "Epoch 24 | LR: 0.05 | Total loss: 496.62 | Epoch time 0.10\n",
      "Epoch 25 | LR: 0.05 | Total loss: 496.17 | Epoch time 0.13\n",
      "Epoch 26 | LR: 0.05 | Total loss: 495.62 | Epoch time 0.10\n",
      "Epoch 27 | LR: 0.05 | Total loss: 494.88 | Epoch time 0.11\n",
      "Epoch 28 | LR: 0.05 | Total loss: 494.68 | Epoch time 0.12\n",
      "Epoch 29 | LR: 0.05 | Total loss: 494.01 | Epoch time 0.11\n",
      "Epoch 30 | LR: 0.05 | Total loss: 493.59 | Epoch time 0.11\n",
      "Epoch 31 | LR: 0.05 | Total loss: 493.18 | Epoch time 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | LR: 0.05 | Total loss: 492.89 | Epoch time 0.11\n",
      "Epoch 33 | LR: 0.05 | Total loss: 492.79 | Epoch time 0.11\n",
      "Epoch 34 | LR: 0.05 | Total loss: 492.63 | Epoch time 0.12\n",
      "Epoch 35 | LR: 0.05 | Total loss: 492.27 | Epoch time 0.10\n",
      "Epoch 36 | LR: 0.05 | Total loss: 491.83 | Epoch time 0.11\n",
      "Epoch 37 | LR: 0.05 | Total loss: 491.45 | Epoch time 0.11\n",
      "Epoch 38 | LR: 0.05 | Total loss: 491.44 | Epoch time 0.10\n",
      "Epoch 39 | LR: 0.05 | Total loss: 491.00 | Epoch time 0.11\n",
      "Epoch 40 | LR: 0.05 | Total loss: 490.30 | Epoch time 0.10\n",
      "Epoch 41 | LR: 0.01 | Total loss: 490.72 | Epoch time 0.11\n",
      "Epoch 42 | LR: 0.01 | Total loss: 490.79 | Epoch time 0.10\n",
      "Epoch 43 | LR: 0.01 | Total loss: 490.75 | Epoch time 0.11\n",
      "Epoch 44 | LR: 0.01 | Total loss: 490.25 | Epoch time 0.13\n",
      "Epoch 45 | LR: 0.01 | Total loss: 490.07 | Epoch time 0.11\n",
      "Epoch 46 | LR: 0.01 | Total loss: 489.99 | Epoch time 0.11\n",
      "Epoch 47 | LR: 0.01 | Total loss: 489.96 | Epoch time 0.11\n",
      "Epoch 48 | LR: 0.01 | Total loss: 489.43 | Epoch time 0.10\n",
      "Epoch 49 | LR: 0.01 | Total loss: 489.20 | Epoch time 0.11\n",
      "Epoch 50 | LR: 0.01 | Total loss: 489.19 | Epoch time 0.11\n",
      "Epoch 51 | LR: 0.01 | Total loss: 489.21 | Epoch time 0.11\n",
      "Epoch 52 | LR: 0.01 | Total loss: 488.95 | Epoch time 0.10\n",
      "Epoch 53 | LR: 0.01 | Total loss: 489.22 | Epoch time 0.12\n",
      "Epoch 54 | LR: 0.01 | Total loss: 488.59 | Epoch time 0.18\n",
      "Epoch 55 | LR: 0.01 | Total loss: 488.81 | Epoch time 0.17\n",
      "Epoch 56 | LR: 0.01 | Total loss: 488.70 | Epoch time 0.14\n",
      "Epoch 57 | LR: 0.01 | Total loss: 488.51 | Epoch time 0.14\n",
      "Epoch 58 | LR: 0.01 | Total loss: 488.45 | Epoch time 0.18\n",
      "Epoch 59 | LR: 0.01 | Total loss: 488.27 | Epoch time 0.15\n",
      "Epoch 60 | LR: 0.01 | Total loss: 488.18 | Epoch time 0.19\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #6 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 785.93 | Epoch time 0.17\n",
      "Epoch 2 | LR: 0.10 | Total loss: 624.67 | Epoch time 0.19\n",
      "Epoch 3 | LR: 0.10 | Total loss: 595.18 | Epoch time 0.16\n",
      "Epoch 4 | LR: 0.10 | Total loss: 575.48 | Epoch time 0.20\n",
      "Epoch 5 | LR: 0.10 | Total loss: 557.11 | Epoch time 0.19\n",
      "Epoch 6 | LR: 0.10 | Total loss: 539.11 | Epoch time 0.12\n",
      "Epoch 7 | LR: 0.10 | Total loss: 522.44 | Epoch time 0.11\n",
      "Epoch 8 | LR: 0.10 | Total loss: 508.15 | Epoch time 0.21\n",
      "Epoch 9 | LR: 0.10 | Total loss: 496.48 | Epoch time 0.16\n",
      "Epoch 10 | LR: 0.10 | Total loss: 486.61 | Epoch time 0.16\n",
      "Epoch 11 | LR: 0.10 | Total loss: 478.97 | Epoch time 0.10\n",
      "Epoch 12 | LR: 0.10 | Total loss: 472.06 | Epoch time 0.11\n",
      "Epoch 13 | LR: 0.10 | Total loss: 466.64 | Epoch time 0.12\n",
      "Epoch 14 | LR: 0.10 | Total loss: 462.40 | Epoch time 0.13\n",
      "Epoch 15 | LR: 0.10 | Total loss: 458.61 | Epoch time 0.16\n",
      "Epoch 16 | LR: 0.10 | Total loss: 455.47 | Epoch time 0.19\n",
      "Epoch 17 | LR: 0.10 | Total loss: 452.28 | Epoch time 0.17\n",
      "Epoch 18 | LR: 0.10 | Total loss: 449.82 | Epoch time 0.13\n",
      "Epoch 19 | LR: 0.10 | Total loss: 447.90 | Epoch time 0.15\n",
      "Epoch 20 | LR: 0.10 | Total loss: 446.03 | Epoch time 0.21\n",
      "Epoch 21 | LR: 0.05 | Total loss: 444.03 | Epoch time 0.25\n",
      "Epoch 22 | LR: 0.05 | Total loss: 442.76 | Epoch time 0.24\n",
      "Epoch 23 | LR: 0.05 | Total loss: 441.44 | Epoch time 0.20\n",
      "Epoch 24 | LR: 0.05 | Total loss: 440.47 | Epoch time 0.21\n",
      "Epoch 25 | LR: 0.05 | Total loss: 439.29 | Epoch time 0.18\n",
      "Epoch 26 | LR: 0.05 | Total loss: 438.11 | Epoch time 0.20\n",
      "Epoch 27 | LR: 0.05 | Total loss: 437.30 | Epoch time 0.17\n",
      "Epoch 28 | LR: 0.05 | Total loss: 436.68 | Epoch time 0.19\n",
      "Epoch 29 | LR: 0.05 | Total loss: 435.71 | Epoch time 0.18\n",
      "Epoch 30 | LR: 0.05 | Total loss: 435.07 | Epoch time 0.19\n",
      "Epoch 31 | LR: 0.05 | Total loss: 434.72 | Epoch time 0.17\n",
      "Epoch 32 | LR: 0.05 | Total loss: 433.89 | Epoch time 0.13\n",
      "Epoch 33 | LR: 0.05 | Total loss: 433.30 | Epoch time 0.10\n",
      "Epoch 34 | LR: 0.05 | Total loss: 432.90 | Epoch time 0.17\n",
      "Epoch 35 | LR: 0.05 | Total loss: 432.48 | Epoch time 0.19\n",
      "Epoch 36 | LR: 0.05 | Total loss: 431.88 | Epoch time 0.21\n",
      "Epoch 37 | LR: 0.05 | Total loss: 431.69 | Epoch time 0.18\n",
      "Epoch 38 | LR: 0.05 | Total loss: 430.89 | Epoch time 0.19\n",
      "Epoch 39 | LR: 0.05 | Total loss: 430.55 | Epoch time 0.18\n",
      "Epoch 40 | LR: 0.05 | Total loss: 430.20 | Epoch time 0.20\n",
      "Epoch 41 | LR: 0.01 | Total loss: 430.06 | Epoch time 0.18\n",
      "Epoch 42 | LR: 0.01 | Total loss: 429.58 | Epoch time 0.19\n",
      "Epoch 43 | LR: 0.01 | Total loss: 429.41 | Epoch time 0.18\n",
      "Epoch 44 | LR: 0.01 | Total loss: 429.13 | Epoch time 0.16\n",
      "Epoch 45 | LR: 0.01 | Total loss: 429.19 | Epoch time 0.10\n",
      "Epoch 46 | LR: 0.01 | Total loss: 428.82 | Epoch time 0.11\n",
      "Epoch 47 | LR: 0.01 | Total loss: 428.37 | Epoch time 0.18\n",
      "Epoch 48 | LR: 0.01 | Total loss: 428.26 | Epoch time 0.18\n",
      "Epoch 49 | LR: 0.01 | Total loss: 427.87 | Epoch time 0.16\n",
      "Epoch 50 | LR: 0.01 | Total loss: 427.81 | Epoch time 0.21\n",
      "Epoch 51 | LR: 0.01 | Total loss: 427.69 | Epoch time 0.17\n",
      "Epoch 52 | LR: 0.01 | Total loss: 427.52 | Epoch time 0.20\n",
      "Epoch 53 | LR: 0.01 | Total loss: 427.20 | Epoch time 0.16\n",
      "Epoch 54 | LR: 0.01 | Total loss: 427.04 | Epoch time 0.18\n",
      "Epoch 55 | LR: 0.01 | Total loss: 426.65 | Epoch time 0.18\n",
      "Epoch 56 | LR: 0.01 | Total loss: 426.67 | Epoch time 0.20\n",
      "Epoch 57 | LR: 0.01 | Total loss: 426.61 | Epoch time 0.17\n",
      "Epoch 58 | LR: 0.01 | Total loss: 426.24 | Epoch time 0.13\n",
      "Epoch 59 | LR: 0.01 | Total loss: 426.13 | Epoch time 0.16\n",
      "Epoch 60 | LR: 0.01 | Total loss: 426.15 | Epoch time 0.18\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #7 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 763.71 | Epoch time 0.17\n",
      "Epoch 2 | LR: 0.10 | Total loss: 634.95 | Epoch time 0.20\n",
      "Epoch 3 | LR: 0.10 | Total loss: 600.74 | Epoch time 0.17\n",
      "Epoch 4 | LR: 0.10 | Total loss: 575.02 | Epoch time 0.19\n",
      "Epoch 5 | LR: 0.10 | Total loss: 554.03 | Epoch time 0.19\n",
      "Epoch 6 | LR: 0.10 | Total loss: 536.60 | Epoch time 0.20\n",
      "Epoch 7 | LR: 0.10 | Total loss: 522.20 | Epoch time 0.13\n",
      "Epoch 8 | LR: 0.10 | Total loss: 510.26 | Epoch time 0.13\n",
      "Epoch 9 | LR: 0.10 | Total loss: 499.85 | Epoch time 0.17\n",
      "Epoch 10 | LR: 0.10 | Total loss: 491.33 | Epoch time 0.18\n",
      "Epoch 11 | LR: 0.10 | Total loss: 483.78 | Epoch time 0.11\n",
      "Epoch 12 | LR: 0.10 | Total loss: 477.82 | Epoch time 0.11\n",
      "Epoch 13 | LR: 0.10 | Total loss: 472.17 | Epoch time 0.19\n",
      "Epoch 14 | LR: 0.10 | Total loss: 467.14 | Epoch time 0.18\n",
      "Epoch 15 | LR: 0.10 | Total loss: 463.20 | Epoch time 0.14\n",
      "Epoch 16 | LR: 0.10 | Total loss: 459.68 | Epoch time 0.18\n",
      "Epoch 17 | LR: 0.10 | Total loss: 456.49 | Epoch time 0.18\n",
      "Epoch 18 | LR: 0.10 | Total loss: 453.58 | Epoch time 0.19\n",
      "Epoch 19 | LR: 0.10 | Total loss: 451.22 | Epoch time 0.18\n",
      "Epoch 20 | LR: 0.10 | Total loss: 448.94 | Epoch time 0.19\n",
      "Epoch 21 | LR: 0.05 | Total loss: 446.69 | Epoch time 0.16\n",
      "Epoch 22 | LR: 0.05 | Total loss: 445.02 | Epoch time 0.16\n",
      "Epoch 23 | LR: 0.05 | Total loss: 443.61 | Epoch time 0.17\n",
      "Epoch 24 | LR: 0.05 | Total loss: 442.00 | Epoch time 0.14\n",
      "Epoch 25 | LR: 0.05 | Total loss: 440.68 | Epoch time 0.11\n",
      "Epoch 26 | LR: 0.05 | Total loss: 439.47 | Epoch time 0.17\n",
      "Epoch 27 | LR: 0.05 | Total loss: 438.52 | Epoch time 0.18\n",
      "Epoch 28 | LR: 0.05 | Total loss: 437.41 | Epoch time 0.20\n",
      "Epoch 29 | LR: 0.05 | Total loss: 436.34 | Epoch time 0.16\n",
      "Epoch 30 | LR: 0.05 | Total loss: 435.64 | Epoch time 0.15\n",
      "Epoch 31 | LR: 0.05 | Total loss: 434.56 | Epoch time 0.16\n",
      "Epoch 32 | LR: 0.05 | Total loss: 434.37 | Epoch time 0.14\n",
      "Epoch 33 | LR: 0.05 | Total loss: 433.28 | Epoch time 0.10\n",
      "Epoch 34 | LR: 0.05 | Total loss: 432.82 | Epoch time 0.09\n",
      "Epoch 35 | LR: 0.05 | Total loss: 432.45 | Epoch time 0.12\n",
      "Epoch 36 | LR: 0.05 | Total loss: 431.58 | Epoch time 0.10\n",
      "Epoch 37 | LR: 0.05 | Total loss: 431.53 | Epoch time 0.11\n",
      "Epoch 38 | LR: 0.05 | Total loss: 431.11 | Epoch time 0.13\n",
      "Epoch 39 | LR: 0.05 | Total loss: 430.31 | Epoch time 0.12\n",
      "Epoch 40 | LR: 0.05 | Total loss: 430.13 | Epoch time 0.11\n",
      "Epoch 41 | LR: 0.01 | Total loss: 429.78 | Epoch time 0.10\n",
      "Epoch 42 | LR: 0.01 | Total loss: 429.65 | Epoch time 0.11\n",
      "Epoch 43 | LR: 0.01 | Total loss: 429.09 | Epoch time 0.10\n",
      "Epoch 44 | LR: 0.01 | Total loss: 428.71 | Epoch time 0.10\n",
      "Epoch 45 | LR: 0.01 | Total loss: 428.75 | Epoch time 0.10\n",
      "Epoch 46 | LR: 0.01 | Total loss: 428.52 | Epoch time 0.12\n",
      "Epoch 47 | LR: 0.01 | Total loss: 428.00 | Epoch time 0.10\n",
      "Epoch 48 | LR: 0.01 | Total loss: 427.90 | Epoch time 0.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | LR: 0.01 | Total loss: 427.46 | Epoch time 0.10\n",
      "Epoch 50 | LR: 0.01 | Total loss: 427.65 | Epoch time 0.12\n",
      "Epoch 51 | LR: 0.01 | Total loss: 427.37 | Epoch time 0.11\n",
      "Epoch 52 | LR: 0.01 | Total loss: 427.18 | Epoch time 0.11\n",
      "Epoch 53 | LR: 0.01 | Total loss: 426.93 | Epoch time 0.11\n",
      "Epoch 54 | LR: 0.01 | Total loss: 426.50 | Epoch time 0.10\n",
      "Epoch 55 | LR: 0.01 | Total loss: 426.29 | Epoch time 0.11\n",
      "Epoch 56 | LR: 0.01 | Total loss: 426.32 | Epoch time 0.11\n",
      "Epoch 57 | LR: 0.01 | Total loss: 426.39 | Epoch time 0.12\n",
      "Epoch 58 | LR: 0.01 | Total loss: 426.17 | Epoch time 0.11\n",
      "Epoch 59 | LR: 0.01 | Total loss: 425.71 | Epoch time 0.10\n",
      "Epoch 60 | LR: 0.01 | Total loss: 425.63 | Epoch time 0.16\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #8 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 715.52 | Epoch time 0.12\n",
      "Epoch 2 | LR: 0.10 | Total loss: 600.83 | Epoch time 0.11\n",
      "Epoch 3 | LR: 0.10 | Total loss: 571.10 | Epoch time 0.17\n",
      "Epoch 4 | LR: 0.10 | Total loss: 549.37 | Epoch time 0.18\n",
      "Epoch 5 | LR: 0.10 | Total loss: 530.90 | Epoch time 0.19\n",
      "Epoch 6 | LR: 0.10 | Total loss: 516.12 | Epoch time 0.15\n",
      "Epoch 7 | LR: 0.10 | Total loss: 503.62 | Epoch time 0.19\n",
      "Epoch 8 | LR: 0.10 | Total loss: 493.03 | Epoch time 0.16\n",
      "Epoch 9 | LR: 0.10 | Total loss: 484.44 | Epoch time 0.11\n",
      "Epoch 10 | LR: 0.10 | Total loss: 477.18 | Epoch time 0.11\n",
      "Epoch 11 | LR: 0.10 | Total loss: 470.73 | Epoch time 0.11\n",
      "Epoch 12 | LR: 0.10 | Total loss: 465.67 | Epoch time 0.11\n",
      "Epoch 13 | LR: 0.10 | Total loss: 461.04 | Epoch time 0.10\n",
      "Epoch 14 | LR: 0.10 | Total loss: 457.27 | Epoch time 0.11\n",
      "Epoch 15 | LR: 0.10 | Total loss: 454.02 | Epoch time 0.12\n",
      "Epoch 16 | LR: 0.10 | Total loss: 451.19 | Epoch time 0.11\n",
      "Epoch 17 | LR: 0.10 | Total loss: 448.70 | Epoch time 0.11\n",
      "Epoch 18 | LR: 0.10 | Total loss: 446.76 | Epoch time 0.11\n",
      "Epoch 19 | LR: 0.10 | Total loss: 444.85 | Epoch time 0.12\n",
      "Epoch 20 | LR: 0.10 | Total loss: 443.28 | Epoch time 0.11\n",
      "Epoch 21 | LR: 0.05 | Total loss: 441.67 | Epoch time 0.11\n",
      "Epoch 22 | LR: 0.05 | Total loss: 440.45 | Epoch time 0.11\n",
      "Epoch 23 | LR: 0.05 | Total loss: 439.35 | Epoch time 0.13\n",
      "Epoch 24 | LR: 0.05 | Total loss: 438.22 | Epoch time 0.11\n",
      "Epoch 25 | LR: 0.05 | Total loss: 437.26 | Epoch time 0.11\n",
      "Epoch 26 | LR: 0.05 | Total loss: 436.32 | Epoch time 0.12\n",
      "Epoch 27 | LR: 0.05 | Total loss: 435.43 | Epoch time 0.11\n",
      "Epoch 28 | LR: 0.05 | Total loss: 434.97 | Epoch time 0.11\n",
      "Epoch 29 | LR: 0.05 | Total loss: 434.30 | Epoch time 0.11\n",
      "Epoch 30 | LR: 0.05 | Total loss: 433.64 | Epoch time 0.12\n",
      "Epoch 31 | LR: 0.05 | Total loss: 433.04 | Epoch time 0.11\n",
      "Epoch 32 | LR: 0.05 | Total loss: 432.64 | Epoch time 0.11\n",
      "Epoch 33 | LR: 0.05 | Total loss: 432.13 | Epoch time 0.13\n",
      "Epoch 34 | LR: 0.05 | Total loss: 431.85 | Epoch time 0.10\n",
      "Epoch 35 | LR: 0.05 | Total loss: 431.26 | Epoch time 0.11\n",
      "Epoch 36 | LR: 0.05 | Total loss: 430.74 | Epoch time 0.11\n",
      "Epoch 37 | LR: 0.05 | Total loss: 430.63 | Epoch time 0.13\n",
      "Epoch 38 | LR: 0.05 | Total loss: 429.96 | Epoch time 0.11\n",
      "Epoch 39 | LR: 0.05 | Total loss: 429.94 | Epoch time 0.11\n",
      "Epoch 40 | LR: 0.05 | Total loss: 429.22 | Epoch time 0.10\n",
      "Epoch 41 | LR: 0.01 | Total loss: 429.26 | Epoch time 0.11\n",
      "Epoch 42 | LR: 0.01 | Total loss: 429.00 | Epoch time 0.11\n",
      "Epoch 43 | LR: 0.01 | Total loss: 428.64 | Epoch time 0.10\n",
      "Epoch 44 | LR: 0.01 | Total loss: 428.59 | Epoch time 0.11\n",
      "Epoch 45 | LR: 0.01 | Total loss: 428.45 | Epoch time 0.11\n",
      "Epoch 46 | LR: 0.01 | Total loss: 427.85 | Epoch time 0.10\n",
      "Epoch 47 | LR: 0.01 | Total loss: 427.89 | Epoch time 0.10\n",
      "Epoch 48 | LR: 0.01 | Total loss: 427.36 | Epoch time 0.13\n",
      "Epoch 49 | LR: 0.01 | Total loss: 427.24 | Epoch time 0.10\n",
      "Epoch 50 | LR: 0.01 | Total loss: 427.04 | Epoch time 0.09\n",
      "Epoch 51 | LR: 0.01 | Total loss: 427.09 | Epoch time 0.12\n",
      "Epoch 52 | LR: 0.01 | Total loss: 426.69 | Epoch time 0.10\n",
      "Epoch 53 | LR: 0.01 | Total loss: 426.75 | Epoch time 0.10\n",
      "Epoch 54 | LR: 0.01 | Total loss: 426.45 | Epoch time 0.12\n",
      "Epoch 55 | LR: 0.01 | Total loss: 426.43 | Epoch time 0.10\n",
      "Epoch 56 | LR: 0.01 | Total loss: 426.38 | Epoch time 0.09\n",
      "Epoch 57 | LR: 0.01 | Total loss: 426.10 | Epoch time 0.11\n",
      "Epoch 58 | LR: 0.01 | Total loss: 425.82 | Epoch time 0.10\n",
      "Epoch 59 | LR: 0.01 | Total loss: 425.81 | Epoch time 0.09\n",
      "Epoch 60 | LR: 0.01 | Total loss: 425.58 | Epoch time 0.12\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #9 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 688.21 | Epoch time 0.14\n",
      "Epoch 2 | LR: 0.10 | Total loss: 600.79 | Epoch time 0.19\n",
      "Epoch 3 | LR: 0.10 | Total loss: 571.17 | Epoch time 0.16\n",
      "Epoch 4 | LR: 0.10 | Total loss: 549.21 | Epoch time 0.20\n",
      "Epoch 5 | LR: 0.10 | Total loss: 531.74 | Epoch time 0.19\n",
      "Epoch 6 | LR: 0.10 | Total loss: 517.97 | Epoch time 0.17\n",
      "Epoch 7 | LR: 0.10 | Total loss: 506.32 | Epoch time 0.18\n",
      "Epoch 8 | LR: 0.10 | Total loss: 496.81 | Epoch time 0.20\n",
      "Epoch 9 | LR: 0.10 | Total loss: 488.76 | Epoch time 0.19\n",
      "Epoch 10 | LR: 0.10 | Total loss: 481.90 | Epoch time 0.19\n",
      "Epoch 11 | LR: 0.10 | Total loss: 476.05 | Epoch time 0.13\n",
      "Epoch 12 | LR: 0.10 | Total loss: 470.96 | Epoch time 0.10\n",
      "Epoch 13 | LR: 0.10 | Total loss: 466.19 | Epoch time 0.16\n",
      "Epoch 14 | LR: 0.10 | Total loss: 462.19 | Epoch time 0.18\n",
      "Epoch 15 | LR: 0.10 | Total loss: 458.77 | Epoch time 0.15\n",
      "Epoch 16 | LR: 0.10 | Total loss: 455.94 | Epoch time 0.18\n",
      "Epoch 17 | LR: 0.10 | Total loss: 453.13 | Epoch time 0.16\n",
      "Epoch 18 | LR: 0.10 | Total loss: 450.72 | Epoch time 0.18\n",
      "Epoch 19 | LR: 0.10 | Total loss: 448.38 | Epoch time 0.17\n",
      "Epoch 20 | LR: 0.10 | Total loss: 446.59 | Epoch time 0.18\n",
      "Epoch 21 | LR: 0.05 | Total loss: 444.56 | Epoch time 0.19\n",
      "Epoch 22 | LR: 0.05 | Total loss: 443.13 | Epoch time 0.20\n",
      "Epoch 23 | LR: 0.05 | Total loss: 441.90 | Epoch time 0.16\n",
      "Epoch 24 | LR: 0.05 | Total loss: 440.15 | Epoch time 0.17\n",
      "Epoch 25 | LR: 0.05 | Total loss: 439.49 | Epoch time 0.11\n",
      "Epoch 26 | LR: 0.05 | Total loss: 438.09 | Epoch time 0.13\n",
      "Epoch 27 | LR: 0.05 | Total loss: 437.26 | Epoch time 0.20\n",
      "Epoch 28 | LR: 0.05 | Total loss: 436.27 | Epoch time 0.19\n",
      "Epoch 29 | LR: 0.05 | Total loss: 435.70 | Epoch time 0.17\n",
      "Epoch 30 | LR: 0.05 | Total loss: 434.74 | Epoch time 0.19\n",
      "Epoch 31 | LR: 0.05 | Total loss: 434.04 | Epoch time 0.16\n",
      "Epoch 32 | LR: 0.05 | Total loss: 433.73 | Epoch time 0.19\n",
      "Epoch 33 | LR: 0.05 | Total loss: 432.73 | Epoch time 0.19\n",
      "Epoch 34 | LR: 0.05 | Total loss: 432.61 | Epoch time 0.18\n",
      "Epoch 35 | LR: 0.05 | Total loss: 431.83 | Epoch time 0.15\n",
      "Epoch 36 | LR: 0.05 | Total loss: 431.42 | Epoch time 0.17\n",
      "Epoch 37 | LR: 0.05 | Total loss: 431.06 | Epoch time 0.17\n",
      "Epoch 38 | LR: 0.05 | Total loss: 430.56 | Epoch time 0.12\n",
      "Epoch 39 | LR: 0.05 | Total loss: 430.54 | Epoch time 0.12\n",
      "Epoch 40 | LR: 0.05 | Total loss: 429.81 | Epoch time 0.17\n",
      "Epoch 41 | LR: 0.01 | Total loss: 429.45 | Epoch time 0.16\n",
      "Epoch 42 | LR: 0.01 | Total loss: 429.13 | Epoch time 0.16\n",
      "Epoch 43 | LR: 0.01 | Total loss: 428.88 | Epoch time 0.16\n",
      "Epoch 44 | LR: 0.01 | Total loss: 428.58 | Epoch time 0.20\n",
      "Epoch 45 | LR: 0.01 | Total loss: 428.34 | Epoch time 0.19\n",
      "Epoch 46 | LR: 0.01 | Total loss: 428.33 | Epoch time 0.20\n",
      "Epoch 47 | LR: 0.01 | Total loss: 427.83 | Epoch time 0.17\n",
      "Epoch 48 | LR: 0.01 | Total loss: 427.36 | Epoch time 0.17\n",
      "Epoch 49 | LR: 0.01 | Total loss: 427.49 | Epoch time 0.16\n",
      "Epoch 50 | LR: 0.01 | Total loss: 427.51 | Epoch time 0.19\n",
      "Epoch 51 | LR: 0.01 | Total loss: 427.34 | Epoch time 0.12\n",
      "Epoch 52 | LR: 0.01 | Total loss: 426.87 | Epoch time 0.11\n",
      "Epoch 53 | LR: 0.01 | Total loss: 426.66 | Epoch time 0.16\n",
      "Epoch 54 | LR: 0.01 | Total loss: 426.68 | Epoch time 0.17\n",
      "Epoch 55 | LR: 0.01 | Total loss: 426.49 | Epoch time 0.15\n",
      "Epoch 56 | LR: 0.01 | Total loss: 426.41 | Epoch time 0.18\n",
      "Epoch 57 | LR: 0.01 | Total loss: 425.80 | Epoch time 0.17\n",
      "Epoch 58 | LR: 0.01 | Total loss: 425.82 | Epoch time 0.18\n",
      "Epoch 59 | LR: 0.01 | Total loss: 425.72 | Epoch time 0.17\n",
      "Epoch 60 | LR: 0.01 | Total loss: 425.49 | Epoch time 0.17\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #10 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 737.61 | Epoch time 0.16\n",
      "Epoch 2 | LR: 0.10 | Total loss: 608.18 | Epoch time 0.18\n",
      "Epoch 3 | LR: 0.10 | Total loss: 577.72 | Epoch time 0.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | LR: 0.10 | Total loss: 554.96 | Epoch time 0.19\n",
      "Epoch 5 | LR: 0.10 | Total loss: 535.49 | Epoch time 0.12\n",
      "Epoch 6 | LR: 0.10 | Total loss: 519.30 | Epoch time 0.11\n",
      "Epoch 7 | LR: 0.10 | Total loss: 505.62 | Epoch time 0.15\n",
      "Epoch 8 | LR: 0.10 | Total loss: 494.26 | Epoch time 0.19\n",
      "Epoch 9 | LR: 0.10 | Total loss: 485.23 | Epoch time 0.18\n",
      "Epoch 10 | LR: 0.10 | Total loss: 477.55 | Epoch time 0.16\n",
      "Epoch 11 | LR: 0.10 | Total loss: 471.26 | Epoch time 0.18\n",
      "Epoch 12 | LR: 0.10 | Total loss: 466.26 | Epoch time 0.18\n",
      "Epoch 13 | LR: 0.10 | Total loss: 461.50 | Epoch time 0.18\n",
      "Epoch 14 | LR: 0.10 | Total loss: 458.06 | Epoch time 0.19\n",
      "Epoch 15 | LR: 0.10 | Total loss: 454.44 | Epoch time 0.11\n",
      "Epoch 16 | LR: 0.10 | Total loss: 451.72 | Epoch time 0.10\n",
      "Epoch 17 | LR: 0.10 | Total loss: 449.21 | Epoch time 0.11\n",
      "Epoch 18 | LR: 0.10 | Total loss: 447.37 | Epoch time 0.11\n",
      "Epoch 19 | LR: 0.10 | Total loss: 445.08 | Epoch time 0.19\n",
      "Epoch 20 | LR: 0.10 | Total loss: 443.66 | Epoch time 0.12\n",
      "Epoch 21 | LR: 0.05 | Total loss: 442.30 | Epoch time 0.10\n",
      "Epoch 22 | LR: 0.05 | Total loss: 440.74 | Epoch time 0.09\n",
      "Epoch 23 | LR: 0.05 | Total loss: 439.47 | Epoch time 0.12\n",
      "Epoch 24 | LR: 0.05 | Total loss: 438.53 | Epoch time 0.10\n",
      "Epoch 25 | LR: 0.05 | Total loss: 437.54 | Epoch time 0.10\n",
      "Epoch 26 | LR: 0.05 | Total loss: 436.78 | Epoch time 0.12\n",
      "Epoch 27 | LR: 0.05 | Total loss: 435.86 | Epoch time 0.10\n",
      "Epoch 28 | LR: 0.05 | Total loss: 435.18 | Epoch time 0.10\n",
      "Epoch 29 | LR: 0.05 | Total loss: 434.46 | Epoch time 0.12\n",
      "Epoch 30 | LR: 0.05 | Total loss: 433.85 | Epoch time 0.11\n",
      "Epoch 31 | LR: 0.05 | Total loss: 433.40 | Epoch time 0.10\n",
      "Epoch 32 | LR: 0.05 | Total loss: 433.05 | Epoch time 0.18\n",
      "Epoch 33 | LR: 0.05 | Total loss: 432.20 | Epoch time 0.18\n",
      "Epoch 34 | LR: 0.05 | Total loss: 431.69 | Epoch time 0.19\n",
      "Epoch 35 | LR: 0.05 | Total loss: 431.45 | Epoch time 0.19\n",
      "Epoch 36 | LR: 0.05 | Total loss: 430.75 | Epoch time 0.16\n",
      "Epoch 37 | LR: 0.05 | Total loss: 430.50 | Epoch time 0.12\n",
      "Epoch 38 | LR: 0.05 | Total loss: 430.16 | Epoch time 0.12\n",
      "Epoch 39 | LR: 0.05 | Total loss: 430.15 | Epoch time 0.18\n",
      "Epoch 40 | LR: 0.05 | Total loss: 429.67 | Epoch time 0.17\n",
      "Epoch 41 | LR: 0.01 | Total loss: 429.54 | Epoch time 0.18\n",
      "Epoch 42 | LR: 0.01 | Total loss: 429.23 | Epoch time 0.16\n",
      "Epoch 43 | LR: 0.01 | Total loss: 428.72 | Epoch time 0.20\n",
      "Epoch 44 | LR: 0.01 | Total loss: 428.39 | Epoch time 0.18\n",
      "Epoch 45 | LR: 0.01 | Total loss: 428.36 | Epoch time 0.19\n",
      "Epoch 46 | LR: 0.01 | Total loss: 428.36 | Epoch time 0.17\n",
      "Epoch 47 | LR: 0.01 | Total loss: 427.91 | Epoch time 0.19\n",
      "Epoch 48 | LR: 0.01 | Total loss: 427.44 | Epoch time 0.15\n",
      "Epoch 49 | LR: 0.01 | Total loss: 427.58 | Epoch time 0.17\n",
      "Epoch 50 | LR: 0.01 | Total loss: 427.30 | Epoch time 0.15\n",
      "Epoch 51 | LR: 0.01 | Total loss: 427.17 | Epoch time 0.11\n",
      "Epoch 52 | LR: 0.01 | Total loss: 426.93 | Epoch time 0.15\n",
      "Epoch 53 | LR: 0.01 | Total loss: 426.85 | Epoch time 0.19\n",
      "Epoch 54 | LR: 0.01 | Total loss: 426.72 | Epoch time 0.16\n",
      "Epoch 55 | LR: 0.01 | Total loss: 426.45 | Epoch time 0.19\n",
      "Epoch 56 | LR: 0.01 | Total loss: 426.48 | Epoch time 0.16\n",
      "Epoch 57 | LR: 0.01 | Total loss: 425.97 | Epoch time 0.19\n",
      "Epoch 58 | LR: 0.01 | Total loss: 425.62 | Epoch time 0.19\n",
      "Epoch 59 | LR: 0.01 | Total loss: 425.82 | Epoch time 0.17\n",
      "Epoch 60 | LR: 0.01 | Total loss: 426.13 | Epoch time 0.15\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #11 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 687.65 | Epoch time 0.17\n",
      "Epoch 2 | LR: 0.10 | Total loss: 597.72 | Epoch time 0.18\n",
      "Epoch 3 | LR: 0.10 | Total loss: 567.73 | Epoch time 0.17\n",
      "Epoch 4 | LR: 0.10 | Total loss: 545.93 | Epoch time 0.10\n",
      "Epoch 5 | LR: 0.10 | Total loss: 528.09 | Epoch time 0.15\n",
      "Epoch 6 | LR: 0.10 | Total loss: 513.60 | Epoch time 0.17\n",
      "Epoch 7 | LR: 0.10 | Total loss: 501.83 | Epoch time 0.17\n",
      "Epoch 8 | LR: 0.10 | Total loss: 492.13 | Epoch time 0.16\n",
      "Epoch 9 | LR: 0.10 | Total loss: 483.74 | Epoch time 0.19\n",
      "Epoch 10 | LR: 0.10 | Total loss: 476.98 | Epoch time 0.16\n",
      "Epoch 11 | LR: 0.10 | Total loss: 471.17 | Epoch time 0.20\n",
      "Epoch 12 | LR: 0.10 | Total loss: 465.84 | Epoch time 0.15\n",
      "Epoch 13 | LR: 0.10 | Total loss: 461.90 | Epoch time 0.19\n",
      "Epoch 14 | LR: 0.10 | Total loss: 458.22 | Epoch time 0.16\n",
      "Epoch 15 | LR: 0.10 | Total loss: 454.86 | Epoch time 0.19\n",
      "Epoch 16 | LR: 0.10 | Total loss: 452.13 | Epoch time 0.18\n",
      "Epoch 17 | LR: 0.10 | Total loss: 449.88 | Epoch time 0.13\n",
      "Epoch 18 | LR: 0.10 | Total loss: 447.58 | Epoch time 0.09\n",
      "Epoch 19 | LR: 0.10 | Total loss: 445.46 | Epoch time 0.16\n",
      "Epoch 20 | LR: 0.10 | Total loss: 444.21 | Epoch time 0.10\n",
      "Epoch 21 | LR: 0.05 | Total loss: 442.57 | Epoch time 0.11\n",
      "Epoch 22 | LR: 0.05 | Total loss: 440.78 | Epoch time 0.12\n",
      "Epoch 23 | LR: 0.05 | Total loss: 440.12 | Epoch time 0.11\n",
      "Epoch 24 | LR: 0.05 | Total loss: 438.68 | Epoch time 0.19\n",
      "Epoch 25 | LR: 0.05 | Total loss: 437.68 | Epoch time 0.16\n",
      "Epoch 26 | LR: 0.05 | Total loss: 436.81 | Epoch time 0.15\n",
      "Epoch 27 | LR: 0.05 | Total loss: 436.04 | Epoch time 0.17\n",
      "Epoch 28 | LR: 0.05 | Total loss: 435.44 | Epoch time 0.17\n",
      "Epoch 29 | LR: 0.05 | Total loss: 434.69 | Epoch time 0.18\n",
      "Epoch 30 | LR: 0.05 | Total loss: 433.74 | Epoch time 0.17\n",
      "Epoch 31 | LR: 0.05 | Total loss: 433.21 | Epoch time 0.19\n",
      "Epoch 32 | LR: 0.05 | Total loss: 432.97 | Epoch time 0.11\n",
      "Epoch 33 | LR: 0.05 | Total loss: 432.29 | Epoch time 0.10\n",
      "Epoch 34 | LR: 0.05 | Total loss: 432.02 | Epoch time 0.15\n",
      "Epoch 35 | LR: 0.05 | Total loss: 431.42 | Epoch time 0.17\n",
      "Epoch 36 | LR: 0.05 | Total loss: 430.92 | Epoch time 0.17\n",
      "Epoch 37 | LR: 0.05 | Total loss: 430.48 | Epoch time 0.20\n",
      "Epoch 38 | LR: 0.05 | Total loss: 430.12 | Epoch time 0.16\n",
      "Epoch 39 | LR: 0.05 | Total loss: 429.84 | Epoch time 0.18\n",
      "Epoch 40 | LR: 0.05 | Total loss: 429.51 | Epoch time 0.16\n",
      "Epoch 41 | LR: 0.01 | Total loss: 429.32 | Epoch time 0.17\n",
      "Epoch 42 | LR: 0.01 | Total loss: 429.04 | Epoch time 0.19\n",
      "Epoch 43 | LR: 0.01 | Total loss: 428.90 | Epoch time 0.17\n",
      "Epoch 44 | LR: 0.01 | Total loss: 428.34 | Epoch time 0.16\n",
      "Epoch 45 | LR: 0.01 | Total loss: 428.16 | Epoch time 0.17\n",
      "Epoch 46 | LR: 0.01 | Total loss: 427.91 | Epoch time 0.09\n",
      "Epoch 47 | LR: 0.01 | Total loss: 427.90 | Epoch time 0.10\n",
      "Epoch 48 | LR: 0.01 | Total loss: 427.42 | Epoch time 0.17\n",
      "Epoch 49 | LR: 0.01 | Total loss: 427.16 | Epoch time 0.16\n",
      "Epoch 50 | LR: 0.01 | Total loss: 427.07 | Epoch time 0.18\n",
      "Epoch 51 | LR: 0.01 | Total loss: 426.85 | Epoch time 0.16\n",
      "Epoch 52 | LR: 0.01 | Total loss: 426.86 | Epoch time 0.19\n",
      "Epoch 53 | LR: 0.01 | Total loss: 426.67 | Epoch time 0.15\n",
      "Epoch 54 | LR: 0.01 | Total loss: 426.58 | Epoch time 0.14\n",
      "Epoch 55 | LR: 0.01 | Total loss: 426.42 | Epoch time 0.11\n",
      "Epoch 56 | LR: 0.01 | Total loss: 426.06 | Epoch time 0.11\n",
      "Epoch 57 | LR: 0.01 | Total loss: 426.11 | Epoch time 0.11\n",
      "Epoch 58 | LR: 0.01 | Total loss: 425.97 | Epoch time 0.09\n",
      "Epoch 59 | LR: 0.01 | Total loss: 425.73 | Epoch time 0.12\n",
      "Epoch 60 | LR: 0.01 | Total loss: 425.86 | Epoch time 0.10\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #12 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 771.91 | Epoch time 0.10\n",
      "Epoch 2 | LR: 0.10 | Total loss: 617.15 | Epoch time 0.12\n",
      "Epoch 3 | LR: 0.10 | Total loss: 589.69 | Epoch time 0.10\n",
      "Epoch 4 | LR: 0.10 | Total loss: 572.24 | Epoch time 0.11\n",
      "Epoch 5 | LR: 0.10 | Total loss: 555.82 | Epoch time 0.11\n",
      "Epoch 6 | LR: 0.10 | Total loss: 538.08 | Epoch time 0.11\n",
      "Epoch 7 | LR: 0.10 | Total loss: 520.48 | Epoch time 0.11\n",
      "Epoch 8 | LR: 0.10 | Total loss: 505.43 | Epoch time 0.11\n",
      "Epoch 9 | LR: 0.10 | Total loss: 493.15 | Epoch time 0.10\n",
      "Epoch 10 | LR: 0.10 | Total loss: 483.50 | Epoch time 0.12\n",
      "Epoch 11 | LR: 0.10 | Total loss: 475.70 | Epoch time 0.12\n",
      "Epoch 12 | LR: 0.10 | Total loss: 469.60 | Epoch time 0.10\n",
      "Epoch 13 | LR: 0.10 | Total loss: 464.39 | Epoch time 0.11\n",
      "Epoch 14 | LR: 0.10 | Total loss: 460.24 | Epoch time 0.12\n",
      "Epoch 15 | LR: 0.10 | Total loss: 456.73 | Epoch time 0.12\n",
      "Epoch 16 | LR: 0.10 | Total loss: 453.83 | Epoch time 0.11\n",
      "Epoch 17 | LR: 0.10 | Total loss: 451.01 | Epoch time 0.15\n",
      "Epoch 18 | LR: 0.10 | Total loss: 448.74 | Epoch time 0.10\n",
      "Epoch 19 | LR: 0.10 | Total loss: 446.72 | Epoch time 0.11\n",
      "Epoch 20 | LR: 0.10 | Total loss: 444.92 | Epoch time 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | LR: 0.05 | Total loss: 443.32 | Epoch time 0.09\n",
      "Epoch 22 | LR: 0.05 | Total loss: 442.06 | Epoch time 0.11\n",
      "Epoch 23 | LR: 0.05 | Total loss: 440.81 | Epoch time 0.12\n",
      "Epoch 24 | LR: 0.05 | Total loss: 439.74 | Epoch time 0.11\n",
      "Epoch 25 | LR: 0.05 | Total loss: 439.02 | Epoch time 0.10\n",
      "Epoch 26 | LR: 0.05 | Total loss: 437.74 | Epoch time 0.12\n",
      "Epoch 27 | LR: 0.05 | Total loss: 437.16 | Epoch time 0.13\n",
      "Epoch 28 | LR: 0.05 | Total loss: 436.19 | Epoch time 0.11\n",
      "Epoch 29 | LR: 0.05 | Total loss: 435.61 | Epoch time 0.10\n",
      "Epoch 30 | LR: 0.05 | Total loss: 435.00 | Epoch time 0.11\n",
      "Epoch 31 | LR: 0.05 | Total loss: 434.08 | Epoch time 0.13\n",
      "Epoch 32 | LR: 0.05 | Total loss: 433.53 | Epoch time 0.11\n",
      "Epoch 33 | LR: 0.05 | Total loss: 433.26 | Epoch time 0.13\n",
      "Epoch 34 | LR: 0.05 | Total loss: 432.48 | Epoch time 0.10\n",
      "Epoch 35 | LR: 0.05 | Total loss: 432.35 | Epoch time 0.13\n",
      "Epoch 36 | LR: 0.05 | Total loss: 431.84 | Epoch time 0.11\n",
      "Epoch 37 | LR: 0.05 | Total loss: 431.36 | Epoch time 0.12\n",
      "Epoch 38 | LR: 0.05 | Total loss: 430.94 | Epoch time 0.11\n",
      "Epoch 39 | LR: 0.05 | Total loss: 430.40 | Epoch time 0.12\n",
      "Epoch 40 | LR: 0.05 | Total loss: 429.96 | Epoch time 0.11\n",
      "Epoch 41 | LR: 0.01 | Total loss: 430.13 | Epoch time 0.12\n",
      "Epoch 42 | LR: 0.01 | Total loss: 429.57 | Epoch time 0.10\n",
      "Epoch 43 | LR: 0.01 | Total loss: 429.29 | Epoch time 0.11\n",
      "Epoch 44 | LR: 0.01 | Total loss: 429.23 | Epoch time 0.11\n",
      "Epoch 45 | LR: 0.01 | Total loss: 428.61 | Epoch time 0.12\n",
      "Epoch 46 | LR: 0.01 | Total loss: 428.56 | Epoch time 0.13\n",
      "Epoch 47 | LR: 0.01 | Total loss: 428.45 | Epoch time 0.12\n",
      "Epoch 48 | LR: 0.01 | Total loss: 427.99 | Epoch time 0.13\n",
      "Epoch 49 | LR: 0.01 | Total loss: 427.83 | Epoch time 0.14\n",
      "Epoch 50 | LR: 0.01 | Total loss: 427.52 | Epoch time 0.12\n",
      "Epoch 51 | LR: 0.01 | Total loss: 427.52 | Epoch time 0.17\n",
      "Epoch 52 | LR: 0.01 | Total loss: 426.97 | Epoch time 0.16\n",
      "Epoch 53 | LR: 0.01 | Total loss: 427.07 | Epoch time 0.18\n",
      "Epoch 54 | LR: 0.01 | Total loss: 426.86 | Epoch time 0.19\n",
      "Epoch 55 | LR: 0.01 | Total loss: 426.77 | Epoch time 0.20\n",
      "Epoch 56 | LR: 0.01 | Total loss: 426.54 | Epoch time 0.16\n",
      "Epoch 57 | LR: 0.01 | Total loss: 426.60 | Epoch time 0.14\n",
      "Epoch 58 | LR: 0.01 | Total loss: 426.26 | Epoch time 0.10\n",
      "Epoch 59 | LR: 0.01 | Total loss: 426.27 | Epoch time 0.15\n",
      "Epoch 60 | LR: 0.01 | Total loss: 425.95 | Epoch time 0.19\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #13 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 705.77 | Epoch time 0.18\n",
      "Epoch 2 | LR: 0.10 | Total loss: 601.68 | Epoch time 0.18\n",
      "Epoch 3 | LR: 0.10 | Total loss: 573.40 | Epoch time 0.11\n",
      "Epoch 4 | LR: 0.10 | Total loss: 553.21 | Epoch time 0.14\n",
      "Epoch 5 | LR: 0.10 | Total loss: 535.84 | Epoch time 0.16\n",
      "Epoch 6 | LR: 0.10 | Total loss: 520.30 | Epoch time 0.20\n",
      "Epoch 7 | LR: 0.10 | Total loss: 507.17 | Epoch time 0.17\n",
      "Epoch 8 | LR: 0.10 | Total loss: 495.76 | Epoch time 0.18\n",
      "Epoch 9 | LR: 0.10 | Total loss: 486.47 | Epoch time 0.18\n",
      "Epoch 10 | LR: 0.10 | Total loss: 478.65 | Epoch time 0.19\n",
      "Epoch 11 | LR: 0.10 | Total loss: 472.05 | Epoch time 0.12\n",
      "Epoch 12 | LR: 0.10 | Total loss: 466.46 | Epoch time 0.10\n",
      "Epoch 13 | LR: 0.10 | Total loss: 461.94 | Epoch time 0.17\n",
      "Epoch 14 | LR: 0.10 | Total loss: 458.02 | Epoch time 0.18\n",
      "Epoch 15 | LR: 0.10 | Total loss: 454.75 | Epoch time 0.17\n",
      "Epoch 16 | LR: 0.10 | Total loss: 452.00 | Epoch time 0.20\n",
      "Epoch 17 | LR: 0.10 | Total loss: 449.28 | Epoch time 0.17\n",
      "Epoch 18 | LR: 0.10 | Total loss: 447.16 | Epoch time 0.14\n",
      "Epoch 19 | LR: 0.10 | Total loss: 445.29 | Epoch time 0.10\n",
      "Epoch 20 | LR: 0.10 | Total loss: 443.22 | Epoch time 0.10\n",
      "Epoch 21 | LR: 0.05 | Total loss: 441.99 | Epoch time 0.10\n",
      "Epoch 22 | LR: 0.05 | Total loss: 440.51 | Epoch time 0.10\n",
      "Epoch 23 | LR: 0.05 | Total loss: 439.52 | Epoch time 0.11\n",
      "Epoch 24 | LR: 0.05 | Total loss: 438.25 | Epoch time 0.12\n",
      "Epoch 25 | LR: 0.05 | Total loss: 437.20 | Epoch time 0.11\n",
      "Epoch 26 | LR: 0.05 | Total loss: 436.56 | Epoch time 0.11\n",
      "Epoch 27 | LR: 0.05 | Total loss: 435.67 | Epoch time 0.11\n",
      "Epoch 28 | LR: 0.05 | Total loss: 434.96 | Epoch time 0.13\n",
      "Epoch 29 | LR: 0.05 | Total loss: 434.18 | Epoch time 0.11\n",
      "Epoch 30 | LR: 0.05 | Total loss: 433.18 | Epoch time 0.10\n",
      "Epoch 31 | LR: 0.05 | Total loss: 432.91 | Epoch time 0.10\n",
      "Epoch 32 | LR: 0.05 | Total loss: 432.36 | Epoch time 0.11\n",
      "Epoch 33 | LR: 0.05 | Total loss: 432.06 | Epoch time 0.10\n",
      "Epoch 34 | LR: 0.05 | Total loss: 432.01 | Epoch time 0.09\n",
      "Epoch 35 | LR: 0.05 | Total loss: 430.99 | Epoch time 0.12\n",
      "Epoch 36 | LR: 0.05 | Total loss: 430.57 | Epoch time 0.10\n",
      "Epoch 37 | LR: 0.05 | Total loss: 430.38 | Epoch time 0.10\n",
      "Epoch 38 | LR: 0.05 | Total loss: 429.87 | Epoch time 0.12\n",
      "Epoch 39 | LR: 0.05 | Total loss: 429.73 | Epoch time 0.10\n",
      "Epoch 40 | LR: 0.05 | Total loss: 429.63 | Epoch time 0.10\n",
      "Epoch 41 | LR: 0.01 | Total loss: 428.96 | Epoch time 0.11\n",
      "Epoch 42 | LR: 0.01 | Total loss: 428.66 | Epoch time 0.09\n",
      "Epoch 43 | LR: 0.01 | Total loss: 428.63 | Epoch time 0.09\n",
      "Epoch 44 | LR: 0.01 | Total loss: 428.33 | Epoch time 0.11\n",
      "Epoch 45 | LR: 0.01 | Total loss: 428.32 | Epoch time 0.10\n",
      "Epoch 46 | LR: 0.01 | Total loss: 427.95 | Epoch time 0.11\n",
      "Epoch 47 | LR: 0.01 | Total loss: 427.53 | Epoch time 0.10\n",
      "Epoch 48 | LR: 0.01 | Total loss: 427.47 | Epoch time 0.12\n",
      "Epoch 49 | LR: 0.01 | Total loss: 427.06 | Epoch time 0.10\n",
      "Epoch 50 | LR: 0.01 | Total loss: 427.02 | Epoch time 0.09\n",
      "Epoch 51 | LR: 0.01 | Total loss: 426.97 | Epoch time 0.11\n",
      "Epoch 52 | LR: 0.01 | Total loss: 426.70 | Epoch time 0.10\n",
      "Epoch 53 | LR: 0.01 | Total loss: 426.51 | Epoch time 0.10\n",
      "Epoch 54 | LR: 0.01 | Total loss: 426.52 | Epoch time 0.12\n",
      "Epoch 55 | LR: 0.01 | Total loss: 426.24 | Epoch time 0.09\n",
      "Epoch 56 | LR: 0.01 | Total loss: 426.11 | Epoch time 0.09\n",
      "Epoch 57 | LR: 0.01 | Total loss: 425.69 | Epoch time 0.11\n",
      "Epoch 58 | LR: 0.01 | Total loss: 425.63 | Epoch time 0.10\n",
      "Epoch 59 | LR: 0.01 | Total loss: 425.93 | Epoch time 0.10\n",
      "Epoch 60 | LR: 0.01 | Total loss: 425.58 | Epoch time 0.13\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #14 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 730.30 | Epoch time 0.09\n",
      "Epoch 2 | LR: 0.10 | Total loss: 590.28 | Epoch time 0.09\n",
      "Epoch 3 | LR: 0.10 | Total loss: 560.19 | Epoch time 0.12\n",
      "Epoch 4 | LR: 0.10 | Total loss: 539.20 | Epoch time 0.09\n",
      "Epoch 5 | LR: 0.10 | Total loss: 522.54 | Epoch time 0.09\n",
      "Epoch 6 | LR: 0.10 | Total loss: 508.79 | Epoch time 0.12\n",
      "Epoch 7 | LR: 0.10 | Total loss: 497.39 | Epoch time 0.11\n",
      "Epoch 8 | LR: 0.10 | Total loss: 488.35 | Epoch time 0.10\n",
      "Epoch 9 | LR: 0.10 | Total loss: 480.60 | Epoch time 0.12\n",
      "Epoch 10 | LR: 0.10 | Total loss: 474.16 | Epoch time 0.10\n",
      "Epoch 11 | LR: 0.10 | Total loss: 469.07 | Epoch time 0.10\n",
      "Epoch 12 | LR: 0.10 | Total loss: 464.67 | Epoch time 0.11\n",
      "Epoch 13 | LR: 0.10 | Total loss: 460.79 | Epoch time 0.11\n",
      "Epoch 14 | LR: 0.10 | Total loss: 457.35 | Epoch time 0.09\n",
      "Epoch 15 | LR: 0.10 | Total loss: 454.76 | Epoch time 0.12\n",
      "Epoch 16 | LR: 0.10 | Total loss: 452.12 | Epoch time 0.12\n",
      "Epoch 17 | LR: 0.10 | Total loss: 449.96 | Epoch time 0.10\n",
      "Epoch 18 | LR: 0.10 | Total loss: 447.91 | Epoch time 0.11\n",
      "Epoch 19 | LR: 0.10 | Total loss: 446.03 | Epoch time 0.11\n",
      "Epoch 20 | LR: 0.10 | Total loss: 444.71 | Epoch time 0.10\n",
      "Epoch 21 | LR: 0.05 | Total loss: 443.26 | Epoch time 0.12\n",
      "Epoch 22 | LR: 0.05 | Total loss: 441.86 | Epoch time 0.12\n",
      "Epoch 23 | LR: 0.05 | Total loss: 440.91 | Epoch time 0.10\n",
      "Epoch 24 | LR: 0.05 | Total loss: 439.92 | Epoch time 0.09\n",
      "Epoch 25 | LR: 0.05 | Total loss: 438.80 | Epoch time 0.11\n",
      "Epoch 26 | LR: 0.05 | Total loss: 437.75 | Epoch time 0.09\n",
      "Epoch 27 | LR: 0.05 | Total loss: 436.91 | Epoch time 0.10\n",
      "Epoch 28 | LR: 0.05 | Total loss: 436.56 | Epoch time 0.12\n",
      "Epoch 29 | LR: 0.05 | Total loss: 435.78 | Epoch time 0.10\n",
      "Epoch 30 | LR: 0.05 | Total loss: 434.83 | Epoch time 0.09\n",
      "Epoch 31 | LR: 0.05 | Total loss: 434.27 | Epoch time 0.12\n",
      "Epoch 32 | LR: 0.05 | Total loss: 433.74 | Epoch time 0.09\n",
      "Epoch 33 | LR: 0.05 | Total loss: 433.22 | Epoch time 0.09\n",
      "Epoch 34 | LR: 0.05 | Total loss: 432.72 | Epoch time 0.11\n",
      "Epoch 35 | LR: 0.05 | Total loss: 432.36 | Epoch time 0.11\n",
      "Epoch 36 | LR: 0.05 | Total loss: 432.05 | Epoch time 0.12\n",
      "Epoch 37 | LR: 0.05 | Total loss: 431.31 | Epoch time 0.10\n",
      "Epoch 38 | LR: 0.05 | Total loss: 431.09 | Epoch time 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | LR: 0.05 | Total loss: 430.64 | Epoch time 0.13\n",
      "Epoch 40 | LR: 0.05 | Total loss: 430.21 | Epoch time 0.09\n",
      "Epoch 41 | LR: 0.01 | Total loss: 430.27 | Epoch time 0.10\n",
      "Epoch 42 | LR: 0.01 | Total loss: 429.82 | Epoch time 0.11\n",
      "Epoch 43 | LR: 0.01 | Total loss: 429.46 | Epoch time 0.10\n",
      "Epoch 44 | LR: 0.01 | Total loss: 429.31 | Epoch time 0.10\n",
      "Epoch 45 | LR: 0.01 | Total loss: 428.96 | Epoch time 0.12\n",
      "Epoch 46 | LR: 0.01 | Total loss: 428.57 | Epoch time 0.10\n",
      "Epoch 47 | LR: 0.01 | Total loss: 428.34 | Epoch time 0.10\n",
      "Epoch 48 | LR: 0.01 | Total loss: 428.25 | Epoch time 0.12\n",
      "Epoch 49 | LR: 0.01 | Total loss: 427.95 | Epoch time 0.10\n",
      "Epoch 50 | LR: 0.01 | Total loss: 427.80 | Epoch time 0.11\n",
      "Epoch 51 | LR: 0.01 | Total loss: 427.44 | Epoch time 0.12\n",
      "Epoch 52 | LR: 0.01 | Total loss: 427.64 | Epoch time 0.12\n",
      "Epoch 53 | LR: 0.01 | Total loss: 427.34 | Epoch time 0.10\n",
      "Epoch 54 | LR: 0.01 | Total loss: 426.84 | Epoch time 0.10\n",
      "Epoch 55 | LR: 0.01 | Total loss: 426.63 | Epoch time 0.12\n",
      "Epoch 56 | LR: 0.01 | Total loss: 426.78 | Epoch time 0.11\n",
      "Epoch 57 | LR: 0.01 | Total loss: 426.71 | Epoch time 0.10\n",
      "Epoch 58 | LR: 0.01 | Total loss: 426.34 | Epoch time 0.10\n",
      "Epoch 59 | LR: 0.01 | Total loss: 425.93 | Epoch time 0.12\n",
      "Epoch 60 | LR: 0.01 | Total loss: 426.21 | Epoch time 0.13\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #15 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 733.00 | Epoch time 0.18\n",
      "Epoch 2 | LR: 0.10 | Total loss: 609.87 | Epoch time 0.19\n",
      "Epoch 3 | LR: 0.10 | Total loss: 583.85 | Epoch time 0.16\n",
      "Epoch 4 | LR: 0.10 | Total loss: 564.58 | Epoch time 0.19\n",
      "Epoch 5 | LR: 0.10 | Total loss: 547.15 | Epoch time 0.16\n",
      "Epoch 6 | LR: 0.10 | Total loss: 531.63 | Epoch time 0.20\n",
      "Epoch 7 | LR: 0.10 | Total loss: 517.90 | Epoch time 0.16\n",
      "Epoch 8 | LR: 0.10 | Total loss: 506.55 | Epoch time 0.14\n",
      "Epoch 9 | LR: 0.10 | Total loss: 496.58 | Epoch time 0.11\n",
      "Epoch 10 | LR: 0.10 | Total loss: 488.34 | Epoch time 0.16\n",
      "Epoch 11 | LR: 0.10 | Total loss: 480.75 | Epoch time 0.17\n",
      "Epoch 12 | LR: 0.10 | Total loss: 474.88 | Epoch time 0.18\n",
      "Epoch 13 | LR: 0.10 | Total loss: 469.80 | Epoch time 0.17\n",
      "Epoch 14 | LR: 0.10 | Total loss: 465.12 | Epoch time 0.20\n",
      "Epoch 15 | LR: 0.10 | Total loss: 461.41 | Epoch time 0.16\n",
      "Epoch 16 | LR: 0.10 | Total loss: 457.72 | Epoch time 0.20\n",
      "Epoch 17 | LR: 0.10 | Total loss: 454.95 | Epoch time 0.16\n",
      "Epoch 18 | LR: 0.10 | Total loss: 452.03 | Epoch time 0.18\n",
      "Epoch 19 | LR: 0.10 | Total loss: 449.51 | Epoch time 0.16\n",
      "Epoch 20 | LR: 0.10 | Total loss: 447.56 | Epoch time 0.19\n",
      "Epoch 21 | LR: 0.05 | Total loss: 445.54 | Epoch time 0.15\n",
      "Epoch 22 | LR: 0.05 | Total loss: 443.99 | Epoch time 0.12\n",
      "Epoch 23 | LR: 0.05 | Total loss: 442.58 | Epoch time 0.14\n",
      "Epoch 24 | LR: 0.05 | Total loss: 440.65 | Epoch time 0.17\n",
      "Epoch 25 | LR: 0.05 | Total loss: 439.68 | Epoch time 0.17\n",
      "Epoch 26 | LR: 0.05 | Total loss: 438.34 | Epoch time 0.19\n",
      "Epoch 27 | LR: 0.05 | Total loss: 437.35 | Epoch time 0.17\n",
      "Epoch 28 | LR: 0.05 | Total loss: 436.59 | Epoch time 0.22\n",
      "Epoch 29 | LR: 0.05 | Total loss: 435.44 | Epoch time 0.15\n",
      "Epoch 30 | LR: 0.05 | Total loss: 434.68 | Epoch time 0.16\n",
      "Epoch 31 | LR: 0.05 | Total loss: 434.14 | Epoch time 0.16\n",
      "Epoch 32 | LR: 0.05 | Total loss: 433.58 | Epoch time 0.18\n",
      "Epoch 33 | LR: 0.05 | Total loss: 432.90 | Epoch time 0.18\n",
      "Epoch 34 | LR: 0.05 | Total loss: 432.14 | Epoch time 0.18\n",
      "Epoch 35 | LR: 0.05 | Total loss: 431.70 | Epoch time 0.10\n",
      "Epoch 36 | LR: 0.05 | Total loss: 431.21 | Epoch time 0.10\n",
      "Epoch 37 | LR: 0.05 | Total loss: 430.98 | Epoch time 0.19\n",
      "Epoch 38 | LR: 0.05 | Total loss: 430.32 | Epoch time 0.16\n",
      "Epoch 39 | LR: 0.05 | Total loss: 430.24 | Epoch time 0.16\n",
      "Epoch 40 | LR: 0.05 | Total loss: 429.87 | Epoch time 0.17\n",
      "Epoch 41 | LR: 0.01 | Total loss: 429.35 | Epoch time 0.19\n",
      "Epoch 42 | LR: 0.01 | Total loss: 429.11 | Epoch time 0.15\n",
      "Epoch 43 | LR: 0.01 | Total loss: 429.01 | Epoch time 0.18\n",
      "Epoch 44 | LR: 0.01 | Total loss: 428.39 | Epoch time 0.16\n",
      "Epoch 45 | LR: 0.01 | Total loss: 428.14 | Epoch time 0.19\n",
      "Epoch 46 | LR: 0.01 | Total loss: 427.93 | Epoch time 0.16\n",
      "Epoch 47 | LR: 0.01 | Total loss: 427.82 | Epoch time 0.13\n",
      "Epoch 48 | LR: 0.01 | Total loss: 427.73 | Epoch time 0.15\n",
      "Epoch 49 | LR: 0.01 | Total loss: 427.36 | Epoch time 0.13\n",
      "Epoch 50 | LR: 0.01 | Total loss: 427.17 | Epoch time 0.10\n",
      "Epoch 51 | LR: 0.01 | Total loss: 426.64 | Epoch time 0.16\n",
      "Epoch 52 | LR: 0.01 | Total loss: 426.86 | Epoch time 0.17\n",
      "Epoch 53 | LR: 0.01 | Total loss: 426.65 | Epoch time 0.17\n",
      "Epoch 54 | LR: 0.01 | Total loss: 426.19 | Epoch time 0.17\n",
      "Epoch 55 | LR: 0.01 | Total loss: 426.20 | Epoch time 0.17\n",
      "Epoch 56 | LR: 0.01 | Total loss: 425.99 | Epoch time 0.16\n",
      "Epoch 57 | LR: 0.01 | Total loss: 426.07 | Epoch time 0.19\n",
      "Epoch 58 | LR: 0.01 | Total loss: 425.99 | Epoch time 0.16\n",
      "Epoch 59 | LR: 0.01 | Total loss: 425.68 | Epoch time 0.19\n",
      "Epoch 60 | LR: 0.01 | Total loss: 425.59 | Epoch time 0.15\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #16 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 729.95 | Epoch time 0.18\n",
      "Epoch 2 | LR: 0.10 | Total loss: 615.59 | Epoch time 0.17\n",
      "Epoch 3 | LR: 0.10 | Total loss: 583.91 | Epoch time 0.11\n",
      "Epoch 4 | LR: 0.10 | Total loss: 561.40 | Epoch time 0.11\n",
      "Epoch 5 | LR: 0.10 | Total loss: 543.52 | Epoch time 0.15\n",
      "Epoch 6 | LR: 0.10 | Total loss: 529.03 | Epoch time 0.18\n",
      "Epoch 7 | LR: 0.10 | Total loss: 516.59 | Epoch time 0.18\n",
      "Epoch 8 | LR: 0.10 | Total loss: 506.23 | Epoch time 0.15\n",
      "Epoch 9 | LR: 0.10 | Total loss: 497.69 | Epoch time 0.15\n",
      "Epoch 10 | LR: 0.10 | Total loss: 490.16 | Epoch time 0.10\n",
      "Epoch 11 | LR: 0.10 | Total loss: 483.40 | Epoch time 0.09\n",
      "Epoch 12 | LR: 0.10 | Total loss: 478.06 | Epoch time 0.11\n",
      "Epoch 13 | LR: 0.10 | Total loss: 472.81 | Epoch time 0.10\n",
      "Epoch 14 | LR: 0.10 | Total loss: 468.34 | Epoch time 0.10\n",
      "Epoch 15 | LR: 0.10 | Total loss: 464.69 | Epoch time 0.11\n",
      "Epoch 16 | LR: 0.10 | Total loss: 461.13 | Epoch time 0.10\n",
      "Epoch 17 | LR: 0.10 | Total loss: 458.02 | Epoch time 0.11\n",
      "Epoch 18 | LR: 0.10 | Total loss: 455.04 | Epoch time 0.10\n",
      "Epoch 19 | LR: 0.10 | Total loss: 452.79 | Epoch time 0.11\n",
      "Epoch 20 | LR: 0.10 | Total loss: 450.56 | Epoch time 0.10\n",
      "Epoch 21 | LR: 0.05 | Total loss: 448.56 | Epoch time 0.10\n",
      "Epoch 22 | LR: 0.05 | Total loss: 446.54 | Epoch time 0.12\n",
      "Epoch 23 | LR: 0.05 | Total loss: 445.03 | Epoch time 0.11\n",
      "Epoch 24 | LR: 0.05 | Total loss: 443.45 | Epoch time 0.09\n",
      "Epoch 25 | LR: 0.05 | Total loss: 441.83 | Epoch time 0.11\n",
      "Epoch 26 | LR: 0.05 | Total loss: 440.86 | Epoch time 0.10\n",
      "Epoch 27 | LR: 0.05 | Total loss: 439.65 | Epoch time 0.09\n",
      "Epoch 28 | LR: 0.05 | Total loss: 438.36 | Epoch time 0.11\n",
      "Epoch 29 | LR: 0.05 | Total loss: 437.27 | Epoch time 0.10\n",
      "Epoch 30 | LR: 0.05 | Total loss: 436.39 | Epoch time 0.10\n",
      "Epoch 31 | LR: 0.05 | Total loss: 435.42 | Epoch time 0.12\n",
      "Epoch 32 | LR: 0.05 | Total loss: 434.68 | Epoch time 0.10\n",
      "Epoch 33 | LR: 0.05 | Total loss: 434.06 | Epoch time 0.10\n",
      "Epoch 34 | LR: 0.05 | Total loss: 433.29 | Epoch time 0.12\n",
      "Epoch 35 | LR: 0.05 | Total loss: 432.79 | Epoch time 0.10\n",
      "Epoch 36 | LR: 0.05 | Total loss: 432.26 | Epoch time 0.10\n",
      "Epoch 37 | LR: 0.05 | Total loss: 431.32 | Epoch time 0.12\n",
      "Epoch 38 | LR: 0.05 | Total loss: 431.05 | Epoch time 0.10\n",
      "Epoch 39 | LR: 0.05 | Total loss: 430.48 | Epoch time 0.11\n",
      "Epoch 40 | LR: 0.05 | Total loss: 430.08 | Epoch time 0.10\n",
      "Epoch 41 | LR: 0.01 | Total loss: 429.82 | Epoch time 0.10\n",
      "Epoch 42 | LR: 0.01 | Total loss: 429.47 | Epoch time 0.12\n",
      "Epoch 43 | LR: 0.01 | Total loss: 428.99 | Epoch time 0.11\n",
      "Epoch 44 | LR: 0.01 | Total loss: 428.67 | Epoch time 0.12\n",
      "Epoch 45 | LR: 0.01 | Total loss: 428.53 | Epoch time 0.12\n",
      "Epoch 46 | LR: 0.01 | Total loss: 428.06 | Epoch time 0.10\n",
      "Epoch 47 | LR: 0.01 | Total loss: 427.94 | Epoch time 0.10\n",
      "Epoch 48 | LR: 0.01 | Total loss: 427.77 | Epoch time 0.12\n",
      "Epoch 49 | LR: 0.01 | Total loss: 427.31 | Epoch time 0.11\n",
      "Epoch 50 | LR: 0.01 | Total loss: 427.07 | Epoch time 0.10\n",
      "Epoch 51 | LR: 0.01 | Total loss: 426.51 | Epoch time 0.11\n",
      "Epoch 52 | LR: 0.01 | Total loss: 426.87 | Epoch time 0.11\n",
      "Epoch 53 | LR: 0.01 | Total loss: 426.56 | Epoch time 0.11\n",
      "Epoch 54 | LR: 0.01 | Total loss: 426.07 | Epoch time 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 | LR: 0.01 | Total loss: 426.30 | Epoch time 0.12\n",
      "Epoch 56 | LR: 0.01 | Total loss: 426.25 | Epoch time 0.11\n",
      "Epoch 57 | LR: 0.01 | Total loss: 425.81 | Epoch time 0.11\n",
      "Epoch 58 | LR: 0.01 | Total loss: 425.81 | Epoch time 0.10\n",
      "Epoch 59 | LR: 0.01 | Total loss: 425.86 | Epoch time 0.10\n",
      "Epoch 60 | LR: 0.01 | Total loss: 425.62 | Epoch time 0.12\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #17 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 707.67 | Epoch time 0.12\n",
      "Epoch 2 | LR: 0.10 | Total loss: 579.45 | Epoch time 0.10\n",
      "Epoch 3 | LR: 0.10 | Total loss: 552.52 | Epoch time 0.12\n",
      "Epoch 4 | LR: 0.10 | Total loss: 532.93 | Epoch time 0.11\n",
      "Epoch 5 | LR: 0.10 | Total loss: 516.85 | Epoch time 0.11\n",
      "Epoch 6 | LR: 0.10 | Total loss: 504.02 | Epoch time 0.11\n",
      "Epoch 7 | LR: 0.10 | Total loss: 492.91 | Epoch time 0.11\n",
      "Epoch 8 | LR: 0.10 | Total loss: 484.27 | Epoch time 0.11\n",
      "Epoch 9 | LR: 0.10 | Total loss: 477.07 | Epoch time 0.11\n",
      "Epoch 10 | LR: 0.10 | Total loss: 471.03 | Epoch time 0.11\n",
      "Epoch 11 | LR: 0.10 | Total loss: 466.33 | Epoch time 0.11\n",
      "Epoch 12 | LR: 0.10 | Total loss: 461.60 | Epoch time 0.11\n",
      "Epoch 13 | LR: 0.10 | Total loss: 458.03 | Epoch time 0.10\n",
      "Epoch 14 | LR: 0.10 | Total loss: 455.13 | Epoch time 0.12\n",
      "Epoch 15 | LR: 0.10 | Total loss: 452.15 | Epoch time 0.11\n",
      "Epoch 16 | LR: 0.10 | Total loss: 449.50 | Epoch time 0.11\n",
      "Epoch 17 | LR: 0.10 | Total loss: 447.87 | Epoch time 0.11\n",
      "Epoch 18 | LR: 0.10 | Total loss: 445.92 | Epoch time 0.11\n",
      "Epoch 19 | LR: 0.10 | Total loss: 444.10 | Epoch time 0.11\n",
      "Epoch 20 | LR: 0.10 | Total loss: 442.76 | Epoch time 0.13\n",
      "Epoch 21 | LR: 0.05 | Total loss: 441.26 | Epoch time 0.17\n",
      "Epoch 22 | LR: 0.05 | Total loss: 440.03 | Epoch time 0.16\n",
      "Epoch 23 | LR: 0.05 | Total loss: 438.90 | Epoch time 0.21\n",
      "Epoch 24 | LR: 0.05 | Total loss: 437.77 | Epoch time 0.18\n",
      "Epoch 25 | LR: 0.05 | Total loss: 437.28 | Epoch time 0.20\n",
      "Epoch 26 | LR: 0.05 | Total loss: 436.08 | Epoch time 0.15\n",
      "Epoch 27 | LR: 0.05 | Total loss: 435.71 | Epoch time 0.20\n",
      "Epoch 28 | LR: 0.05 | Total loss: 435.19 | Epoch time 0.16\n",
      "Epoch 29 | LR: 0.05 | Total loss: 434.40 | Epoch time 0.18\n",
      "Epoch 30 | LR: 0.05 | Total loss: 433.99 | Epoch time 0.16\n",
      "Epoch 31 | LR: 0.05 | Total loss: 433.17 | Epoch time 0.18\n",
      "Epoch 32 | LR: 0.05 | Total loss: 432.64 | Epoch time 0.15\n",
      "Epoch 33 | LR: 0.05 | Total loss: 432.31 | Epoch time 0.22\n",
      "Epoch 34 | LR: 0.05 | Total loss: 432.02 | Epoch time 0.13\n",
      "Epoch 35 | LR: 0.05 | Total loss: 431.59 | Epoch time 0.12\n",
      "Epoch 36 | LR: 0.05 | Total loss: 431.06 | Epoch time 0.17\n",
      "Epoch 37 | LR: 0.05 | Total loss: 430.68 | Epoch time 0.17\n",
      "Epoch 38 | LR: 0.05 | Total loss: 430.41 | Epoch time 0.18\n",
      "Epoch 39 | LR: 0.05 | Total loss: 429.98 | Epoch time 0.19\n",
      "Epoch 40 | LR: 0.05 | Total loss: 429.76 | Epoch time 0.16\n",
      "Epoch 41 | LR: 0.01 | Total loss: 429.67 | Epoch time 0.17\n",
      "Epoch 42 | LR: 0.01 | Total loss: 429.24 | Epoch time 0.17\n",
      "Epoch 43 | LR: 0.01 | Total loss: 428.95 | Epoch time 0.19\n",
      "Epoch 44 | LR: 0.01 | Total loss: 428.55 | Epoch time 0.15\n",
      "Epoch 45 | LR: 0.01 | Total loss: 428.67 | Epoch time 0.19\n",
      "Epoch 46 | LR: 0.01 | Total loss: 428.08 | Epoch time 0.17\n",
      "Epoch 47 | LR: 0.01 | Total loss: 427.99 | Epoch time 0.15\n",
      "Epoch 48 | LR: 0.01 | Total loss: 427.65 | Epoch time 0.10\n",
      "Epoch 49 | LR: 0.01 | Total loss: 427.47 | Epoch time 0.15\n",
      "Epoch 50 | LR: 0.01 | Total loss: 427.34 | Epoch time 0.15\n",
      "Epoch 51 | LR: 0.01 | Total loss: 427.16 | Epoch time 0.18\n",
      "Epoch 52 | LR: 0.01 | Total loss: 427.33 | Epoch time 0.17\n",
      "Epoch 53 | LR: 0.01 | Total loss: 426.77 | Epoch time 0.19\n",
      "Epoch 54 | LR: 0.01 | Total loss: 426.70 | Epoch time 0.16\n",
      "Epoch 55 | LR: 0.01 | Total loss: 426.39 | Epoch time 0.21\n",
      "Epoch 56 | LR: 0.01 | Total loss: 426.32 | Epoch time 0.16\n",
      "Epoch 57 | LR: 0.01 | Total loss: 426.22 | Epoch time 0.17\n",
      "Epoch 58 | LR: 0.01 | Total loss: 426.56 | Epoch time 0.16\n",
      "Epoch 59 | LR: 0.01 | Total loss: 425.92 | Epoch time 0.16\n",
      "Epoch 60 | LR: 0.01 | Total loss: 425.83 | Epoch time 0.09\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #18 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 760.84 | Epoch time 0.09\n",
      "Epoch 2 | LR: 0.10 | Total loss: 625.97 | Epoch time 0.11\n",
      "Epoch 3 | LR: 0.10 | Total loss: 597.06 | Epoch time 0.09\n",
      "Epoch 4 | LR: 0.10 | Total loss: 576.33 | Epoch time 0.10\n",
      "Epoch 5 | LR: 0.10 | Total loss: 557.80 | Epoch time 0.12\n",
      "Epoch 6 | LR: 0.10 | Total loss: 539.96 | Epoch time 0.10\n",
      "Epoch 7 | LR: 0.10 | Total loss: 524.75 | Epoch time 0.09\n",
      "Epoch 8 | LR: 0.10 | Total loss: 511.50 | Epoch time 0.11\n",
      "Epoch 9 | LR: 0.10 | Total loss: 500.53 | Epoch time 0.10\n",
      "Epoch 10 | LR: 0.10 | Total loss: 491.13 | Epoch time 0.10\n",
      "Epoch 11 | LR: 0.10 | Total loss: 483.34 | Epoch time 0.11\n",
      "Epoch 12 | LR: 0.10 | Total loss: 476.71 | Epoch time 0.10\n",
      "Epoch 13 | LR: 0.10 | Total loss: 470.99 | Epoch time 0.10\n",
      "Epoch 14 | LR: 0.10 | Total loss: 466.24 | Epoch time 0.12\n",
      "Epoch 15 | LR: 0.10 | Total loss: 461.92 | Epoch time 0.09\n",
      "Epoch 16 | LR: 0.10 | Total loss: 458.21 | Epoch time 0.09\n",
      "Epoch 17 | LR: 0.10 | Total loss: 455.11 | Epoch time 0.11\n",
      "Epoch 18 | LR: 0.10 | Total loss: 452.23 | Epoch time 0.10\n",
      "Epoch 19 | LR: 0.10 | Total loss: 449.80 | Epoch time 0.09\n",
      "Epoch 20 | LR: 0.10 | Total loss: 447.57 | Epoch time 0.11\n",
      "Epoch 21 | LR: 0.05 | Total loss: 445.61 | Epoch time 0.09\n",
      "Epoch 22 | LR: 0.05 | Total loss: 444.04 | Epoch time 0.09\n",
      "Epoch 23 | LR: 0.05 | Total loss: 442.63 | Epoch time 0.11\n",
      "Epoch 24 | LR: 0.05 | Total loss: 440.76 | Epoch time 0.10\n",
      "Epoch 25 | LR: 0.05 | Total loss: 439.69 | Epoch time 0.09\n",
      "Epoch 26 | LR: 0.05 | Total loss: 438.47 | Epoch time 0.11\n",
      "Epoch 27 | LR: 0.05 | Total loss: 437.54 | Epoch time 0.10\n",
      "Epoch 28 | LR: 0.05 | Total loss: 436.68 | Epoch time 0.09\n",
      "Epoch 29 | LR: 0.05 | Total loss: 435.55 | Epoch time 0.11\n",
      "Epoch 30 | LR: 0.05 | Total loss: 434.86 | Epoch time 0.10\n",
      "Epoch 31 | LR: 0.05 | Total loss: 434.30 | Epoch time 0.09\n",
      "Epoch 32 | LR: 0.05 | Total loss: 433.73 | Epoch time 0.12\n",
      "Epoch 33 | LR: 0.05 | Total loss: 432.95 | Epoch time 0.09\n",
      "Epoch 34 | LR: 0.05 | Total loss: 432.73 | Epoch time 0.10\n",
      "Epoch 35 | LR: 0.05 | Total loss: 432.05 | Epoch time 0.11\n",
      "Epoch 36 | LR: 0.05 | Total loss: 431.41 | Epoch time 0.10\n",
      "Epoch 37 | LR: 0.05 | Total loss: 431.02 | Epoch time 0.10\n",
      "Epoch 38 | LR: 0.05 | Total loss: 430.57 | Epoch time 0.12\n",
      "Epoch 39 | LR: 0.05 | Total loss: 430.09 | Epoch time 0.09\n",
      "Epoch 40 | LR: 0.05 | Total loss: 429.94 | Epoch time 0.09\n",
      "Epoch 41 | LR: 0.01 | Total loss: 429.52 | Epoch time 0.11\n",
      "Epoch 42 | LR: 0.01 | Total loss: 429.09 | Epoch time 0.10\n",
      "Epoch 43 | LR: 0.01 | Total loss: 428.78 | Epoch time 0.10\n",
      "Epoch 44 | LR: 0.01 | Total loss: 428.73 | Epoch time 0.12\n",
      "Epoch 45 | LR: 0.01 | Total loss: 428.37 | Epoch time 0.10\n",
      "Epoch 46 | LR: 0.01 | Total loss: 428.08 | Epoch time 0.10\n",
      "Epoch 47 | LR: 0.01 | Total loss: 427.89 | Epoch time 0.11\n",
      "Epoch 48 | LR: 0.01 | Total loss: 427.73 | Epoch time 0.11\n",
      "Epoch 49 | LR: 0.01 | Total loss: 427.23 | Epoch time 0.12\n",
      "Epoch 50 | LR: 0.01 | Total loss: 427.23 | Epoch time 0.09\n",
      "Epoch 51 | LR: 0.01 | Total loss: 427.09 | Epoch time 0.11\n",
      "Epoch 52 | LR: 0.01 | Total loss: 427.20 | Epoch time 0.11\n",
      "Epoch 53 | LR: 0.01 | Total loss: 426.60 | Epoch time 0.12\n",
      "Epoch 54 | LR: 0.01 | Total loss: 426.51 | Epoch time 0.10\n",
      "Epoch 55 | LR: 0.01 | Total loss: 426.27 | Epoch time 0.11\n",
      "Epoch 56 | LR: 0.01 | Total loss: 426.47 | Epoch time 0.11\n",
      "Epoch 57 | LR: 0.01 | Total loss: 426.28 | Epoch time 0.11\n",
      "Epoch 58 | LR: 0.01 | Total loss: 425.86 | Epoch time 0.11\n",
      "Epoch 59 | LR: 0.01 | Total loss: 425.90 | Epoch time 0.12\n",
      "Epoch 60 | LR: 0.01 | Total loss: 425.63 | Epoch time 0.10\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #19 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 769.38 | Epoch time 0.11\n",
      "Epoch 2 | LR: 0.10 | Total loss: 632.04 | Epoch time 0.11\n",
      "Epoch 3 | LR: 0.10 | Total loss: 595.35 | Epoch time 0.10\n",
      "Epoch 4 | LR: 0.10 | Total loss: 567.73 | Epoch time 0.10\n",
      "Epoch 5 | LR: 0.10 | Total loss: 545.62 | Epoch time 0.12\n",
      "Epoch 6 | LR: 0.10 | Total loss: 527.83 | Epoch time 0.10\n",
      "Epoch 7 | LR: 0.10 | Total loss: 513.39 | Epoch time 0.09\n",
      "Epoch 8 | LR: 0.10 | Total loss: 501.63 | Epoch time 0.12\n",
      "Epoch 9 | LR: 0.10 | Total loss: 491.80 | Epoch time 0.10\n",
      "Epoch 10 | LR: 0.10 | Total loss: 483.99 | Epoch time 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | LR: 0.10 | Total loss: 477.17 | Epoch time 0.12\n",
      "Epoch 12 | LR: 0.10 | Total loss: 471.55 | Epoch time 0.11\n",
      "Epoch 13 | LR: 0.10 | Total loss: 466.82 | Epoch time 0.11\n",
      "Epoch 14 | LR: 0.10 | Total loss: 462.68 | Epoch time 0.11\n",
      "Epoch 15 | LR: 0.10 | Total loss: 458.82 | Epoch time 0.12\n",
      "Epoch 16 | LR: 0.10 | Total loss: 456.17 | Epoch time 0.11\n",
      "Epoch 17 | LR: 0.10 | Total loss: 453.37 | Epoch time 0.09\n",
      "Epoch 18 | LR: 0.10 | Total loss: 451.38 | Epoch time 0.11\n",
      "Epoch 19 | LR: 0.10 | Total loss: 448.71 | Epoch time 0.10\n",
      "Epoch 20 | LR: 0.10 | Total loss: 446.89 | Epoch time 0.10\n",
      "Epoch 21 | LR: 0.05 | Total loss: 445.31 | Epoch time 0.12\n",
      "Epoch 22 | LR: 0.05 | Total loss: 444.06 | Epoch time 0.11\n",
      "Epoch 23 | LR: 0.05 | Total loss: 442.66 | Epoch time 0.11\n",
      "Epoch 24 | LR: 0.05 | Total loss: 441.45 | Epoch time 0.10\n",
      "Epoch 25 | LR: 0.05 | Total loss: 440.17 | Epoch time 0.10\n",
      "Epoch 26 | LR: 0.05 | Total loss: 439.11 | Epoch time 0.11\n",
      "Epoch 27 | LR: 0.05 | Total loss: 438.57 | Epoch time 0.11\n",
      "Epoch 28 | LR: 0.05 | Total loss: 437.43 | Epoch time 0.11\n",
      "Epoch 29 | LR: 0.05 | Total loss: 436.83 | Epoch time 0.12\n",
      "Epoch 30 | LR: 0.05 | Total loss: 435.93 | Epoch time 0.11\n",
      "Epoch 31 | LR: 0.05 | Total loss: 435.39 | Epoch time 0.11\n",
      "Epoch 32 | LR: 0.05 | Total loss: 434.86 | Epoch time 0.11\n",
      "Epoch 33 | LR: 0.05 | Total loss: 434.25 | Epoch time 0.10\n",
      "Epoch 34 | LR: 0.05 | Total loss: 433.35 | Epoch time 0.11\n",
      "Epoch 35 | LR: 0.05 | Total loss: 433.00 | Epoch time 0.11\n",
      "Epoch 36 | LR: 0.05 | Total loss: 432.45 | Epoch time 0.11\n",
      "Epoch 37 | LR: 0.05 | Total loss: 432.24 | Epoch time 0.10\n",
      "Epoch 38 | LR: 0.05 | Total loss: 431.73 | Epoch time 0.11\n",
      "Epoch 39 | LR: 0.05 | Total loss: 431.33 | Epoch time 0.11\n",
      "Epoch 40 | LR: 0.05 | Total loss: 430.70 | Epoch time 0.11\n",
      "Epoch 41 | LR: 0.01 | Total loss: 430.53 | Epoch time 0.12\n",
      "Epoch 42 | LR: 0.01 | Total loss: 430.15 | Epoch time 0.19\n",
      "Epoch 43 | LR: 0.01 | Total loss: 430.12 | Epoch time 0.20\n",
      "Epoch 44 | LR: 0.01 | Total loss: 429.52 | Epoch time 0.17\n",
      "Epoch 45 | LR: 0.01 | Total loss: 429.34 | Epoch time 0.13\n",
      "Epoch 46 | LR: 0.01 | Total loss: 429.05 | Epoch time 0.11\n",
      "Epoch 47 | LR: 0.01 | Total loss: 428.72 | Epoch time 0.17\n",
      "Epoch 48 | LR: 0.01 | Total loss: 428.73 | Epoch time 0.19\n",
      "Epoch 49 | LR: 0.01 | Total loss: 428.26 | Epoch time 0.20\n",
      "Epoch 50 | LR: 0.01 | Total loss: 428.30 | Epoch time 0.16\n",
      "Epoch 51 | LR: 0.01 | Total loss: 427.80 | Epoch time 0.13\n",
      "Epoch 52 | LR: 0.01 | Total loss: 427.73 | Epoch time 0.11\n",
      "Epoch 53 | LR: 0.01 | Total loss: 427.41 | Epoch time 0.10\n",
      "Epoch 54 | LR: 0.01 | Total loss: 427.29 | Epoch time 0.11\n",
      "Epoch 55 | LR: 0.01 | Total loss: 427.31 | Epoch time 0.11\n",
      "Epoch 56 | LR: 0.01 | Total loss: 426.94 | Epoch time 0.11\n",
      "Epoch 57 | LR: 0.01 | Total loss: 426.97 | Epoch time 0.09\n",
      "Epoch 58 | LR: 0.01 | Total loss: 426.52 | Epoch time 0.13\n",
      "Epoch 59 | LR: 0.01 | Total loss: 426.67 | Epoch time 0.11\n",
      "Epoch 60 | LR: 0.01 | Total loss: 426.30 | Epoch time 0.11\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #20 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 775.31 | Epoch time 0.13\n",
      "Epoch 2 | LR: 0.10 | Total loss: 637.25 | Epoch time 0.13\n",
      "Epoch 3 | LR: 0.10 | Total loss: 599.87 | Epoch time 0.11\n",
      "Epoch 4 | LR: 0.10 | Total loss: 572.70 | Epoch time 0.17\n",
      "Epoch 5 | LR: 0.10 | Total loss: 550.72 | Epoch time 0.13\n",
      "Epoch 6 | LR: 0.10 | Total loss: 533.16 | Epoch time 0.11\n",
      "Epoch 7 | LR: 0.10 | Total loss: 518.89 | Epoch time 0.21\n",
      "Epoch 8 | LR: 0.10 | Total loss: 506.76 | Epoch time 0.16\n",
      "Epoch 9 | LR: 0.10 | Total loss: 496.63 | Epoch time 0.18\n",
      "Epoch 10 | LR: 0.10 | Total loss: 488.17 | Epoch time 0.17\n",
      "Epoch 11 | LR: 0.10 | Total loss: 481.28 | Epoch time 0.17\n",
      "Epoch 12 | LR: 0.10 | Total loss: 475.01 | Epoch time 0.16\n",
      "Epoch 13 | LR: 0.10 | Total loss: 469.77 | Epoch time 0.16\n",
      "Epoch 14 | LR: 0.10 | Total loss: 465.22 | Epoch time 0.16\n",
      "Epoch 15 | LR: 0.10 | Total loss: 461.56 | Epoch time 0.18\n",
      "Epoch 16 | LR: 0.10 | Total loss: 457.86 | Epoch time 0.10\n",
      "Epoch 17 | LR: 0.10 | Total loss: 455.01 | Epoch time 0.10\n",
      "Epoch 18 | LR: 0.10 | Total loss: 452.67 | Epoch time 0.14\n",
      "Epoch 19 | LR: 0.10 | Total loss: 450.02 | Epoch time 0.14\n",
      "Epoch 20 | LR: 0.10 | Total loss: 448.10 | Epoch time 0.17\n",
      "Epoch 21 | LR: 0.05 | Total loss: 446.14 | Epoch time 0.16\n",
      "Epoch 22 | LR: 0.05 | Total loss: 444.69 | Epoch time 0.16\n",
      "Epoch 23 | LR: 0.05 | Total loss: 443.07 | Epoch time 0.17\n",
      "Epoch 24 | LR: 0.05 | Total loss: 441.70 | Epoch time 0.19\n",
      "Epoch 25 | LR: 0.05 | Total loss: 440.52 | Epoch time 0.15\n",
      "Epoch 26 | LR: 0.05 | Total loss: 439.71 | Epoch time 0.14\n",
      "Epoch 27 | LR: 0.05 | Total loss: 438.30 | Epoch time 0.10\n",
      "Epoch 28 | LR: 0.05 | Total loss: 437.28 | Epoch time 0.10\n",
      "Epoch 29 | LR: 0.05 | Total loss: 436.43 | Epoch time 0.12\n",
      "Epoch 30 | LR: 0.05 | Total loss: 436.11 | Epoch time 0.10\n",
      "Epoch 31 | LR: 0.05 | Total loss: 434.96 | Epoch time 0.09\n",
      "Epoch 32 | LR: 0.05 | Total loss: 434.57 | Epoch time 0.11\n",
      "Epoch 33 | LR: 0.05 | Total loss: 433.83 | Epoch time 0.09\n",
      "Epoch 34 | LR: 0.05 | Total loss: 433.47 | Epoch time 0.09\n",
      "Epoch 35 | LR: 0.05 | Total loss: 432.76 | Epoch time 0.11\n",
      "Epoch 36 | LR: 0.05 | Total loss: 432.11 | Epoch time 0.09\n",
      "Epoch 37 | LR: 0.05 | Total loss: 431.91 | Epoch time 0.09\n",
      "Epoch 38 | LR: 0.05 | Total loss: 431.32 | Epoch time 0.11\n",
      "Epoch 39 | LR: 0.05 | Total loss: 430.88 | Epoch time 0.10\n",
      "Epoch 40 | LR: 0.05 | Total loss: 430.54 | Epoch time 0.09\n",
      "Epoch 41 | LR: 0.01 | Total loss: 430.20 | Epoch time 0.11\n",
      "Epoch 42 | LR: 0.01 | Total loss: 430.10 | Epoch time 0.13\n",
      "Epoch 43 | LR: 0.01 | Total loss: 429.70 | Epoch time 0.19\n",
      "Epoch 44 | LR: 0.01 | Total loss: 429.09 | Epoch time 0.16\n",
      "Epoch 45 | LR: 0.01 | Total loss: 429.00 | Epoch time 0.18\n",
      "Epoch 46 | LR: 0.01 | Total loss: 429.06 | Epoch time 0.14\n",
      "Epoch 47 | LR: 0.01 | Total loss: 428.46 | Epoch time 0.17\n",
      "Epoch 48 | LR: 0.01 | Total loss: 428.37 | Epoch time 0.18\n",
      "Epoch 49 | LR: 0.01 | Total loss: 428.17 | Epoch time 0.16\n",
      "Epoch 50 | LR: 0.01 | Total loss: 427.84 | Epoch time 0.12\n",
      "Epoch 51 | LR: 0.01 | Total loss: 427.70 | Epoch time 0.10\n",
      "Epoch 52 | LR: 0.01 | Total loss: 427.21 | Epoch time 0.16\n",
      "Epoch 53 | LR: 0.01 | Total loss: 427.19 | Epoch time 0.21\n",
      "Epoch 54 | LR: 0.01 | Total loss: 427.25 | Epoch time 0.17\n",
      "Epoch 55 | LR: 0.01 | Total loss: 426.99 | Epoch time 0.18\n",
      "Epoch 56 | LR: 0.01 | Total loss: 426.47 | Epoch time 0.16\n",
      "Epoch 57 | LR: 0.01 | Total loss: 426.54 | Epoch time 0.19\n",
      "Epoch 58 | LR: 0.01 | Total loss: 426.77 | Epoch time 0.15\n",
      "Epoch 59 | LR: 0.01 | Total loss: 426.48 | Epoch time 0.16\n",
      "Epoch 60 | LR: 0.01 | Total loss: 426.07 | Epoch time 0.18\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theta_p = torch.ones([num_classes])*5\n",
    "w_p = torch.tensor([\n",
    "        [[9., 1.], [1., 9.]],\n",
    "        [[1., 9.], [9., 1.]]\n",
    "        ])\n",
    "\n",
    "dataloader = DataLoader(EdgesDataset(A.float()), \n",
    "                        batch_size=N, shuffle=True, num_workers=0)\n",
    "\n",
    "vi = VI_SBM(num_nodes=N, num_classes=num_classes, \n",
    "                   priors={'theta_p':theta_p, \n",
    "                           'B_p':w_p},\n",
    "                   init_values={'etas':None, \n",
    "                                'thetas':None, \n",
    "                                'Bs':None})\n",
    "vi.multi_train(dataloader, epochs=20, lrs = [0.1, 0.05, 0.01], trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = vi.get_multi_losses()[:,-1].argmin()   # With the smallest loss ar the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi.load_state_dict(vi.state_dicts[best_trial])      # Load the parameters from the best trial\n",
    "q_eta, q_theta, q_B = vi.constrained_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7551, 0.2449])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.multi_results[1][best_trial]                     # Class probability of the best trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True class probabilities: tensor([0.5294, 0.4706])\n"
     ]
    }
   ],
   "source": [
    "print('True class probabilities:', z_true.sum(dim=0).float()/34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the standard SBM struggles to find the correct class probabilities $\\theta$. Let us look at the accuracy of the class assignments in all trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5588235259056091\n",
      "0.5588235259056091\n",
      "0.5588235259056091\n",
      "0.5588235259056091\n",
      "0.529411792755127\n",
      "0.5588235259056091\n",
      "0.5588235259056091\n",
      "0.5588235259056091\n",
      "0.5588235259056091\n",
      "0.5588235259056091\n",
      "0.5588235259056091\n",
      "0.5588235259056091\n",
      "0.5588235259056091\n",
      "0.5588235259056091\n",
      "0.5588235259056091\n",
      "0.5588235259056091\n",
      "0.5588235259056091\n",
      "0.5588235259056091\n",
      "0.5588235259056091\n",
      "0.5588235259056091\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(vi.multi_results[0])):\n",
    "    print(vi.class_accuracy(z_true,vi.multi_results[0][i]).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that the standart SBM does not suit for this task. Next, we try the DCSBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCSBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the same prior as for the SBM. As in the preivious examples we initialize $\\delta$ with the observed degree distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_p = torch.ones([num_classes])*5\n",
    "w_p = torch.tensor([\n",
    "        [[9., 1.], [1., 9.]],\n",
    "        [[1., 9.], [9., 1.]]\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains infinities: False\n"
     ]
    }
   ],
   "source": [
    "delta_init = torch.ones([N,2])\n",
    "delta_mu = A.sum(dim=1)/A.sum(dim=1).mean()\n",
    "delta_init[:,0]=delta_mu.log().clone()\n",
    "print('Contains infinities:', bool(torch.isinf(delta_init).sum().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>> Training iteration #1 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/mo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning:To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | LR: 0.10 | Total loss: 492.14 | Epoch time 0.35\n",
      "Epoch 2 | LR: 0.10 | Total loss: 455.81 | Epoch time 0.24\n",
      "Epoch 3 | LR: 0.10 | Total loss: 444.23 | Epoch time 0.35\n",
      "Epoch 4 | LR: 0.10 | Total loss: 437.11 | Epoch time 0.30\n",
      "Epoch 5 | LR: 0.10 | Total loss: 429.21 | Epoch time 0.31\n",
      "Epoch 6 | LR: 0.10 | Total loss: 433.13 | Epoch time 0.18\n",
      "Epoch 7 | LR: 0.10 | Total loss: 426.01 | Epoch time 0.21\n",
      "Epoch 8 | LR: 0.10 | Total loss: 429.96 | Epoch time 0.16\n",
      "Epoch 9 | LR: 0.10 | Total loss: 426.99 | Epoch time 0.20\n",
      "Epoch 10 | LR: 0.10 | Total loss: 426.38 | Epoch time 0.17\n",
      "Epoch 11 | LR: 0.10 | Total loss: 422.59 | Epoch time 0.20\n",
      "Epoch 12 | LR: 0.10 | Total loss: 423.63 | Epoch time 0.17\n",
      "Epoch 13 | LR: 0.10 | Total loss: 423.27 | Epoch time 0.20\n",
      "Epoch 14 | LR: 0.10 | Total loss: 424.38 | Epoch time 0.16\n",
      "Epoch 15 | LR: 0.10 | Total loss: 418.90 | Epoch time 0.25\n",
      "Epoch 16 | LR: 0.10 | Total loss: 419.93 | Epoch time 0.16\n",
      "Epoch 17 | LR: 0.10 | Total loss: 413.22 | Epoch time 0.19\n",
      "Epoch 18 | LR: 0.10 | Total loss: 408.45 | Epoch time 0.17\n",
      "Epoch 19 | LR: 0.10 | Total loss: 399.21 | Epoch time 0.19\n",
      "Epoch 20 | LR: 0.10 | Total loss: 395.45 | Epoch time 0.18\n",
      "Epoch 21 | LR: 0.05 | Total loss: 394.15 | Epoch time 0.19\n",
      "Epoch 22 | LR: 0.05 | Total loss: 386.58 | Epoch time 0.16\n",
      "Epoch 23 | LR: 0.05 | Total loss: 380.45 | Epoch time 0.18\n",
      "Epoch 24 | LR: 0.05 | Total loss: 381.04 | Epoch time 0.17\n",
      "Epoch 25 | LR: 0.05 | Total loss: 378.84 | Epoch time 0.17\n",
      "Epoch 26 | LR: 0.05 | Total loss: 370.50 | Epoch time 0.17\n",
      "Epoch 27 | LR: 0.05 | Total loss: 373.06 | Epoch time 0.19\n",
      "Epoch 28 | LR: 0.05 | Total loss: 367.89 | Epoch time 0.17\n",
      "Epoch 29 | LR: 0.05 | Total loss: 365.60 | Epoch time 0.18\n",
      "Epoch 30 | LR: 0.05 | Total loss: 364.72 | Epoch time 0.17\n",
      "Epoch 31 | LR: 0.05 | Total loss: 365.57 | Epoch time 0.19\n",
      "Epoch 32 | LR: 0.05 | Total loss: 363.14 | Epoch time 0.15\n",
      "Epoch 33 | LR: 0.05 | Total loss: 360.89 | Epoch time 0.19\n",
      "Epoch 34 | LR: 0.05 | Total loss: 361.02 | Epoch time 0.17\n",
      "Epoch 35 | LR: 0.05 | Total loss: 358.47 | Epoch time 0.19\n",
      "Epoch 36 | LR: 0.05 | Total loss: 358.30 | Epoch time 0.15\n",
      "Epoch 37 | LR: 0.05 | Total loss: 358.06 | Epoch time 0.18\n",
      "Epoch 38 | LR: 0.05 | Total loss: 358.06 | Epoch time 0.18\n",
      "Epoch 39 | LR: 0.05 | Total loss: 357.87 | Epoch time 0.19\n",
      "Epoch 40 | LR: 0.05 | Total loss: 357.85 | Epoch time 0.16\n",
      "Epoch 41 | LR: 0.01 | Total loss: 355.48 | Epoch time 0.18\n",
      "Epoch 42 | LR: 0.01 | Total loss: 356.62 | Epoch time 0.16\n",
      "Epoch 43 | LR: 0.01 | Total loss: 356.02 | Epoch time 0.18\n",
      "Epoch 44 | LR: 0.01 | Total loss: 356.40 | Epoch time 0.17\n",
      "Epoch 45 | LR: 0.01 | Total loss: 352.80 | Epoch time 0.19\n",
      "Epoch 46 | LR: 0.01 | Total loss: 359.13 | Epoch time 0.17\n",
      "Epoch 47 | LR: 0.01 | Total loss: 351.97 | Epoch time 0.17\n",
      "Epoch 48 | LR: 0.01 | Total loss: 355.96 | Epoch time 0.16\n",
      "Epoch 49 | LR: 0.01 | Total loss: 353.87 | Epoch time 0.17\n",
      "Epoch 50 | LR: 0.01 | Total loss: 353.73 | Epoch time 0.17\n",
      "Epoch 51 | LR: 0.01 | Total loss: 353.17 | Epoch time 0.18\n",
      "Epoch 52 | LR: 0.01 | Total loss: 354.27 | Epoch time 0.16\n",
      "Epoch 53 | LR: 0.01 | Total loss: 352.74 | Epoch time 0.17\n",
      "Epoch 54 | LR: 0.01 | Total loss: 360.42 | Epoch time 0.16\n",
      "Epoch 55 | LR: 0.01 | Total loss: 355.99 | Epoch time 0.18\n",
      "Epoch 56 | LR: 0.01 | Total loss: 356.37 | Epoch time 0.17\n",
      "Epoch 57 | LR: 0.01 | Total loss: 354.10 | Epoch time 0.18\n",
      "Epoch 58 | LR: 0.01 | Total loss: 355.30 | Epoch time 0.17\n",
      "Epoch 59 | LR: 0.01 | Total loss: 353.32 | Epoch time 0.18\n",
      "Epoch 60 | LR: 0.01 | Total loss: 356.92 | Epoch time 0.16\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #2 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 452.38 | Epoch time 0.18\n",
      "Epoch 2 | LR: 0.10 | Total loss: 434.71 | Epoch time 0.16\n",
      "Epoch 3 | LR: 0.10 | Total loss: 435.16 | Epoch time 0.18\n",
      "Epoch 4 | LR: 0.10 | Total loss: 429.33 | Epoch time 0.15\n",
      "Epoch 5 | LR: 0.10 | Total loss: 428.92 | Epoch time 0.18\n",
      "Epoch 6 | LR: 0.10 | Total loss: 423.98 | Epoch time 0.17\n",
      "Epoch 7 | LR: 0.10 | Total loss: 425.42 | Epoch time 0.17\n",
      "Epoch 8 | LR: 0.10 | Total loss: 418.70 | Epoch time 0.17\n",
      "Epoch 9 | LR: 0.10 | Total loss: 413.68 | Epoch time 0.18\n",
      "Epoch 10 | LR: 0.10 | Total loss: 410.52 | Epoch time 0.15\n",
      "Epoch 11 | LR: 0.10 | Total loss: 403.85 | Epoch time 0.18\n",
      "Epoch 12 | LR: 0.10 | Total loss: 397.71 | Epoch time 0.17\n",
      "Epoch 13 | LR: 0.10 | Total loss: 389.48 | Epoch time 0.18\n",
      "Epoch 14 | LR: 0.10 | Total loss: 388.85 | Epoch time 0.16\n",
      "Epoch 15 | LR: 0.10 | Total loss: 386.01 | Epoch time 0.18\n",
      "Epoch 16 | LR: 0.10 | Total loss: 380.32 | Epoch time 0.15\n",
      "Epoch 17 | LR: 0.10 | Total loss: 376.91 | Epoch time 0.18\n",
      "Epoch 18 | LR: 0.10 | Total loss: 373.87 | Epoch time 0.16\n",
      "Epoch 19 | LR: 0.10 | Total loss: 368.83 | Epoch time 0.18\n",
      "Epoch 20 | LR: 0.10 | Total loss: 368.01 | Epoch time 0.16\n",
      "Epoch 21 | LR: 0.05 | Total loss: 368.84 | Epoch time 0.17\n",
      "Epoch 22 | LR: 0.05 | Total loss: 366.78 | Epoch time 0.15\n",
      "Epoch 23 | LR: 0.05 | Total loss: 363.89 | Epoch time 0.18\n",
      "Epoch 24 | LR: 0.05 | Total loss: 362.96 | Epoch time 0.16\n",
      "Epoch 25 | LR: 0.05 | Total loss: 363.38 | Epoch time 0.17\n",
      "Epoch 26 | LR: 0.05 | Total loss: 358.23 | Epoch time 0.16\n",
      "Epoch 27 | LR: 0.05 | Total loss: 357.71 | Epoch time 0.18\n",
      "Epoch 28 | LR: 0.05 | Total loss: 362.03 | Epoch time 0.15\n",
      "Epoch 29 | LR: 0.05 | Total loss: 359.01 | Epoch time 0.17\n",
      "Epoch 30 | LR: 0.05 | Total loss: 363.55 | Epoch time 0.15\n",
      "Epoch 31 | LR: 0.05 | Total loss: 358.46 | Epoch time 0.18\n",
      "Epoch 32 | LR: 0.05 | Total loss: 356.81 | Epoch time 0.17\n",
      "Epoch 33 | LR: 0.05 | Total loss: 359.31 | Epoch time 0.18\n",
      "Epoch 34 | LR: 0.05 | Total loss: 354.85 | Epoch time 0.15\n",
      "Epoch 35 | LR: 0.05 | Total loss: 358.64 | Epoch time 0.18\n",
      "Epoch 36 | LR: 0.05 | Total loss: 352.97 | Epoch time 0.17\n",
      "Epoch 37 | LR: 0.05 | Total loss: 356.60 | Epoch time 0.17\n",
      "Epoch 38 | LR: 0.05 | Total loss: 357.94 | Epoch time 0.17\n",
      "Epoch 39 | LR: 0.05 | Total loss: 354.57 | Epoch time 0.18\n",
      "Epoch 40 | LR: 0.05 | Total loss: 355.67 | Epoch time 0.16\n",
      "Epoch 41 | LR: 0.01 | Total loss: 356.79 | Epoch time 0.18\n",
      "Epoch 42 | LR: 0.01 | Total loss: 355.43 | Epoch time 0.16\n",
      "Epoch 43 | LR: 0.01 | Total loss: 357.85 | Epoch time 0.18\n",
      "Epoch 44 | LR: 0.01 | Total loss: 356.70 | Epoch time 0.16\n",
      "Epoch 45 | LR: 0.01 | Total loss: 352.74 | Epoch time 0.18\n",
      "Epoch 46 | LR: 0.01 | Total loss: 357.05 | Epoch time 0.17\n",
      "Epoch 47 | LR: 0.01 | Total loss: 351.46 | Epoch time 0.17\n",
      "Epoch 48 | LR: 0.01 | Total loss: 354.55 | Epoch time 0.16\n",
      "Epoch 49 | LR: 0.01 | Total loss: 354.17 | Epoch time 0.19\n",
      "Epoch 50 | LR: 0.01 | Total loss: 354.86 | Epoch time 0.17\n",
      "Epoch 51 | LR: 0.01 | Total loss: 354.45 | Epoch time 0.18\n",
      "Epoch 52 | LR: 0.01 | Total loss: 356.44 | Epoch time 0.16\n",
      "Epoch 53 | LR: 0.01 | Total loss: 353.88 | Epoch time 0.18\n",
      "Epoch 54 | LR: 0.01 | Total loss: 354.78 | Epoch time 0.16\n",
      "Epoch 55 | LR: 0.01 | Total loss: 352.51 | Epoch time 0.19\n",
      "Epoch 56 | LR: 0.01 | Total loss: 357.46 | Epoch time 0.16\n",
      "Epoch 57 | LR: 0.01 | Total loss: 354.04 | Epoch time 0.18\n",
      "Epoch 58 | LR: 0.01 | Total loss: 356.53 | Epoch time 0.17\n",
      "Epoch 59 | LR: 0.01 | Total loss: 353.67 | Epoch time 0.18\n",
      "Epoch 60 | LR: 0.01 | Total loss: 354.96 | Epoch time 0.16\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #3 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 455.95 | Epoch time 0.18\n",
      "Epoch 2 | LR: 0.10 | Total loss: 436.25 | Epoch time 0.17\n",
      "Epoch 3 | LR: 0.10 | Total loss: 434.87 | Epoch time 0.18\n",
      "Epoch 4 | LR: 0.10 | Total loss: 431.00 | Epoch time 0.16\n",
      "Epoch 5 | LR: 0.10 | Total loss: 428.40 | Epoch time 0.18\n",
      "Epoch 6 | LR: 0.10 | Total loss: 429.69 | Epoch time 0.16\n",
      "Epoch 7 | LR: 0.10 | Total loss: 429.63 | Epoch time 0.19\n",
      "Epoch 8 | LR: 0.10 | Total loss: 422.94 | Epoch time 0.16\n",
      "Epoch 9 | LR: 0.10 | Total loss: 423.06 | Epoch time 0.18\n",
      "Epoch 10 | LR: 0.10 | Total loss: 421.64 | Epoch time 0.17\n",
      "Epoch 11 | LR: 0.10 | Total loss: 417.32 | Epoch time 0.18\n",
      "Epoch 12 | LR: 0.10 | Total loss: 414.51 | Epoch time 0.16\n",
      "Epoch 13 | LR: 0.10 | Total loss: 409.28 | Epoch time 0.20\n",
      "Epoch 14 | LR: 0.10 | Total loss: 401.44 | Epoch time 0.16\n",
      "Epoch 15 | LR: 0.10 | Total loss: 399.90 | Epoch time 0.18\n",
      "Epoch 16 | LR: 0.10 | Total loss: 390.47 | Epoch time 0.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | LR: 0.10 | Total loss: 388.39 | Epoch time 0.24\n",
      "Epoch 18 | LR: 0.10 | Total loss: 383.09 | Epoch time 0.16\n",
      "Epoch 19 | LR: 0.10 | Total loss: 379.46 | Epoch time 0.19\n",
      "Epoch 20 | LR: 0.10 | Total loss: 370.07 | Epoch time 0.16\n",
      "Epoch 21 | LR: 0.05 | Total loss: 374.76 | Epoch time 0.17\n",
      "Epoch 22 | LR: 0.05 | Total loss: 369.96 | Epoch time 0.16\n",
      "Epoch 23 | LR: 0.05 | Total loss: 366.94 | Epoch time 0.19\n",
      "Epoch 24 | LR: 0.05 | Total loss: 365.02 | Epoch time 0.16\n",
      "Epoch 25 | LR: 0.05 | Total loss: 360.59 | Epoch time 0.18\n",
      "Epoch 26 | LR: 0.05 | Total loss: 365.70 | Epoch time 0.17\n",
      "Epoch 27 | LR: 0.05 | Total loss: 361.01 | Epoch time 0.18\n",
      "Epoch 28 | LR: 0.05 | Total loss: 364.70 | Epoch time 0.16\n",
      "Epoch 29 | LR: 0.05 | Total loss: 360.82 | Epoch time 0.18\n",
      "Epoch 30 | LR: 0.05 | Total loss: 361.97 | Epoch time 0.17\n",
      "Epoch 31 | LR: 0.05 | Total loss: 360.74 | Epoch time 0.18\n",
      "Epoch 32 | LR: 0.05 | Total loss: 358.44 | Epoch time 0.16\n",
      "Epoch 33 | LR: 0.05 | Total loss: 358.61 | Epoch time 0.18\n",
      "Epoch 34 | LR: 0.05 | Total loss: 355.71 | Epoch time 0.16\n",
      "Epoch 35 | LR: 0.05 | Total loss: 357.69 | Epoch time 0.17\n",
      "Epoch 36 | LR: 0.05 | Total loss: 356.76 | Epoch time 0.18\n",
      "Epoch 37 | LR: 0.05 | Total loss: 360.07 | Epoch time 0.18\n",
      "Epoch 38 | LR: 0.05 | Total loss: 356.91 | Epoch time 0.16\n",
      "Epoch 39 | LR: 0.05 | Total loss: 354.71 | Epoch time 0.18\n",
      "Epoch 40 | LR: 0.05 | Total loss: 359.51 | Epoch time 0.16\n",
      "Epoch 41 | LR: 0.01 | Total loss: 355.73 | Epoch time 0.18\n",
      "Epoch 42 | LR: 0.01 | Total loss: 359.43 | Epoch time 0.23\n",
      "Epoch 43 | LR: 0.01 | Total loss: 357.79 | Epoch time 0.31\n",
      "Epoch 44 | LR: 0.01 | Total loss: 356.17 | Epoch time 0.17\n",
      "Epoch 45 | LR: 0.01 | Total loss: 352.39 | Epoch time 0.29\n",
      "Epoch 46 | LR: 0.01 | Total loss: 356.33 | Epoch time 0.31\n",
      "Epoch 47 | LR: 0.01 | Total loss: 355.29 | Epoch time 0.32\n",
      "Epoch 48 | LR: 0.01 | Total loss: 357.05 | Epoch time 0.31\n",
      "Epoch 49 | LR: 0.01 | Total loss: 354.16 | Epoch time 0.30\n",
      "Epoch 50 | LR: 0.01 | Total loss: 354.42 | Epoch time 0.29\n",
      "Epoch 51 | LR: 0.01 | Total loss: 352.97 | Epoch time 0.26\n",
      "Epoch 52 | LR: 0.01 | Total loss: 352.88 | Epoch time 0.18\n",
      "Epoch 53 | LR: 0.01 | Total loss: 353.26 | Epoch time 0.29\n",
      "Epoch 54 | LR: 0.01 | Total loss: 352.40 | Epoch time 0.28\n",
      "Epoch 55 | LR: 0.01 | Total loss: 353.88 | Epoch time 0.30\n",
      "Epoch 56 | LR: 0.01 | Total loss: 354.50 | Epoch time 0.31\n",
      "Epoch 57 | LR: 0.01 | Total loss: 355.30 | Epoch time 0.30\n",
      "Epoch 58 | LR: 0.01 | Total loss: 354.19 | Epoch time 0.29\n",
      "Epoch 59 | LR: 0.01 | Total loss: 355.88 | Epoch time 0.15\n",
      "Epoch 60 | LR: 0.01 | Total loss: 350.87 | Epoch time 0.18\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #4 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 462.70 | Epoch time 0.15\n",
      "Epoch 2 | LR: 0.10 | Total loss: 442.48 | Epoch time 0.18\n",
      "Epoch 3 | LR: 0.10 | Total loss: 436.30 | Epoch time 0.16\n",
      "Epoch 4 | LR: 0.10 | Total loss: 438.35 | Epoch time 0.18\n",
      "Epoch 5 | LR: 0.10 | Total loss: 432.69 | Epoch time 0.16\n",
      "Epoch 6 | LR: 0.10 | Total loss: 431.25 | Epoch time 0.19\n",
      "Epoch 7 | LR: 0.10 | Total loss: 424.31 | Epoch time 0.17\n",
      "Epoch 8 | LR: 0.10 | Total loss: 426.07 | Epoch time 0.17\n",
      "Epoch 9 | LR: 0.10 | Total loss: 423.91 | Epoch time 0.19\n",
      "Epoch 10 | LR: 0.10 | Total loss: 422.89 | Epoch time 0.18\n",
      "Epoch 11 | LR: 0.10 | Total loss: 425.49 | Epoch time 0.16\n",
      "Epoch 12 | LR: 0.10 | Total loss: 420.95 | Epoch time 0.19\n",
      "Epoch 13 | LR: 0.10 | Total loss: 424.88 | Epoch time 0.15\n",
      "Epoch 14 | LR: 0.10 | Total loss: 423.69 | Epoch time 0.18\n",
      "Epoch 15 | LR: 0.10 | Total loss: 420.99 | Epoch time 0.15\n",
      "Epoch 16 | LR: 0.10 | Total loss: 420.75 | Epoch time 0.18\n",
      "Epoch 17 | LR: 0.10 | Total loss: 417.70 | Epoch time 0.28\n",
      "Epoch 18 | LR: 0.10 | Total loss: 420.96 | Epoch time 0.30\n",
      "Epoch 19 | LR: 0.10 | Total loss: 418.33 | Epoch time 0.32\n",
      "Epoch 20 | LR: 0.10 | Total loss: 421.71 | Epoch time 0.30\n",
      "Epoch 21 | LR: 0.05 | Total loss: 422.34 | Epoch time 0.31\n",
      "Epoch 22 | LR: 0.05 | Total loss: 419.66 | Epoch time 0.21\n",
      "Epoch 23 | LR: 0.05 | Total loss: 421.51 | Epoch time 0.27\n",
      "Epoch 24 | LR: 0.05 | Total loss: 412.23 | Epoch time 0.28\n",
      "Epoch 25 | LR: 0.05 | Total loss: 419.24 | Epoch time 0.29\n",
      "Epoch 26 | LR: 0.05 | Total loss: 414.57 | Epoch time 0.32\n",
      "Epoch 27 | LR: 0.05 | Total loss: 415.66 | Epoch time 0.27\n",
      "Epoch 28 | LR: 0.05 | Total loss: 413.86 | Epoch time 0.17\n",
      "Epoch 29 | LR: 0.05 | Total loss: 413.36 | Epoch time 0.19\n",
      "Epoch 30 | LR: 0.05 | Total loss: 413.65 | Epoch time 0.16\n",
      "Epoch 31 | LR: 0.05 | Total loss: 409.34 | Epoch time 0.18\n",
      "Epoch 32 | LR: 0.05 | Total loss: 404.47 | Epoch time 0.16\n",
      "Epoch 33 | LR: 0.05 | Total loss: 401.33 | Epoch time 0.19\n",
      "Epoch 34 | LR: 0.05 | Total loss: 397.84 | Epoch time 0.17\n",
      "Epoch 35 | LR: 0.05 | Total loss: 390.71 | Epoch time 0.17\n",
      "Epoch 36 | LR: 0.05 | Total loss: 390.19 | Epoch time 0.16\n",
      "Epoch 37 | LR: 0.05 | Total loss: 384.87 | Epoch time 0.18\n",
      "Epoch 38 | LR: 0.05 | Total loss: 379.05 | Epoch time 0.16\n",
      "Epoch 39 | LR: 0.05 | Total loss: 378.69 | Epoch time 0.18\n",
      "Epoch 40 | LR: 0.05 | Total loss: 373.78 | Epoch time 0.17\n",
      "Epoch 41 | LR: 0.01 | Total loss: 373.04 | Epoch time 0.18\n",
      "Epoch 42 | LR: 0.01 | Total loss: 368.86 | Epoch time 0.16\n",
      "Epoch 43 | LR: 0.01 | Total loss: 368.37 | Epoch time 0.19\n",
      "Epoch 44 | LR: 0.01 | Total loss: 367.67 | Epoch time 0.17\n",
      "Epoch 45 | LR: 0.01 | Total loss: 367.77 | Epoch time 0.17\n",
      "Epoch 46 | LR: 0.01 | Total loss: 361.96 | Epoch time 0.17\n",
      "Epoch 47 | LR: 0.01 | Total loss: 361.84 | Epoch time 0.18\n",
      "Epoch 48 | LR: 0.01 | Total loss: 361.11 | Epoch time 0.16\n",
      "Epoch 49 | LR: 0.01 | Total loss: 362.90 | Epoch time 0.17\n",
      "Epoch 50 | LR: 0.01 | Total loss: 360.31 | Epoch time 0.17\n",
      "Epoch 51 | LR: 0.01 | Total loss: 361.57 | Epoch time 0.18\n",
      "Epoch 52 | LR: 0.01 | Total loss: 358.94 | Epoch time 0.16\n",
      "Epoch 53 | LR: 0.01 | Total loss: 355.16 | Epoch time 0.17\n",
      "Epoch 54 | LR: 0.01 | Total loss: 360.92 | Epoch time 0.17\n",
      "Epoch 55 | LR: 0.01 | Total loss: 357.93 | Epoch time 0.17\n",
      "Epoch 56 | LR: 0.01 | Total loss: 358.71 | Epoch time 0.17\n",
      "Epoch 57 | LR: 0.01 | Total loss: 357.42 | Epoch time 0.19\n",
      "Epoch 58 | LR: 0.01 | Total loss: 355.90 | Epoch time 0.15\n",
      "Epoch 59 | LR: 0.01 | Total loss: 359.91 | Epoch time 0.17\n",
      "Epoch 60 | LR: 0.01 | Total loss: 355.56 | Epoch time 0.17\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #5 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 446.33 | Epoch time 0.18\n",
      "Epoch 2 | LR: 0.10 | Total loss: 433.83 | Epoch time 0.16\n",
      "Epoch 3 | LR: 0.10 | Total loss: 429.15 | Epoch time 0.19\n",
      "Epoch 4 | LR: 0.10 | Total loss: 426.49 | Epoch time 0.16\n",
      "Epoch 5 | LR: 0.10 | Total loss: 424.91 | Epoch time 0.17\n",
      "Epoch 6 | LR: 0.10 | Total loss: 421.97 | Epoch time 0.17\n",
      "Epoch 7 | LR: 0.10 | Total loss: 422.65 | Epoch time 0.18\n",
      "Epoch 8 | LR: 0.10 | Total loss: 416.78 | Epoch time 0.16\n",
      "Epoch 9 | LR: 0.10 | Total loss: 412.62 | Epoch time 0.18\n",
      "Epoch 10 | LR: 0.10 | Total loss: 402.52 | Epoch time 0.16\n",
      "Epoch 11 | LR: 0.10 | Total loss: 402.30 | Epoch time 0.18\n",
      "Epoch 12 | LR: 0.10 | Total loss: 393.93 | Epoch time 0.15\n",
      "Epoch 13 | LR: 0.10 | Total loss: 388.64 | Epoch time 0.18\n",
      "Epoch 14 | LR: 0.10 | Total loss: 385.01 | Epoch time 0.15\n",
      "Epoch 15 | LR: 0.10 | Total loss: 378.38 | Epoch time 0.18\n",
      "Epoch 16 | LR: 0.10 | Total loss: 375.27 | Epoch time 0.16\n",
      "Epoch 17 | LR: 0.10 | Total loss: 372.15 | Epoch time 0.18\n",
      "Epoch 18 | LR: 0.10 | Total loss: 371.97 | Epoch time 0.15\n",
      "Epoch 19 | LR: 0.10 | Total loss: 364.74 | Epoch time 0.18\n",
      "Epoch 20 | LR: 0.10 | Total loss: 368.07 | Epoch time 0.16\n",
      "Epoch 21 | LR: 0.05 | Total loss: 366.53 | Epoch time 0.18\n",
      "Epoch 22 | LR: 0.05 | Total loss: 365.16 | Epoch time 0.16\n",
      "Epoch 23 | LR: 0.05 | Total loss: 363.11 | Epoch time 0.18\n",
      "Epoch 24 | LR: 0.05 | Total loss: 360.99 | Epoch time 0.15\n",
      "Epoch 25 | LR: 0.05 | Total loss: 360.73 | Epoch time 0.20\n",
      "Epoch 26 | LR: 0.05 | Total loss: 358.99 | Epoch time 0.16\n",
      "Epoch 27 | LR: 0.05 | Total loss: 358.85 | Epoch time 0.19\n",
      "Epoch 28 | LR: 0.05 | Total loss: 357.12 | Epoch time 0.15\n",
      "Epoch 29 | LR: 0.05 | Total loss: 356.94 | Epoch time 0.18\n",
      "Epoch 30 | LR: 0.05 | Total loss: 356.86 | Epoch time 0.15\n",
      "Epoch 31 | LR: 0.05 | Total loss: 357.70 | Epoch time 0.18\n",
      "Epoch 32 | LR: 0.05 | Total loss: 355.20 | Epoch time 0.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | LR: 0.05 | Total loss: 358.56 | Epoch time 0.19\n",
      "Epoch 34 | LR: 0.05 | Total loss: 355.22 | Epoch time 0.16\n",
      "Epoch 35 | LR: 0.05 | Total loss: 357.89 | Epoch time 0.17\n",
      "Epoch 36 | LR: 0.05 | Total loss: 356.41 | Epoch time 0.17\n",
      "Epoch 37 | LR: 0.05 | Total loss: 355.20 | Epoch time 0.17\n",
      "Epoch 38 | LR: 0.05 | Total loss: 357.29 | Epoch time 0.16\n",
      "Epoch 39 | LR: 0.05 | Total loss: 354.91 | Epoch time 0.20\n",
      "Epoch 40 | LR: 0.05 | Total loss: 355.50 | Epoch time 0.15\n",
      "Epoch 41 | LR: 0.01 | Total loss: 357.03 | Epoch time 0.18\n",
      "Epoch 42 | LR: 0.01 | Total loss: 356.05 | Epoch time 0.16\n",
      "Epoch 43 | LR: 0.01 | Total loss: 355.14 | Epoch time 0.17\n",
      "Epoch 44 | LR: 0.01 | Total loss: 353.50 | Epoch time 0.17\n",
      "Epoch 45 | LR: 0.01 | Total loss: 354.89 | Epoch time 0.18\n",
      "Epoch 46 | LR: 0.01 | Total loss: 353.45 | Epoch time 0.16\n",
      "Epoch 47 | LR: 0.01 | Total loss: 354.04 | Epoch time 0.18\n",
      "Epoch 48 | LR: 0.01 | Total loss: 349.31 | Epoch time 0.17\n",
      "Epoch 49 | LR: 0.01 | Total loss: 354.06 | Epoch time 0.18\n",
      "Epoch 50 | LR: 0.01 | Total loss: 357.14 | Epoch time 0.15\n",
      "Epoch 51 | LR: 0.01 | Total loss: 352.84 | Epoch time 0.18\n",
      "Epoch 52 | LR: 0.01 | Total loss: 353.13 | Epoch time 0.16\n",
      "Epoch 53 | LR: 0.01 | Total loss: 348.82 | Epoch time 0.17\n",
      "Epoch 54 | LR: 0.01 | Total loss: 354.24 | Epoch time 0.16\n",
      "Epoch 55 | LR: 0.01 | Total loss: 354.55 | Epoch time 0.18\n",
      "Epoch 56 | LR: 0.01 | Total loss: 354.39 | Epoch time 0.16\n",
      "Epoch 57 | LR: 0.01 | Total loss: 356.39 | Epoch time 0.20\n",
      "Epoch 58 | LR: 0.01 | Total loss: 352.53 | Epoch time 0.17\n",
      "Epoch 59 | LR: 0.01 | Total loss: 354.08 | Epoch time 0.18\n",
      "Epoch 60 | LR: 0.01 | Total loss: 355.42 | Epoch time 0.16\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #6 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 456.40 | Epoch time 0.18\n",
      "Epoch 2 | LR: 0.10 | Total loss: 442.00 | Epoch time 0.17\n",
      "Epoch 3 | LR: 0.10 | Total loss: 436.46 | Epoch time 0.18\n",
      "Epoch 4 | LR: 0.10 | Total loss: 431.67 | Epoch time 0.15\n",
      "Epoch 5 | LR: 0.10 | Total loss: 431.12 | Epoch time 0.18\n",
      "Epoch 6 | LR: 0.10 | Total loss: 427.26 | Epoch time 0.19\n",
      "Epoch 7 | LR: 0.10 | Total loss: 428.13 | Epoch time 0.25\n",
      "Epoch 8 | LR: 0.10 | Total loss: 425.57 | Epoch time 0.30\n",
      "Epoch 9 | LR: 0.10 | Total loss: 422.95 | Epoch time 0.30\n",
      "Epoch 10 | LR: 0.10 | Total loss: 425.21 | Epoch time 0.29\n",
      "Epoch 11 | LR: 0.10 | Total loss: 421.72 | Epoch time 0.31\n",
      "Epoch 12 | LR: 0.10 | Total loss: 420.61 | Epoch time 0.20\n",
      "Epoch 13 | LR: 0.10 | Total loss: 422.22 | Epoch time 0.25\n",
      "Epoch 14 | LR: 0.10 | Total loss: 422.38 | Epoch time 0.29\n",
      "Epoch 15 | LR: 0.10 | Total loss: 424.69 | Epoch time 0.29\n",
      "Epoch 16 | LR: 0.10 | Total loss: 417.26 | Epoch time 0.30\n",
      "Epoch 17 | LR: 0.10 | Total loss: 418.83 | Epoch time 0.29\n",
      "Epoch 18 | LR: 0.10 | Total loss: 421.22 | Epoch time 0.31\n",
      "Epoch 19 | LR: 0.10 | Total loss: 416.38 | Epoch time 0.29\n",
      "Epoch 20 | LR: 0.10 | Total loss: 412.41 | Epoch time 0.19\n",
      "Epoch 21 | LR: 0.05 | Total loss: 409.68 | Epoch time 0.27\n",
      "Epoch 22 | LR: 0.05 | Total loss: 406.53 | Epoch time 0.29\n",
      "Epoch 23 | LR: 0.05 | Total loss: 404.25 | Epoch time 0.31\n",
      "Epoch 24 | LR: 0.05 | Total loss: 401.02 | Epoch time 0.30\n",
      "Epoch 25 | LR: 0.05 | Total loss: 401.25 | Epoch time 0.31\n",
      "Epoch 26 | LR: 0.05 | Total loss: 393.58 | Epoch time 0.30\n",
      "Epoch 27 | LR: 0.05 | Total loss: 387.95 | Epoch time 0.28\n",
      "Epoch 28 | LR: 0.05 | Total loss: 388.47 | Epoch time 0.17\n",
      "Epoch 29 | LR: 0.05 | Total loss: 387.66 | Epoch time 0.27\n",
      "Epoch 30 | LR: 0.05 | Total loss: 382.82 | Epoch time 0.29\n",
      "Epoch 31 | LR: 0.05 | Total loss: 379.45 | Epoch time 0.33\n",
      "Epoch 32 | LR: 0.05 | Total loss: 375.55 | Epoch time 0.19\n",
      "Epoch 33 | LR: 0.05 | Total loss: 374.07 | Epoch time 0.30\n",
      "Epoch 34 | LR: 0.05 | Total loss: 372.98 | Epoch time 0.29\n",
      "Epoch 35 | LR: 0.05 | Total loss: 370.53 | Epoch time 0.32\n",
      "Epoch 36 | LR: 0.05 | Total loss: 368.32 | Epoch time 0.19\n",
      "Epoch 37 | LR: 0.05 | Total loss: 367.19 | Epoch time 0.27\n",
      "Epoch 38 | LR: 0.05 | Total loss: 366.40 | Epoch time 0.27\n",
      "Epoch 39 | LR: 0.05 | Total loss: 367.22 | Epoch time 0.15\n",
      "Epoch 40 | LR: 0.05 | Total loss: 366.16 | Epoch time 0.17\n",
      "Epoch 41 | LR: 0.01 | Total loss: 363.68 | Epoch time 0.15\n",
      "Epoch 42 | LR: 0.01 | Total loss: 361.08 | Epoch time 0.18\n",
      "Epoch 43 | LR: 0.01 | Total loss: 358.53 | Epoch time 0.16\n",
      "Epoch 44 | LR: 0.01 | Total loss: 363.03 | Epoch time 0.23\n",
      "Epoch 45 | LR: 0.01 | Total loss: 356.93 | Epoch time 0.18\n",
      "Epoch 46 | LR: 0.01 | Total loss: 358.64 | Epoch time 0.18\n",
      "Epoch 47 | LR: 0.01 | Total loss: 359.37 | Epoch time 0.15\n",
      "Epoch 48 | LR: 0.01 | Total loss: 359.86 | Epoch time 0.17\n",
      "Epoch 49 | LR: 0.01 | Total loss: 359.25 | Epoch time 0.15\n",
      "Epoch 50 | LR: 0.01 | Total loss: 357.18 | Epoch time 0.18\n",
      "Epoch 51 | LR: 0.01 | Total loss: 359.77 | Epoch time 0.20\n",
      "Epoch 52 | LR: 0.01 | Total loss: 357.66 | Epoch time 0.27\n",
      "Epoch 53 | LR: 0.01 | Total loss: 356.78 | Epoch time 0.15\n",
      "Epoch 54 | LR: 0.01 | Total loss: 355.50 | Epoch time 0.18\n",
      "Epoch 55 | LR: 0.01 | Total loss: 357.06 | Epoch time 0.16\n",
      "Epoch 56 | LR: 0.01 | Total loss: 356.26 | Epoch time 0.17\n",
      "Epoch 57 | LR: 0.01 | Total loss: 357.30 | Epoch time 0.16\n",
      "Epoch 58 | LR: 0.01 | Total loss: 356.83 | Epoch time 0.19\n",
      "Epoch 59 | LR: 0.01 | Total loss: 355.91 | Epoch time 0.16\n",
      "Epoch 60 | LR: 0.01 | Total loss: 358.47 | Epoch time 0.18\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #7 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 464.05 | Epoch time 0.16\n",
      "Epoch 2 | LR: 0.10 | Total loss: 438.77 | Epoch time 0.19\n",
      "Epoch 3 | LR: 0.10 | Total loss: 435.78 | Epoch time 0.16\n",
      "Epoch 4 | LR: 0.10 | Total loss: 434.10 | Epoch time 0.18\n",
      "Epoch 5 | LR: 0.10 | Total loss: 433.42 | Epoch time 0.16\n",
      "Epoch 6 | LR: 0.10 | Total loss: 432.62 | Epoch time 0.17\n",
      "Epoch 7 | LR: 0.10 | Total loss: 426.66 | Epoch time 0.17\n",
      "Epoch 8 | LR: 0.10 | Total loss: 428.62 | Epoch time 0.19\n",
      "Epoch 9 | LR: 0.10 | Total loss: 423.56 | Epoch time 0.16\n",
      "Epoch 10 | LR: 0.10 | Total loss: 424.22 | Epoch time 0.19\n",
      "Epoch 11 | LR: 0.10 | Total loss: 424.75 | Epoch time 0.17\n",
      "Epoch 12 | LR: 0.10 | Total loss: 423.55 | Epoch time 0.18\n",
      "Epoch 13 | LR: 0.10 | Total loss: 425.82 | Epoch time 0.16\n",
      "Epoch 14 | LR: 0.10 | Total loss: 423.27 | Epoch time 0.18\n",
      "Epoch 15 | LR: 0.10 | Total loss: 420.71 | Epoch time 0.16\n",
      "Epoch 16 | LR: 0.10 | Total loss: 419.84 | Epoch time 0.19\n",
      "Epoch 17 | LR: 0.10 | Total loss: 421.45 | Epoch time 0.16\n",
      "Epoch 18 | LR: 0.10 | Total loss: 415.68 | Epoch time 0.29\n",
      "Epoch 19 | LR: 0.10 | Total loss: 410.52 | Epoch time 0.32\n",
      "Epoch 20 | LR: 0.10 | Total loss: 408.14 | Epoch time 0.31\n",
      "Epoch 21 | LR: 0.05 | Total loss: 401.34 | Epoch time 0.32\n",
      "Epoch 22 | LR: 0.05 | Total loss: 392.45 | Epoch time 0.26\n",
      "Epoch 23 | LR: 0.05 | Total loss: 393.72 | Epoch time 0.24\n",
      "Epoch 24 | LR: 0.05 | Total loss: 384.10 | Epoch time 0.30\n",
      "Epoch 25 | LR: 0.05 | Total loss: 380.91 | Epoch time 0.28\n",
      "Epoch 26 | LR: 0.05 | Total loss: 377.91 | Epoch time 0.18\n",
      "Epoch 27 | LR: 0.05 | Total loss: 376.16 | Epoch time 0.18\n",
      "Epoch 28 | LR: 0.05 | Total loss: 369.12 | Epoch time 0.17\n",
      "Epoch 29 | LR: 0.05 | Total loss: 370.60 | Epoch time 0.18\n",
      "Epoch 30 | LR: 0.05 | Total loss: 366.34 | Epoch time 0.17\n",
      "Epoch 31 | LR: 0.05 | Total loss: 365.86 | Epoch time 0.18\n",
      "Epoch 32 | LR: 0.05 | Total loss: 363.20 | Epoch time 0.17\n",
      "Epoch 33 | LR: 0.05 | Total loss: 365.43 | Epoch time 0.18\n",
      "Epoch 34 | LR: 0.05 | Total loss: 358.53 | Epoch time 0.17\n",
      "Epoch 35 | LR: 0.05 | Total loss: 362.87 | Epoch time 0.18\n",
      "Epoch 36 | LR: 0.05 | Total loss: 361.18 | Epoch time 0.17\n",
      "Epoch 37 | LR: 0.05 | Total loss: 356.23 | Epoch time 0.18\n",
      "Epoch 38 | LR: 0.05 | Total loss: 355.79 | Epoch time 0.16\n",
      "Epoch 39 | LR: 0.05 | Total loss: 358.93 | Epoch time 0.18\n",
      "Epoch 40 | LR: 0.05 | Total loss: 357.63 | Epoch time 0.16\n",
      "Epoch 41 | LR: 0.01 | Total loss: 358.03 | Epoch time 0.19\n",
      "Epoch 42 | LR: 0.01 | Total loss: 356.75 | Epoch time 0.17\n",
      "Epoch 43 | LR: 0.01 | Total loss: 357.22 | Epoch time 0.18\n",
      "Epoch 44 | LR: 0.01 | Total loss: 354.99 | Epoch time 0.16\n",
      "Epoch 45 | LR: 0.01 | Total loss: 357.48 | Epoch time 0.19\n",
      "Epoch 46 | LR: 0.01 | Total loss: 355.65 | Epoch time 0.16\n",
      "Epoch 47 | LR: 0.01 | Total loss: 358.64 | Epoch time 0.24\n",
      "Epoch 48 | LR: 0.01 | Total loss: 352.73 | Epoch time 0.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | LR: 0.01 | Total loss: 355.31 | Epoch time 0.24\n",
      "Epoch 50 | LR: 0.01 | Total loss: 355.42 | Epoch time 0.22\n",
      "Epoch 51 | LR: 0.01 | Total loss: 355.70 | Epoch time 0.32\n",
      "Epoch 52 | LR: 0.01 | Total loss: 352.23 | Epoch time 0.19\n",
      "Epoch 53 | LR: 0.01 | Total loss: 354.40 | Epoch time 0.29\n",
      "Epoch 54 | LR: 0.01 | Total loss: 353.00 | Epoch time 0.29\n",
      "Epoch 55 | LR: 0.01 | Total loss: 354.81 | Epoch time 0.18\n",
      "Epoch 56 | LR: 0.01 | Total loss: 353.66 | Epoch time 0.25\n",
      "Epoch 57 | LR: 0.01 | Total loss: 356.04 | Epoch time 0.29\n",
      "Epoch 58 | LR: 0.01 | Total loss: 355.11 | Epoch time 0.30\n",
      "Epoch 59 | LR: 0.01 | Total loss: 353.27 | Epoch time 0.26\n",
      "Epoch 60 | LR: 0.01 | Total loss: 350.66 | Epoch time 0.31\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #8 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 451.14 | Epoch time 0.29\n",
      "Epoch 2 | LR: 0.10 | Total loss: 433.42 | Epoch time 0.22\n",
      "Epoch 3 | LR: 0.10 | Total loss: 432.12 | Epoch time 0.17\n",
      "Epoch 4 | LR: 0.10 | Total loss: 431.46 | Epoch time 0.18\n",
      "Epoch 5 | LR: 0.10 | Total loss: 430.90 | Epoch time 0.16\n",
      "Epoch 6 | LR: 0.10 | Total loss: 426.14 | Epoch time 0.17\n",
      "Epoch 7 | LR: 0.10 | Total loss: 427.24 | Epoch time 0.16\n",
      "Epoch 8 | LR: 0.10 | Total loss: 425.63 | Epoch time 0.18\n",
      "Epoch 9 | LR: 0.10 | Total loss: 420.96 | Epoch time 0.16\n",
      "Epoch 10 | LR: 0.10 | Total loss: 423.51 | Epoch time 0.19\n",
      "Epoch 11 | LR: 0.10 | Total loss: 424.73 | Epoch time 0.16\n",
      "Epoch 12 | LR: 0.10 | Total loss: 423.42 | Epoch time 0.18\n",
      "Epoch 13 | LR: 0.10 | Total loss: 423.09 | Epoch time 0.16\n",
      "Epoch 14 | LR: 0.10 | Total loss: 418.99 | Epoch time 0.18\n",
      "Epoch 15 | LR: 0.10 | Total loss: 416.24 | Epoch time 0.16\n",
      "Epoch 16 | LR: 0.10 | Total loss: 415.24 | Epoch time 0.18\n",
      "Epoch 17 | LR: 0.10 | Total loss: 410.73 | Epoch time 0.16\n",
      "Epoch 18 | LR: 0.10 | Total loss: 407.71 | Epoch time 0.18\n",
      "Epoch 19 | LR: 0.10 | Total loss: 397.92 | Epoch time 0.15\n",
      "Epoch 20 | LR: 0.10 | Total loss: 396.13 | Epoch time 0.18\n",
      "Epoch 21 | LR: 0.05 | Total loss: 388.39 | Epoch time 0.16\n",
      "Epoch 22 | LR: 0.05 | Total loss: 384.13 | Epoch time 0.17\n",
      "Epoch 23 | LR: 0.05 | Total loss: 383.93 | Epoch time 0.16\n",
      "Epoch 24 | LR: 0.05 | Total loss: 376.08 | Epoch time 0.18\n",
      "Epoch 25 | LR: 0.05 | Total loss: 372.48 | Epoch time 0.15\n",
      "Epoch 26 | LR: 0.05 | Total loss: 371.46 | Epoch time 0.18\n",
      "Epoch 27 | LR: 0.05 | Total loss: 370.67 | Epoch time 0.15\n",
      "Epoch 28 | LR: 0.05 | Total loss: 366.47 | Epoch time 0.18\n",
      "Epoch 29 | LR: 0.05 | Total loss: 365.01 | Epoch time 0.16\n",
      "Epoch 30 | LR: 0.05 | Total loss: 364.39 | Epoch time 0.18\n",
      "Epoch 31 | LR: 0.05 | Total loss: 364.66 | Epoch time 0.16\n",
      "Epoch 32 | LR: 0.05 | Total loss: 363.74 | Epoch time 0.19\n",
      "Epoch 33 | LR: 0.05 | Total loss: 361.47 | Epoch time 0.16\n",
      "Epoch 34 | LR: 0.05 | Total loss: 363.61 | Epoch time 0.17\n",
      "Epoch 35 | LR: 0.05 | Total loss: 356.17 | Epoch time 0.17\n",
      "Epoch 36 | LR: 0.05 | Total loss: 360.35 | Epoch time 0.19\n",
      "Epoch 37 | LR: 0.05 | Total loss: 358.10 | Epoch time 0.16\n",
      "Epoch 38 | LR: 0.05 | Total loss: 358.60 | Epoch time 0.19\n",
      "Epoch 39 | LR: 0.05 | Total loss: 358.45 | Epoch time 0.17\n",
      "Epoch 40 | LR: 0.05 | Total loss: 355.75 | Epoch time 0.19\n",
      "Epoch 41 | LR: 0.01 | Total loss: 356.64 | Epoch time 0.16\n",
      "Epoch 42 | LR: 0.01 | Total loss: 357.75 | Epoch time 0.19\n",
      "Epoch 43 | LR: 0.01 | Total loss: 354.99 | Epoch time 0.16\n",
      "Epoch 44 | LR: 0.01 | Total loss: 357.36 | Epoch time 0.19\n",
      "Epoch 45 | LR: 0.01 | Total loss: 353.56 | Epoch time 0.31\n",
      "Epoch 46 | LR: 0.01 | Total loss: 356.71 | Epoch time 0.28\n",
      "Epoch 47 | LR: 0.01 | Total loss: 356.50 | Epoch time 0.33\n",
      "Epoch 48 | LR: 0.01 | Total loss: 356.19 | Epoch time 0.30\n",
      "Epoch 49 | LR: 0.01 | Total loss: 355.13 | Epoch time 0.30\n",
      "Epoch 50 | LR: 0.01 | Total loss: 353.65 | Epoch time 0.34\n",
      "Epoch 51 | LR: 0.01 | Total loss: 354.79 | Epoch time 0.28\n",
      "Epoch 52 | LR: 0.01 | Total loss: 356.79 | Epoch time 0.32\n",
      "Epoch 53 | LR: 0.01 | Total loss: 352.27 | Epoch time 0.22\n",
      "Epoch 54 | LR: 0.01 | Total loss: 357.15 | Epoch time 0.18\n",
      "Epoch 55 | LR: 0.01 | Total loss: 352.51 | Epoch time 0.19\n",
      "Epoch 56 | LR: 0.01 | Total loss: 354.66 | Epoch time 0.28\n",
      "Epoch 57 | LR: 0.01 | Total loss: 356.64 | Epoch time 0.31\n",
      "Epoch 58 | LR: 0.01 | Total loss: 355.64 | Epoch time 0.36\n",
      "Epoch 59 | LR: 0.01 | Total loss: 353.09 | Epoch time 0.24\n",
      "Epoch 60 | LR: 0.01 | Total loss: 354.65 | Epoch time 0.30\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #9 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 449.14 | Epoch time 0.31\n",
      "Epoch 2 | LR: 0.10 | Total loss: 440.67 | Epoch time 0.31\n",
      "Epoch 3 | LR: 0.10 | Total loss: 437.18 | Epoch time 0.32\n",
      "Epoch 4 | LR: 0.10 | Total loss: 431.14 | Epoch time 0.31\n",
      "Epoch 5 | LR: 0.10 | Total loss: 431.42 | Epoch time 0.33\n",
      "Epoch 6 | LR: 0.10 | Total loss: 427.55 | Epoch time 0.25\n",
      "Epoch 7 | LR: 0.10 | Total loss: 427.16 | Epoch time 0.25\n",
      "Epoch 8 | LR: 0.10 | Total loss: 424.98 | Epoch time 0.34\n",
      "Epoch 9 | LR: 0.10 | Total loss: 427.04 | Epoch time 0.28\n",
      "Epoch 10 | LR: 0.10 | Total loss: 423.91 | Epoch time 0.32\n",
      "Epoch 11 | LR: 0.10 | Total loss: 424.09 | Epoch time 0.31\n",
      "Epoch 12 | LR: 0.10 | Total loss: 419.27 | Epoch time 0.33\n",
      "Epoch 13 | LR: 0.10 | Total loss: 415.08 | Epoch time 0.30\n",
      "Epoch 14 | LR: 0.10 | Total loss: 409.11 | Epoch time 0.19\n",
      "Epoch 15 | LR: 0.10 | Total loss: 403.82 | Epoch time 0.23\n",
      "Epoch 16 | LR: 0.10 | Total loss: 396.33 | Epoch time 0.17\n",
      "Epoch 17 | LR: 0.10 | Total loss: 392.07 | Epoch time 0.18\n",
      "Epoch 18 | LR: 0.10 | Total loss: 387.00 | Epoch time 0.15\n",
      "Epoch 19 | LR: 0.10 | Total loss: 381.97 | Epoch time 0.18\n",
      "Epoch 20 | LR: 0.10 | Total loss: 376.99 | Epoch time 0.17\n",
      "Epoch 21 | LR: 0.05 | Total loss: 376.64 | Epoch time 0.19\n",
      "Epoch 22 | LR: 0.05 | Total loss: 372.54 | Epoch time 0.16\n",
      "Epoch 23 | LR: 0.05 | Total loss: 368.44 | Epoch time 0.18\n",
      "Epoch 24 | LR: 0.05 | Total loss: 367.21 | Epoch time 0.16\n",
      "Epoch 25 | LR: 0.05 | Total loss: 364.81 | Epoch time 0.17\n",
      "Epoch 26 | LR: 0.05 | Total loss: 362.73 | Epoch time 0.16\n",
      "Epoch 27 | LR: 0.05 | Total loss: 366.08 | Epoch time 0.17\n",
      "Epoch 28 | LR: 0.05 | Total loss: 362.03 | Epoch time 0.15\n",
      "Epoch 29 | LR: 0.05 | Total loss: 360.82 | Epoch time 0.18\n",
      "Epoch 30 | LR: 0.05 | Total loss: 357.38 | Epoch time 0.16\n",
      "Epoch 31 | LR: 0.05 | Total loss: 362.07 | Epoch time 0.18\n",
      "Epoch 32 | LR: 0.05 | Total loss: 362.13 | Epoch time 0.16\n",
      "Epoch 33 | LR: 0.05 | Total loss: 357.45 | Epoch time 0.18\n",
      "Epoch 34 | LR: 0.05 | Total loss: 359.08 | Epoch time 0.15\n",
      "Epoch 35 | LR: 0.05 | Total loss: 355.45 | Epoch time 0.18\n",
      "Epoch 36 | LR: 0.05 | Total loss: 360.54 | Epoch time 0.16\n",
      "Epoch 37 | LR: 0.05 | Total loss: 355.69 | Epoch time 0.17\n",
      "Epoch 38 | LR: 0.05 | Total loss: 359.58 | Epoch time 0.16\n",
      "Epoch 39 | LR: 0.05 | Total loss: 357.48 | Epoch time 0.18\n",
      "Epoch 40 | LR: 0.05 | Total loss: 357.47 | Epoch time 0.15\n",
      "Epoch 41 | LR: 0.01 | Total loss: 356.40 | Epoch time 0.17\n",
      "Epoch 42 | LR: 0.01 | Total loss: 354.01 | Epoch time 0.15\n",
      "Epoch 43 | LR: 0.01 | Total loss: 357.64 | Epoch time 0.19\n",
      "Epoch 44 | LR: 0.01 | Total loss: 353.35 | Epoch time 0.16\n",
      "Epoch 45 | LR: 0.01 | Total loss: 354.25 | Epoch time 0.17\n",
      "Epoch 46 | LR: 0.01 | Total loss: 352.37 | Epoch time 0.16\n",
      "Epoch 47 | LR: 0.01 | Total loss: 355.01 | Epoch time 0.18\n",
      "Epoch 48 | LR: 0.01 | Total loss: 352.50 | Epoch time 0.15\n",
      "Epoch 49 | LR: 0.01 | Total loss: 353.09 | Epoch time 0.18\n",
      "Epoch 50 | LR: 0.01 | Total loss: 356.88 | Epoch time 0.16\n",
      "Epoch 51 | LR: 0.01 | Total loss: 353.51 | Epoch time 0.17\n",
      "Epoch 52 | LR: 0.01 | Total loss: 353.94 | Epoch time 0.16\n",
      "Epoch 53 | LR: 0.01 | Total loss: 352.78 | Epoch time 0.17\n",
      "Epoch 54 | LR: 0.01 | Total loss: 355.43 | Epoch time 0.16\n",
      "Epoch 55 | LR: 0.01 | Total loss: 353.85 | Epoch time 0.18\n",
      "Epoch 56 | LR: 0.01 | Total loss: 353.97 | Epoch time 0.16\n",
      "Epoch 57 | LR: 0.01 | Total loss: 352.16 | Epoch time 0.18\n",
      "Epoch 58 | LR: 0.01 | Total loss: 356.44 | Epoch time 0.16\n",
      "Epoch 59 | LR: 0.01 | Total loss: 354.23 | Epoch time 0.18\n",
      "Epoch 60 | LR: 0.01 | Total loss: 351.21 | Epoch time 0.16\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n",
      ">>>>>>> Training iteration #10 \n",
      "\n",
      ">>>>>>>>>>>> Start training...\n",
      "Epoch 1 | LR: 0.10 | Total loss: 452.64 | Epoch time 0.18\n",
      "Epoch 2 | LR: 0.10 | Total loss: 437.17 | Epoch time 0.17\n",
      "Epoch 3 | LR: 0.10 | Total loss: 431.72 | Epoch time 0.18\n",
      "Epoch 4 | LR: 0.10 | Total loss: 428.81 | Epoch time 0.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | LR: 0.10 | Total loss: 424.09 | Epoch time 0.17\n",
      "Epoch 6 | LR: 0.10 | Total loss: 427.98 | Epoch time 0.16\n",
      "Epoch 7 | LR: 0.10 | Total loss: 423.92 | Epoch time 0.17\n",
      "Epoch 8 | LR: 0.10 | Total loss: 424.38 | Epoch time 0.16\n",
      "Epoch 9 | LR: 0.10 | Total loss: 420.47 | Epoch time 0.18\n",
      "Epoch 10 | LR: 0.10 | Total loss: 421.72 | Epoch time 0.17\n",
      "Epoch 11 | LR: 0.10 | Total loss: 422.10 | Epoch time 0.17\n",
      "Epoch 12 | LR: 0.10 | Total loss: 418.30 | Epoch time 0.16\n",
      "Epoch 13 | LR: 0.10 | Total loss: 418.72 | Epoch time 0.18\n",
      "Epoch 14 | LR: 0.10 | Total loss: 418.62 | Epoch time 0.16\n",
      "Epoch 15 | LR: 0.10 | Total loss: 417.64 | Epoch time 0.18\n",
      "Epoch 16 | LR: 0.10 | Total loss: 418.04 | Epoch time 0.17\n",
      "Epoch 17 | LR: 0.10 | Total loss: 418.52 | Epoch time 0.17\n",
      "Epoch 18 | LR: 0.10 | Total loss: 412.52 | Epoch time 0.17\n",
      "Epoch 19 | LR: 0.10 | Total loss: 414.95 | Epoch time 0.18\n",
      "Epoch 20 | LR: 0.10 | Total loss: 413.46 | Epoch time 0.16\n",
      "Epoch 21 | LR: 0.05 | Total loss: 410.34 | Epoch time 0.19\n",
      "Epoch 22 | LR: 0.05 | Total loss: 407.56 | Epoch time 0.17\n",
      "Epoch 23 | LR: 0.05 | Total loss: 402.66 | Epoch time 0.18\n",
      "Epoch 24 | LR: 0.05 | Total loss: 395.16 | Epoch time 0.16\n",
      "Epoch 25 | LR: 0.05 | Total loss: 390.85 | Epoch time 0.18\n",
      "Epoch 26 | LR: 0.05 | Total loss: 387.80 | Epoch time 0.17\n",
      "Epoch 27 | LR: 0.05 | Total loss: 383.60 | Epoch time 0.18\n",
      "Epoch 28 | LR: 0.05 | Total loss: 378.17 | Epoch time 0.16\n",
      "Epoch 29 | LR: 0.05 | Total loss: 373.59 | Epoch time 0.18\n",
      "Epoch 30 | LR: 0.05 | Total loss: 376.12 | Epoch time 0.17\n",
      "Epoch 31 | LR: 0.05 | Total loss: 371.99 | Epoch time 0.19\n",
      "Epoch 32 | LR: 0.05 | Total loss: 365.63 | Epoch time 0.16\n",
      "Epoch 33 | LR: 0.05 | Total loss: 365.63 | Epoch time 0.17\n",
      "Epoch 34 | LR: 0.05 | Total loss: 367.63 | Epoch time 0.16\n",
      "Epoch 35 | LR: 0.05 | Total loss: 364.14 | Epoch time 0.17\n",
      "Epoch 36 | LR: 0.05 | Total loss: 363.53 | Epoch time 0.17\n",
      "Epoch 37 | LR: 0.05 | Total loss: 363.06 | Epoch time 0.19\n",
      "Epoch 38 | LR: 0.05 | Total loss: 363.80 | Epoch time 0.16\n",
      "Epoch 39 | LR: 0.05 | Total loss: 362.73 | Epoch time 0.18\n",
      "Epoch 40 | LR: 0.05 | Total loss: 359.49 | Epoch time 0.16\n",
      "Epoch 41 | LR: 0.01 | Total loss: 355.52 | Epoch time 0.18\n",
      "Epoch 42 | LR: 0.01 | Total loss: 359.63 | Epoch time 0.16\n",
      "Epoch 43 | LR: 0.01 | Total loss: 357.45 | Epoch time 0.18\n",
      "Epoch 44 | LR: 0.01 | Total loss: 359.58 | Epoch time 0.17\n",
      "Epoch 45 | LR: 0.01 | Total loss: 359.65 | Epoch time 0.17\n",
      "Epoch 46 | LR: 0.01 | Total loss: 357.91 | Epoch time 0.16\n",
      "Epoch 47 | LR: 0.01 | Total loss: 361.00 | Epoch time 0.17\n",
      "Epoch 48 | LR: 0.01 | Total loss: 358.48 | Epoch time 0.16\n",
      "Epoch 49 | LR: 0.01 | Total loss: 357.92 | Epoch time 0.18\n",
      "Epoch 50 | LR: 0.01 | Total loss: 358.39 | Epoch time 0.16\n",
      "Epoch 51 | LR: 0.01 | Total loss: 356.85 | Epoch time 0.18\n",
      "Epoch 52 | LR: 0.01 | Total loss: 356.19 | Epoch time 0.16\n",
      "Epoch 53 | LR: 0.01 | Total loss: 357.59 | Epoch time 0.18\n",
      "Epoch 54 | LR: 0.01 | Total loss: 356.89 | Epoch time 0.17\n",
      "Epoch 55 | LR: 0.01 | Total loss: 355.00 | Epoch time 0.17\n",
      "Epoch 56 | LR: 0.01 | Total loss: 354.36 | Epoch time 0.17\n",
      "Epoch 57 | LR: 0.01 | Total loss: 355.01 | Epoch time 0.18\n",
      "Epoch 58 | LR: 0.01 | Total loss: 355.08 | Epoch time 0.15\n",
      "Epoch 59 | LR: 0.01 | Total loss: 355.72 | Epoch time 0.17\n",
      "Epoch 60 | LR: 0.01 | Total loss: 353.98 | Epoch time 0.17\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(EdgesDataset(torch.tensor(A).float()), \n",
    "                        batch_size=N, shuffle=True, num_workers=0)\n",
    "\n",
    "vi = VI_DCSBM(num_nodes=N, num_classes=num_classes, \n",
    "                   priors={'theta_p':theta_p, \n",
    "                           'B_p':w_p,\n",
    "                           'delta_p':None},\n",
    "                   init_values={'etas':None, \n",
    "                                'thetas':None, \n",
    "                                'Bs':None,\n",
    "                                'deltas':delta_init})\n",
    "vi.multi_train(dataloader, epochs=20, lrs = [0.1, 0.05, 0.01], trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = vi.get_multi_losses()[:,-1].argmin()   # With the smallest loss ar the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi.load_state_dict(vi.state_dicts[best_trial])      # Load the parameters from the best trial\n",
    "q_eta, q_theta, q_B, q_delta = vi.constrained_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4748, 0.5252])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.multi_results[1][best_trial]                     # Class probability of the best trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_true = z_true.sum(dim=0).float()/34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True class probabilities: tensor([0.5294, 0.4706])\n"
     ]
    }
   ],
   "source": [
    "print('True class probabilities:', theta_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let us look at the class acuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(vi.multi_results[0])):\n",
    "    print(vi.class_accuracy(z_true,vi.multi_results[0][i]).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class assignments of the DCSBM is correct in the majority of the trials. Further, we may inspect the estimated $\\theta$ and $B$ distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation = [1,0]\n",
    "q_theta_perm = q_theta.detach()[permutation]\n",
    "num_samples = 1000\n",
    "theta_samples = Dirichlet(q_theta_perm).sample([num_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set()\n",
    "fig, axs = plt.subplots(1, num_classes, figsize=(12, 6), sharey=True)\n",
    "bins, alpha = 20, 0.8\n",
    "for i in range(num_classes):\n",
    "    axs[i].hist(theta_samples[:,i], bins=bins, alpha=alpha) \n",
    "    axs[i].vlines(theta_true[i], 0, num_samples*0.15, colors='r')\n",
    "fig.suptitle(r'Posterior class probabilities $\\theta$', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_B_perm = q_B.detach()[permutation,:,:][:,permutation,:]\n",
    "B_samples = Beta(q_B_perm[:,:,0], q_B_perm[:,:,1]).sample([num_samples])\n",
    "\n",
    "fig, axs = plt.subplots(num_classes, num_classes, figsize=(12, 12), sharey=True)\n",
    "bins, alpha = 20, 0.8\n",
    "for i in range(num_classes):\n",
    "    for j in range(num_classes):\n",
    "        axs[i,j].hist(B_samples[:,i, j], bins=bins, alpha=alpha) \n",
    "fig.suptitle(r'Posterior connection probabilities $B$', fontsize=18)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
