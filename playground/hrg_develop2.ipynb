{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f290f091110>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from vi_hrg_approx import *\n",
    "from utils import c2d, hyperdist, p_hd, polar2cart, warn_tensor\n",
    "from torch import autograd\n",
    "torch.manual_seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_r(x, R, rel_var=0.1, epsilon=1e-4):\n",
    "    rs = torch.distributions.normal.Normal(x, R*rel_var).sample() \n",
    "    return torch.clamp(rs, min=0+epsilon, max=R.item()-epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_phi(x, rel_var=0.1):\n",
    "    phis = torch.distributions.normal.Normal(x, 2*np.pi*rel_var).sample()\n",
    "    return phis % (2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = lambda x: (x/(1-x)).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAF6CAYAAAAUO1/9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAF4hJREFUeJzt3c1vVdd6x/HfMS/GYBsIhkvAYPNiqxlVqtTOkkkiRcosk7bjq/sn9EptJ0vrH+ig43QSVem0k3SUDNMMoqRSdEUSAw4BGwg2xu82fuF08Kyds31ig1/OOfvs/Xw/EopybM7ZOOH5rbX2s9au1et1AQD86in6AgAAxSIIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAGAX58+f763VardqtVpv0dfSbrV6vV70NQBA14gx9s3NzY3euXPn0x9++OHU9PT095L+WK/XXxZ9be1yvOgLAICixRhPSzqffg2sr6//3ebm5qVarTYpaVzSsKT7RV5jOxEEAFyKMZ6RFf5zknol1SVtSDrZ39//9ZMnT35YWVl5W9JfJE0Vd6Xtx9IQADdyxf+8pJOy4r8oaV7SS0k302sTCwsL73z//fdnv/zyy6+rvCwkMSMAUHExxn41iv8JNYr/Y0nzIYTtFBBjkrYlTYQQXsYYV959993VL774otIhIBEEAComxliTlBX/c2oU/wVJLyQthBC2c9/fLwuBTVkIbKQvbUo608FLLwxBAKD0mor/eVlte6VG8V/MF//c7xuUdEt2b2AihLCZ+/KmLEQqjyAAUEqp+A+oMfJvLv4LIYRXr/n9Z2UhsC4Lga2mb9mU1BNjPLZbiFQJQQCgNFLxH1Sj+B+TrevnR/57Fv/c+5yT3Rhek3R3lxCQLAgkmxUQBABQlBhjj3aO/LPiPy8r/kv7Kf6593tL0qikVVkI7FXk80GwfqiLLwmCAEDXScU/G/mf1e+L/2II4cC97zHGC7IQWJZ07w1LPvkgqDSCAEBXSMX/rBrFv0fSlqzwZyP/Q298ijEOSRqRtY7e38csgiAAgHZ7TfF/Liv+y0cp/rnPuSTpmuxewuR+lpLS/oJXIggAoLVijMfUKP6DsuK/qRYX/9znXZZ0VbasNHnA93bRQkoQAGi7VPzPqVH8a7IiOysr/iutLP65z31b0hVJc5IeHOIzNmVHUVQaQQCgLWKMx2XF/5waxX9D0jNJL0IIK23+/KuSLstmGr8cMmg2JZ1u6YV1IYIAQMvkiv95WctnTXaYW0eKf+46rkm6JGkmhPDwCG/F0hAAvEmM8YR2Fn/Jiv+vsuK/2uHruS7poqRnIYRHR3y7DTnYXUwQADiwVPyzDV5Z8V+X9ERW/NcKuKaarD30gqSnIYTpFryti93FBAGAfYkxnlRj5N+fXl5TgcU/d2012UaxtyQ9DiE8adFbu9hdTBAA2FMq/tmJntmRzGuys/xfhBAKL44pBG7KQmo6hPC0hW/vYlMZQQBghxhjrxrLPlnxX5U0LXuQS+HFP5M2pN2U7Ut4FEJ41uKPIAgA+BBjPKXGsk/WLrkiK/4vQghd95SuFAK3ZK2pD0MIM63+DC+7iwkCwKlU/LNln7708orsQe0vck/q6jppg9ot2Y3qByGE5238uMq3kBIEgCMxxj41iv+p9PKypEeyZZ+uLf6ZFAJjspnLzyGEuTZ/JEEAoNxijKfVWPbJiv+SpBnZyH9zr9/bbdKGtTHZDGYyhDDfgY/dVGPGVEkEAVBBqfhnI//e9PKSbIfvfJmKfyaFwLgszO6HEBY69NGbsvsQlUUQABURYzyjRvE/KakuK/5PZcV/t8cxlkLawDYu+3PdCyEsdvDjNyUdizH2HORJaGVCEAAlFmPsV2PZJyv+i7I+/4UyF/9M2sswLlunvxdCWOrwJeRbSLuue6oVCAKgRNLmqfzI/4R2Fv/5Kp2Jk/Y0jMseVXk3hLBcwGVkQXBSBAGAIqTi36/GJq+s+C/IzvJfqFLxz6T21jFZCEx0+vC6nKyTqrKdQwQB0IVS8R9QY9nnuKRXahT/xSoW/0wKgXHZMdY/FXmOkRzsLiYIgC6RK/7ZyL+5+C9U9WZlXtrrMC6b9fxU9JEWHnYXEwRAgVLxH1Sj+B+THXecH/lXvvhnUufTmOxnMNFFR1tUelMZQQB0WDojJyv+Z9Uo/vOy4r/kqfhnUgfUbUlbshDopl3OBAGAw6nVar2ShoeHh6f/9Kc/ZWf7nJPUo53Ff7EdD28vixjjgCwENtV9ISBVfHcxQQC0Sa1W67106dJ/jY2N/c3q6urPa2tr/9bX17cuK/7zss1er2RtiRdijHXZung9vV7f5deer5c1SGKMg7ID5DZkIdCNu54rvbu4Vq+X8v8doKvFGGuff/75325sbPznzZs3j83Ozh67du3av46Pj/8o64Rpl/2Gx4GDptWvhxDqMcazshBYl4VAV26AizFelnRV0v9VcdmOIABaLG2CGl1aWjr/2Wef/cv8/Pzw5cuXn3788cdhcHDwpxDCUrpJnP/V0/Tvh3m9Fe+x1+vtMCDpiuyJZw9lo+5Oh9N+v/f80tLSX3366adzMzMzk/V6vVtuYrcES0NAC8UYL8lGjvWBgYGJJ0+e/L2k4ZGRkWeDg4PXJY3FGH9J5+eXZhSWC65Whc1bsofMP5L0i+xn8ab3OUj4tVLfy5cvR3788cc/1+v1mqS/1Gq1P1YpDJgRAC2QZgEjslHugqRfmte6mx6m8iSE8LjjF9oFYowXZA+aX5KdHdTypZYUXEeZNR2XhdVFSacmJyevfvPNN//86NGjn5eXly9I+sd6vX6/1dddFIIAOKIY40VJw7JR7VQIYfY131uTdF3SkKxb6EEV15z3kn5W12VnI93vtj97amEdkoVATfbEtplPPvlkZWpq6j9kG90mJDEjAPDbqZgjsm6SRdksYF9tjzHGP8jCY0VWELuxU6alcn/mBdlDZboiBNJM7YIsAPpkbb1zkmbyR1tkrcCSpqoUAhJBABxKWt64Jhs1Th3mwekxxnOSbsg2UN0r+Dydtsp13byQPV6y8MKTdjFflO3t6JGF8qykuW4JqU4hCIADSA9IGZHtCF6WLe0cenSYniR2W1aIJjv8wJWOiDFekfS2bJT9oMgQSKP/bO2/T9Yd9FzSbIGnmxaOIAD2Kcb4lmx9uyZpOoTwrEXve1IWBqckPTrM7KJbxRivSrosG2k/LCoE0ug/W/vvkbSqxjObK3uK634RBMAbpGfljsiOhliRjWpbeiJmOn/opmym8Uy23FTqv5wxxmuSLsnW2h8W8PnZ6H9I0mnZ6D9b+3c7+t8NQQC8RozxvGwWcEzStKRn7SrQqaNoWFY8F2Rr6aUcrcYYR2QF+NcQwlSHP/u0bOknG/2vyUb/c2X9ebYbQQDsIs0CrsmKyaqsKHfkXPzUYnlNduzCvS48gG1PKcxGZF04T0MI0x363B411v6z0f8L2eh/pRPXUGYEAdAkdfNcl20qeiIraB39i5IOYrspK2j3yrCUkULghqwL53EI4UkHPvO0Gmv/x2Sj/1lJzxn97x9BACRpTfmabDS7JpsFFNbSmZ7UdVsWSD+HEOaLupY3SSFwU3YfZSqE8GsbPysb/Q9JOqPG6H+2oIfblx5BAOi3EfiorOg+lR0BUfhfjtSuektW8NpaYA+r6Ub3o1Z1U+3yOX1qrP0fky2dZWv/XXlqaVkQBHAtzQKGZaPLddnIu6uWYVKhHZUtuRTahtksXdst2e7qX153vMYR3v+8LADOyI7xyNb+Gf23CEEAt9JTsUZlD4bJZgFdu6M0tzFrSXYsRaFr4ClEb0vql7XUPm/he5+SFf8Laoz+s7V/Rv8tRhDAnTTKHJYVmnVZEStFZ0k62mJE0kvZTeRCzrxJITAm69D5OYTwogXv2SO7x3BRFi7Z6H82hLB01PfH3ggCuJJOlxyV1CvbuDXdzbOA3aQ/w630r/c7vUSSWmvHZEc0TB71JnYa/Q/JRv/HZSE3I0b/HUMQwIU02rwi6Q+yQvOgzGvM6fkHt2WB9iCEMNehzz0hC4FTshBaOOT71GRr/0Oy5zPUZc9xnmH033kEASovnTMzKiteM7Lum1LNAnaTRuY31aEH3aQQGJfdU7l3mIKdAixb+89G/9naf+WP4u5WBAEqK406r8gOPduQdbVU6nTPpp28c7I/Yzue+HVSFgInJN09yGwqXWO29p+N/hdko/9K/fcoK4IAlZR2nI7K1rFnZbOAyu40zZ33vyxbsmnZ2noaxY/Lunfu7vfGevp9Q+nXcVkYz8pu/jL67yIEASoljT7fls0CtmQj5EOtY5dNOiBvVNKmbOnmyGcjpRu547Kjt+++aY9FbvQ/JNtbkI3+ZyUtdsv+B+xEEKAy0s7TUVlL43PZLtfKzgJ2k+6H3FILHnSTfp5jshCYeN1xG2npKFv7PyFG/6VCEKD00ij0smwmsCXbedu15/K0W9ODbh4eZrdvWlobk43oJ3abXaSf+1lZAAymlxdkN+QZ/ZcIQYBSS0sXo7LjB17ICp/73vO04euGrFD/Ktsvsa+/7GlWMSZ7iPtE86a1FDTZ2v8J2VJUNvovzZHZaCAIUEppNHpJdoN0WxYAR97dWiVND7qZl+0Afm1HUdqsdls2s5rICnt6r0HZ6P9s+vZs7X+B0X+5EQQondSNMio7hmBeFgKsQ+8hxnhJdrz2quwm8q4/q3T20m3Z+v5ECGEzjf4vyEb/J8Xov5IIApRKKmpXZWvXDzu1o7bsYoxnZZvPtrXLg27SMdy3ZBu87spuuA/JOoAkaVG29s/ov4IIApRCmgWMyDYkLcjaQpkFHMBeD7pJT2S7KRvtv5Ad/ZCN/p/LRv+FHG6HziAI0PXSM3yHZbOAR6087tibdEzEbUmnp6amnn399ddDH3300bkzZ84cl4VAXTb6n5U0z+jfB4IAXSutT4/IblIuymYBrEsfUYzx5OLi4l9/++23/37ixInhhYWFyffee+/PAwMD02L079Lxoi8A2E2McUg2C6jJ7gXMFHxJpZS6ffpk7bX96Z+9Dx48uLK1tXX51KlTS3fu3Bn47rvvnm9tbU0Xea0oDkGArpKWLkZkLYpLslkAI9R9SieSntHOwt+TvrwpO4toZnt7e/Krr776X9nxEROSpgq4XHQJlobQNWKMb0m6LpsFTLfrIehVkjbUZQW/X7abWLK1/jVZ4V+RtNy8rFar1Xpls66per1O2DpGEKBwaRZwXdaquCybBRz5wLSqSbuFT2tn4T+WvrylVPDTP1eq8MwFdAZBgEKlEzOvywratKRndKqY1DKbX+I5nfvymnKFn+DEURAEKERay74u61lfkT1u0W0xS4/SPK2dhf9E+vK20ihfjcLv6lRVtBdBgI5LG5iuy5oVHkv61dssIC2H5Zd4TsvujUi2u/e3tX1J695+PugsggAdk9a4r8nOrlmVzQL2POO+KnItnPnCfzJ9+ZXsZ5G/qev+9FR0FkGAjkhn3YzIZgFPZQ9br+T/fLkWzqzw51s4N7Tzpu5qVX8OKA+CAG2VZgHDsgPM1mSzgNc+7rBs0hk++cKfb+Fc1c61fXZGo+sQBGibdKzxqGwZ5Kmkx2Uf/aZga96wlW/hzK/tr9LCiTIgCNByqQNmWPYQk3XZLGCl2Ks6nNTCmV/b78t9uXnDFpuyUEoEAVoqPeFqVFKv7BGJj8syKs61cOYLf3YMS9bCmd+wRQsnKoEgQEukInpV9ljEl7JZwHKxV/V66XTT5g1bWQvnunau7Ve+uwl+EQQ4svSw81HZTdIZSVPdNgtILZzNG7byLZzNG7Zo4YQbBAEOLc0C3pZ0WdYW+SCEsFTsVZnUwtm8YSvfwpm/qbtW9pvYwFEQBDiUGONpSTdks4BZ2SygkDXzNNpvPoWzN305a+HM39TlEZdADkGAA0lFN5sFbMlmAYsdvoashTO/YStr4dzU7zdsddUyFdBtCALsW9o4dUPWQvlc9vzgts8C0pn7+cKfb+Fs3rBFCydwQAQB3ijNAi7LZgJbskdHzrfps3r0+w1b+RbO5g1btHACR0QQ4LXSaPyG7GbrnGwW0LKOmtTC2bxhK9/CmV/bd3tMNdBOBAF2lWYBl2R7A7Zls4AXLXjP5g1b2Zn7WQtnfsMWLZxAB/DwevxOmgWMyor1vOzRkQcuyunM/eabuvkz95fUKPy0cAIFYUaAHWKM2SygLpsFzO3z92Vn7ucLf76Fs3nDFi2cQJcgCCDpt8PVRmVFfEE2C9izWOfO3M8X/mzD1qZ+f1OX/9GALkUQQDHGi7LTQuuym8HPd/me5g1b+TP3m0/h5Mx9oEQIAsdSx86IpEFJi7JZwEauhTNf+PNn7jff1GXDFlBiBIFTMcYh2SygJumZbFSfP4Uzs6ada/u0cAIVQxA48/777/f39/e/984776ivr++lrCso80o71/Y5cx9wgCBw5MMPPxxYWlr6n42NjSsbGxsPPvjgg386e/bsCzUK/zo3dQF/CAJHarXarStXrvz3ysrK9PLy8tD29vY/1Ov1+0VfF4BisaHMl6nHjx9/L2lc0k+Spgq+HgBdgBmBM7VarVd2k3iqXq9zUicAggAAvOt587cAAKqMIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHDu/wHUkYJoR3PQjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 5\n",
    "R = torch.tensor([5.0]).double()\n",
    "alpha = .7\n",
    "T = 0.1\n",
    "\n",
    "G = HRG(R=R, alpha=alpha, T=T)\n",
    "r, theta, A = G.generate(N)\n",
    "G.show()\n",
    "G.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_loc_init = logit(noise_r(r, R, rel_var=0.05)/R)*R/5\n",
    "r_scale_init = torch.ones([N]).double().log()\n",
    "phi_loc_init = torch.cat((polar2cart(1, noise_phi(theta, 0.02)),  torch.zeros([N,1]).double()), dim=-1)\n",
    "phi_loc_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8354,  1.9024, -0.4989,  0.5558, -1.4038], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_loc_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.3120, 4.3508, 1.8890, 3.1774, 0.9861], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Radius(r_loc_init, r_scale_init.exp(), R.expand([N])).mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_conc_init = torch.tensor(10.).log()\n",
    "R_scale_init = torch.tensor(1.).log()\n",
    "alpha_conc_init = torch.tensor(.5).log()\n",
    "alpha_scale_init = torch.tensor(.5).log()\n",
    "T_init = torch.tensor([3.,10.]).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0986, 2.3026])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(EdgesDataset(A), batch_size=N**2, shuffle=True, num_workers=0)\n",
    "vi = VI_HRG(N,10, init_values={'rs_loc':r_loc_init,\n",
    "                                'rs_scale':r_scale_init,\n",
    "                              'phis_loc':phi_loc_init,\n",
    "                              'phis_scale':None, \n",
    "                              'R_conc':R_conc_init, \n",
    "                              'R_scale':R_scale_init,\n",
    "                              'alpha_conc':alpha_conc_init,\n",
    "                              'alpha_scale':alpha_scale_init,\n",
    "                              'T':T_init})\n",
    "vi.dataloader = dataloader\n",
    "vi.optimizer = torch.optim.RMSprop(vi.parameters())\n",
    "#vi.optimizer.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>> Start training...\n",
      "-D_kl(R)    >> tensor(-7.4639, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8525, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.8176, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-125.9165, dtype=torch.float64, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/utils.py:126: UserWarning: cosh_dist has 1 in it!\n",
      "  warnings.warn(str('%s has 1 in it!' % variable))\n",
      "../src/utils.py:126: UserWarning: c has 1 in it!\n",
      "  warnings.warn(str('%s has 1 in it!' % variable))\n",
      "../src/utils.py:126: UserWarning: p_raw has 1 in it!\n",
      "  warnings.warn(str('%s has 1 in it!' % variable))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha_R_ri  >> tensor(-464.0568, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-26.1030, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(32.3456, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.1105, -1.2390, -2.2518, -2.2558, -1.4602],\n",
      "        [-2.9155, -2.1327, -2.4197, -2.1499, -1.4365],\n",
      "        [-1.2070, -1.0870, -2.3977, -2.4808, -1.9887],\n",
      "        [-0.1783, -0.7402, -1.3987, -1.1252, -1.2008],\n",
      "        [-1.5099, -1.0782, -1.9039, -1.8253, -1.2105],\n",
      "        [-1.4065, -1.0501, -1.7592, -1.9677, -1.2185],\n",
      "        [-2.3398, -2.1897, -1.9489, -1.8145, -3.9999],\n",
      "        [-0.3820, -0.9156, -4.5684, -1.3304, -1.9365],\n",
      "        [-1.2018, -1.4934, -1.9370, -1.8233, -1.3179],\n",
      "        [-0.3852, -0.4019, -1.4191, -1.2139, -1.1135]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(204.5961, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.3007, -1.1285, -1.2247, -2.9008, -3.9570],\n",
      "        [-2.4147, -2.3567, -1.5290, -2.0029, -2.0009],\n",
      "        [-2.7554, -1.4674, -3.9252, -2.8407, -2.4370],\n",
      "        [-1.3666, -0.8984, -1.3279, -1.7698, -2.1308],\n",
      "        [-2.7124, -1.0537, -1.1152, -2.1445, -1.6238],\n",
      "        [-2.6631, -1.2837, -2.1005, -1.9343, -2.3578],\n",
      "        [-1.2099, -0.9396, -1.6041, -3.5385, -1.7614],\n",
      "        [-1.3322, -1.0085, -1.4106, -1.8734, -1.5856],\n",
      "        [-1.8875, -1.4820, -1.1150, -2.3243, -2.1015],\n",
      "        [-2.1961, -1.1718, -1.1008, -3.6975, -1.4961]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(238.9009, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-190.9028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1 | LR: 0.10 | Total loss: 190.90 | Epoch time 0.36\n",
      "-D_kl(R)    >> tensor(-9.5246, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6422, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.7304, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-171.6600, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-232.0563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-11.0497, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(6.3521, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-2.7960, -2.7471, -2.2307, -2.2518, -7.9371],\n",
      "        [-1.2552, -2.2131, -2.0408, -1.9773, -2.5329],\n",
      "        [-0.7874, -0.9551, -1.5356, -4.8855, -1.1959],\n",
      "        [-1.3612, -1.2512, -2.1043, -3.4218, -1.9456],\n",
      "        [-1.7567, -1.8092, -2.3780, -2.2649, -2.1219],\n",
      "        [-1.1952, -2.1425, -2.5423, -2.0218, -1.5316],\n",
      "        [-1.1092, -2.1410, -2.2657, -2.3586, -1.4242],\n",
      "        [-1.4946, -2.2930, -3.2319, -1.9559, -1.6915],\n",
      "        [-3.2852, -1.8917, -1.9840, -1.9315, -2.7397],\n",
      "        [-1.0156, -1.0479, -2.2393, -3.0129, -1.2453]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(268.8714, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-4.0700, -1.0369, -1.8737, -2.9273, -2.6288],\n",
      "        [-2.6184, -1.9577, -1.6182, -2.1010, -1.6459],\n",
      "        [-2.4678, -2.1902, -2.3708, -1.7963, -2.6389],\n",
      "        [-2.2426, -1.9534, -1.8377, -2.3890, -2.3581],\n",
      "        [-2.4769, -1.6307, -2.9821, -2.9205, -2.0089],\n",
      "        [-2.7865, -2.0229, -1.6357, -2.6490, -3.4360],\n",
      "        [-2.5833, -1.9371, -2.7491, -3.1992, -3.4956],\n",
      "        [-2.5623, -4.0378, -1.5044, -2.0729, -3.5650],\n",
      "        [-2.2531, -3.3562, -1.5771, -2.5392, -3.6485],\n",
      "        [-3.2499, -4.8165, -1.6777, -2.1654, -1.8546]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(310.2925, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(144.3113, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2 | LR: 0.10 | Total loss: -144.31 | Epoch time 0.30\n",
      "-D_kl(R)    >> tensor(-8.0373, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6983, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6649, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-152.1694, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-230.9692, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-11.4421, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(9.0910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-2.4116, -1.1438, -2.6542, -2.0035, -2.8550],\n",
      "        [-1.2991, -1.1773, -2.5676, -1.8853, -1.6149],\n",
      "        [-1.0054, -3.0563, -2.2659, -1.9071, -2.1691],\n",
      "        [-1.4618, -1.2193, -2.2283, -1.8782, -1.3613],\n",
      "        [-4.2432, -0.7398, -1.9448, -1.3844, -1.0737],\n",
      "        [-1.1123, -1.1363, -2.7476, -2.3635, -3.8673],\n",
      "        [-0.6182, -3.8568, -2.2892, -1.5351, -1.0866],\n",
      "        [-1.0857, -0.5361, -1.8097, -1.7164, -1.2548],\n",
      "        [-3.5713, -1.3162, -1.4730, -1.3576, -0.9885],\n",
      "        [-0.8834, -0.6026, -1.5158, -1.8538, -1.4026]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(223.8292, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-2.7615, -1.1701, -2.1214, -1.9739, -2.4979],\n",
      "        [-1.7078, -1.8330, -3.2723, -3.1955, -3.3460],\n",
      "        [-3.0715, -4.1964, -2.7712, -2.2970, -3.3585],\n",
      "        [-3.7438, -2.2316, -3.0166, -2.1051, -1.7606],\n",
      "        [-2.1704, -2.5128, -3.3792, -2.4176, -3.8227],\n",
      "        [-2.7648, -3.8332, -1.9010, -3.0074, -4.1056],\n",
      "        [-2.8781, -1.1105, -2.9400, -3.1760, -2.9028],\n",
      "        [-2.7880, -4.0973, -3.4029, -2.1027, -3.3169],\n",
      "        [-1.8261, -0.8106, -2.7658, -2.6958, -3.8890],\n",
      "        [-2.9474, -1.9719, -2.8216, -2.2636, -2.4200]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(338.6838, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(149.3423, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 3 | LR: 0.10 | Total loss: -149.34 | Epoch time 0.31\n",
      "-D_kl(R)    >> tensor(-7.1408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7066, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6208, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-114.2788, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-220.4765, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-11.2563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(6.7153, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-2.4882, -2.1033, -2.2417, -3.2087, -1.7249],\n",
      "        [-1.0395, -3.5213, -2.1316, -2.8134, -1.3987],\n",
      "        [-0.9950, -1.3072, -2.4219, -2.0817, -1.4664],\n",
      "        [-2.0235, -1.0316, -1.8388, -1.7453, -1.5717],\n",
      "        [-0.9626, -2.5981, -1.1414, -0.9795, -0.5838],\n",
      "        [-0.8097, -1.8220, -1.7362, -3.0921, -1.3148],\n",
      "        [-1.6974, -1.3702, -2.0252, -2.5794, -1.9683],\n",
      "        [-1.5123, -3.2161, -2.6058, -2.3475, -1.6742],\n",
      "        [-0.5310, -0.5548, -1.3318, -1.2637, -1.6874],\n",
      "        [-1.0397, -2.1338, -1.6266, -1.9768, -1.2114]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(221.3695, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-3.8335, -1.2060, -2.9492, -2.1329, -2.8014],\n",
      "        [-4.3522, -1.8608, -4.1776, -2.7558, -2.4951],\n",
      "        [-2.8507, -1.2572, -2.9997, -3.3685, -3.6863],\n",
      "        [-2.4496, -2.9529, -2.4806, -2.2812, -2.7245],\n",
      "        [-3.5042, -3.1290, -3.5474, -2.3843, -2.2173],\n",
      "        [-2.9902, -1.9752, -3.3903, -3.4375, -3.4933],\n",
      "        [-1.9814, -4.1328, -2.7754, -2.0696, -3.7407],\n",
      "        [-2.6954, -4.4067, -2.2533, -2.0801, -4.0403],\n",
      "        [-3.1797, -3.9742, -4.1529, -2.0741, -4.2352],\n",
      "        [-1.7245, -2.3259, -2.7448, -1.9468, -4.2891]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(366.2690, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(223.9694, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 4 | LR: 0.10 | Total loss: -223.97 | Epoch time 0.34\n",
      "-D_kl(R)    >> tensor(-6.8621, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7234, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-89.6456, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-427.9667, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-8.8373, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(8.0936, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.4158, -3.9506, -1.9917, -2.8842, -1.4162],\n",
      "        [-2.9155, -2.7843, -1.4719, -3.4867, -1.0471],\n",
      "        [-1.1315, -3.2120, -2.1423, -2.4554, -1.5098],\n",
      "        [-2.0131, -2.1383, -1.9871, -1.6910, -1.6295],\n",
      "        [-4.4964, -2.2218, -2.6605, -1.7227, -1.3957],\n",
      "        [-0.8291, -0.8221, -2.3683, -2.0330, -1.2053],\n",
      "        [-1.5773, -2.5166, -1.9561, -3.4351, -1.4993],\n",
      "        [-1.8243, -1.2238, -1.4447, -1.1943, -1.0675],\n",
      "        [-1.2920, -1.1776, -1.7606, -1.4218, -1.7106],\n",
      "        [-0.7886, -0.5999, -1.5545, -1.4627, -1.0293]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(233.9135, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-3.6808, -4.0609, -3.6100, -2.9212, -4.3399],\n",
      "        [-4.0040, -3.4054, -2.6070, -1.9043, -4.2796],\n",
      "        [-3.8278, -2.6769, -4.1565, -2.5854, -3.5043],\n",
      "        [-4.1039, -1.1254, -3.9022, -2.9187, -4.3350],\n",
      "        [-3.6568, -3.9345, -3.4114, -2.2424, -4.3213],\n",
      "        [-3.7297, -2.0306, -2.5385, -2.5360, -4.3814],\n",
      "        [-3.3400, -3.0158, -4.0566, -2.3212, -2.2075],\n",
      "        [-4.0898, -1.7921, -3.7258, -2.4607, -4.0680],\n",
      "        [-4.3975, -4.9366, -4.2677, -2.5076, -4.0674],\n",
      "        [-4.4752, -4.4786, -3.3990, -2.2747, -3.7018]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(425.7887, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(115.8810, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 5 | LR: 0.10 | Total loss: -115.88 | Epoch time 0.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(R)    >> tensor(-5.5839, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7978, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-74.2476, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-264.0706, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-17.2408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(17.8710, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.0727, -0.1734, -1.4224, -1.3917, -1.8244],\n",
      "        [-1.0268, -2.6293, -1.7299, -1.2248, -3.2870],\n",
      "        [-1.5848, -2.2194, -2.4338, -1.7844, -3.0385],\n",
      "        [-1.4991, -1.4684, -1.9980, -3.4239, -1.2594],\n",
      "        [-1.9378, -2.2759, -2.1205, -2.0439, -1.6798],\n",
      "        [-1.1244, -0.9954, -2.1763, -2.0427, -1.5459],\n",
      "        [-0.9584, -0.6329, -2.1512, -4.5284, -1.3898],\n",
      "        [ 0.1641,  0.1949, -1.2183, -1.5445, -0.7132],\n",
      "        [-1.3757, -1.0327, -2.3023, -1.6635, -1.6538],\n",
      "        [-1.1221, -1.7656, -1.5951, -1.2172, -1.0526]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(204.9826, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-4.4599, -3.1001, -3.4822, -2.8953, -2.3360],\n",
      "        [-4.0587, -6.2993, -2.7430, -2.3779, -4.5857],\n",
      "        [-1.9119, -4.0167, -2.2557, -2.7221, -3.6629],\n",
      "        [-3.7073, -4.3993, -4.1894, -2.7616, -4.0556],\n",
      "        [-3.5537, -6.3925, -3.3134, -2.9333, -4.4239],\n",
      "        [-4.6359, -4.2071, -3.1737, -2.3197, -4.0158],\n",
      "        [-4.7098, -4.3799, -4.3488, -2.7892, -4.0481],\n",
      "        [-3.7922, -2.8686, -4.2434, -2.8691, -4.3070],\n",
      "        [-2.9578, -3.6212, -2.8378, -1.9645, -4.1072],\n",
      "        [-3.2987, -5.4457, -3.7630, -2.5811, -3.9354]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(454.6444, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(287.9142, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 6 | LR: 0.10 | Total loss: -287.91 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-6.0499, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7282, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5713, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-77.2265, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-187.6648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.8729, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(7.3871, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.1900, -0.9823, -2.0765, -1.9526, -2.5161],\n",
      "        [-1.1423, -1.5432, -2.0652, -1.6385, -1.6130],\n",
      "        [-1.3197, -2.7245, -1.6101, -1.6485, -1.0790],\n",
      "        [-0.8474, -2.0465, -1.7808, -1.7989, -2.2645],\n",
      "        [-2.9156, -1.9501, -1.4981, -2.1767, -1.8842],\n",
      "        [-2.2504, -0.9967, -1.9485, -1.4683, -2.3014],\n",
      "        [-1.3343, -1.3681, -1.6073, -1.5730, -1.7704],\n",
      "        [-1.0311, -0.9355, -2.1333, -1.4675, -2.3148],\n",
      "        [-0.8638, -2.1913, -1.5707, -1.1666, -1.3915],\n",
      "        [-1.3208, -1.8983, -2.0912, -1.7592, -1.5497]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(211.4205, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-2.6539, -5.2973, -3.9738, -2.8795, -2.9301],\n",
      "        [-4.6348, -2.1084, -4.4096, -1.9694, -4.5786],\n",
      "        [-4.1142, -6.5309, -4.3868, -2.7528, -4.6908],\n",
      "        [-4.4476, -5.2300, -2.7496, -2.0119, -4.5169],\n",
      "        [-2.3293, -6.4676, -3.6743, -2.6718, -4.1822],\n",
      "        [-4.3120, -5.1209, -4.1296, -2.3377, -4.4151],\n",
      "        [-3.5573, -6.5560, -4.3745, -2.5859, -4.7640],\n",
      "        [-4.2801, -6.4466, -4.3589, -2.0747, -4.7834],\n",
      "        [-4.7002, -5.7549, -3.8849, -2.1846, -4.5834],\n",
      "        [-3.6029, -6.1753, -4.2101, -3.3458, -1.5700]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(500.7519, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(419.8694, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 7 | LR: 0.10 | Total loss: -419.87 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-6.0874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7197, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5608, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-74.2565, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-187.6821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.0212, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(5.9137, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.9629, -1.2312, -2.2763, -1.8463, -3.0878],\n",
      "        [-1.3770, -2.1272, -2.0930, -1.4088, -1.5500],\n",
      "        [-3.0733, -2.8009, -1.3488, -1.1651, -0.8211],\n",
      "        [-2.2818, -0.7799, -1.7768, -1.3346, -2.7940],\n",
      "        [-0.8656, -0.5233, -1.9374, -1.9577, -1.6812],\n",
      "        [-1.5277, -0.8267, -3.0408, -1.3579, -1.3620],\n",
      "        [-1.5904, -1.4629, -1.7600, -1.2141, -1.8979],\n",
      "        [-1.2144, -1.0938, -2.2993, -2.4165, -1.3354],\n",
      "        [-0.9564, -1.4838, -1.8205, -2.5488, -1.2632],\n",
      "        [-1.8322, -2.1874, -2.5794, -2.6676, -2.0721]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(219.7831, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-2.3448, -5.6239, -4.7025, -2.4129, -4.5698],\n",
      "        [-4.0058, -6.8820, -4.6189, -1.9670, -3.6037],\n",
      "        [-4.6468, -7.0646, -4.7284, -2.4019, -4.7574],\n",
      "        [-4.7811, -6.8677, -4.6375, -2.0465, -4.4933],\n",
      "        [-2.7898, -2.0401, -3.1592, -1.9906, -4.5177],\n",
      "        [-3.7569, -5.5084, -3.0234, -2.5788, -3.5079],\n",
      "        [-4.6330, -7.2569, -2.9392, -2.0077, -1.9485],\n",
      "        [-4.8371, -4.7058, -2.9820, -2.6093, -4.2962],\n",
      "        [-3.1950, -4.7450, -4.4917, -3.0159, -4.7897],\n",
      "        [-3.9225, -6.9734, -4.5073, -3.1553, -3.5702]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(501.5274, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(432.7934, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 8 | LR: 0.10 | Total loss: -432.79 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-6.0972, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7266, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5524, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-86.7457, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-159.6185, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.5177, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(6.3537, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.5192, -1.2375, -2.5454, -1.8365, -1.9440],\n",
      "        [-2.3311, -1.6533, -1.9532, -1.6699, -3.2937],\n",
      "        [-1.3531, -0.5387, -1.3706, -1.3030, -2.2954],\n",
      "        [-2.4528, -2.1489, -1.9778, -1.5129, -3.4219],\n",
      "        [-0.1233, -1.5224, -1.1576, -0.9108, -2.1297],\n",
      "        [-1.4622, -2.0531, -1.7862, -3.2909, -2.8406],\n",
      "        [-1.2547, -1.7625, -2.7495, -1.6630, -1.4906],\n",
      "        [-1.1876, -2.4653, -2.3767, -2.3402, -1.6104],\n",
      "        [-0.8595, -1.1563, -1.6830, -1.7097, -1.5728],\n",
      "        [-1.9803, -1.5709, -2.7139, -2.5888, -2.3200]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(231.7292, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-4.9242, -6.7323, -4.2183, -2.1616, -4.6367],\n",
      "        [-4.4898, -5.2641, -4.9750, -3.0231, -3.6055],\n",
      "        [-3.7876, -7.0523, -4.8320, -2.8974, -4.7047],\n",
      "        [-4.9570, -7.7080, -4.9430, -2.9412, -4.9673],\n",
      "        [-4.7668, -7.2796, -4.7687, -2.6807, -4.9494],\n",
      "        [-4.1568, -7.3972, -3.9567, -2.9759, -5.0652],\n",
      "        [-4.1864, -6.2465, -4.8111, -2.3189, -4.7332],\n",
      "        [-3.2635, -6.7950, -4.6656, -2.8079, -4.9398],\n",
      "        [-3.7891, -5.5297, -4.9773, -2.0168, -4.8607],\n",
      "        [-3.4370, -6.4657, -4.9009, -2.0520, -4.5877]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(570.5080, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(528.7898, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 9 | LR: 0.10 | Total loss: -528.79 | Epoch time 0.29\n",
      "-D_kl(R)    >> tensor(-6.1356, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7222, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5440, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-117.5889, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-229.0313, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-9.1577, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(5.9943, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.1263, -1.2329, -1.9524, -1.7584, -1.4981],\n",
      "        [-1.1338, -1.0032, -2.0712, -1.6939, -1.6620],\n",
      "        [-1.2737, -1.7758, -1.6120, -1.6757, -1.6994],\n",
      "        [-1.8357, -1.1281, -2.1773, -2.2638, -1.7360],\n",
      "        [-1.0715, -1.1304, -2.0179, -3.1349, -1.4136],\n",
      "        [-1.3497, -1.6737, -1.7556, -1.8762, -1.3888],\n",
      "        [-2.6838, -1.7944, -2.6017, -2.2914, -3.3625],\n",
      "        [-1.4549, -2.6173, -2.0644, -2.1250, -1.7695],\n",
      "        [-1.7310, -2.8134, -2.7132, -1.8177, -3.2834],\n",
      "        [-1.6114, -2.0415, -2.0201, -1.2714, -1.8294]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(232.5486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-5.2103, -7.5642, -5.2685, -2.8874, -4.9394],\n",
      "        [-5.3222, -6.9982, -4.5976, -2.8756, -2.9703],\n",
      "        [-4.1603, -2.7197, -4.2542, -2.0368, -4.9978],\n",
      "        [-4.5657, -7.5591, -4.2361, -2.6939, -3.2240],\n",
      "        [-4.7149, -7.9090, -4.3429, -3.2219, -5.1282],\n",
      "        [-4.9593, -6.5431, -3.6546, -2.2200, -2.6256],\n",
      "        [-2.7136, -6.5180, -4.8136, -2.3914, -3.5789],\n",
      "        [-2.8148, -7.7717, -5.0621, -2.0899, -4.9869],\n",
      "        [-3.5949, -4.7222, -5.0182, -2.2594, -4.4188],\n",
      "        [-4.7226, -7.3776, -2.7759, -3.0198, -3.5913]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(546.6059, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(406.7853, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 10 | LR: 0.10 | Total loss: -406.79 | Epoch time 0.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(R)    >> tensor(-5.5971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7540, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5360, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-71.7821, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-356.0113, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-21.9563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(26.7698, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-0.8406, -2.1552, -1.0613, -1.2930, -0.5475],\n",
      "        [-1.0531, -1.6461, -1.9066, -1.4095, -2.7820],\n",
      "        [-2.1520, -1.3426, -2.3542, -1.9531, -2.1098],\n",
      "        [-1.3982, -1.6479, -2.3456, -2.0244, -2.8065],\n",
      "        [-1.8710, -0.3270, -1.3711, -0.9141, -0.9106],\n",
      "        [-1.1283, -0.9416, -1.6925, -1.9056, -1.0195],\n",
      "        [-0.9201, -1.6789, -1.8756, -1.3026, -2.0436],\n",
      "        [-1.2031, -3.1585, -2.3891, -1.5114, -3.9784],\n",
      "        [-1.1171, -2.6896, -2.2844, -1.7142, -1.5410],\n",
      "        [-0.4961, -0.7547, -1.5170, -1.3993, -1.3181]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(204.5075, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-4.6508, -6.4916, -5.1862, -2.4886, -5.3978],\n",
      "        [-4.8625, -6.7512, -3.9332, -2.0225, -2.9292],\n",
      "        [-5.0065, -8.3261, -5.2548, -2.1274, -3.4474],\n",
      "        [-5.2204, -8.2885, -4.6326, -2.8919, -5.2767],\n",
      "        [-5.4452, -8.2079, -4.8102, -2.1113, -3.5622],\n",
      "        [-4.5106, -8.4149, -4.7086, -2.6682, -5.1344],\n",
      "        [-5.1501, -7.9875, -5.1095, -2.9820, -5.4575],\n",
      "        [-3.9896, -7.7775, -4.0727, -3.1245, -5.1090],\n",
      "        [-3.5468, -7.6188, -5.3951, -2.4188, -2.4940],\n",
      "        [-4.6205, -7.9509, -3.8354, -2.0620, -4.4689]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(599.8270, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(338.5084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 11 | LR: 0.10 | Total loss: -338.51 | Epoch time 0.29\n",
      "-D_kl(R)    >> tensor(-6.1465, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6652, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5320, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-69.3109, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-232.7251, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-11.9799, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(9.9569, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.0063, -0.7301, -1.4980, -0.8555, -0.8314],\n",
      "        [-0.8972, -0.6036, -1.4219, -1.2433, -0.8296],\n",
      "        [-2.3287, -1.7687, -2.0096, -1.8875, -1.5465],\n",
      "        [-0.6074, -1.6719, -1.5772, -1.1194, -1.2883],\n",
      "        [-2.4270, -1.4061, -1.6604, -1.8626, -1.1957],\n",
      "        [-1.2769, -1.1214, -1.7277, -1.5776, -1.2447],\n",
      "        [-3.1610, -1.1889, -2.5351, -3.1326, -3.6841],\n",
      "        [-2.2926, -3.2685, -2.1033, -2.1390, -2.3356],\n",
      "        [-1.1379, -2.6793, -1.3782, -0.8788, -0.9027],\n",
      "        [-3.9658, -2.8513, -3.0081, -1.9954, -2.0044]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(219.6627, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-5.6733, -8.6167, -5.3817, -2.2400, -2.2686],\n",
      "        [-4.7400, -6.9675, -3.2244, -2.9040, -1.7468],\n",
      "        [-5.2553, -8.4481, -5.4076, -2.2412, -4.0009],\n",
      "        [-3.8354, -8.6011, -4.8662, -2.2895, -4.7051],\n",
      "        [-3.7007, -5.0254, -5.7416, -2.7865, -5.1886],\n",
      "        [-4.6599, -5.9323, -5.8315, -2.2940, -4.5113],\n",
      "        [-4.5853, -7.8442, -4.1546, -2.6215, -5.2334],\n",
      "        [-4.6111, -4.7153, -5.8909, -2.2882, -5.1700],\n",
      "        [-4.1719, -4.2961, -5.3351, -2.9663, -4.6822],\n",
      "        [-4.2884, -6.1759, -5.4964, -2.0722, -4.1589]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(574.6077, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(463.7215, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 12 | LR: 0.10 | Total loss: -463.72 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-6.3563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6537, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5295, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-84.7366, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-185.5513, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-13.6951, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(10.5479, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-2.2691, -1.2073, -1.9595, -1.5142, -2.6017],\n",
      "        [-2.9699, -2.0747, -2.6555, -2.2521, -3.1638],\n",
      "        [-0.7393, -1.3397, -1.1240, -0.6264, -0.8144],\n",
      "        [-1.9618, -1.8707, -2.0956, -1.5869, -1.5085],\n",
      "        [-2.8294, -1.5501, -2.1852, -2.0635, -2.0690],\n",
      "        [-2.0077, -1.2583, -2.0459, -1.8074, -1.7723],\n",
      "        [-1.7620, -0.8855, -1.8579, -1.4479, -2.6090],\n",
      "        [-1.7682, -2.3326, -1.9336, -2.3344, -1.8917],\n",
      "        [-0.5922, -1.3402, -1.4561, -1.6978, -1.0391],\n",
      "        [-1.4649, -2.0772, -2.2321, -2.2145, -3.0755]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(229.8405, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-5.1881, -8.3355, -3.2728, -2.2390, -4.2699],\n",
      "        [-5.2145, -7.7087, -5.7108, -2.5899, -2.8446],\n",
      "        [-5.8998, -8.6026, -5.5015, -2.1440, -3.7515],\n",
      "        [-5.9608, -7.7697, -5.4784, -2.4684, -5.5780],\n",
      "        [-4.9046, -8.2134, -6.1229, -2.9000, -5.4796],\n",
      "        [-5.4955, -8.6818, -5.5808, -2.1662, -5.2468],\n",
      "        [-5.5234, -9.1151, -5.7888, -2.5859, -3.3633],\n",
      "        [-4.5652, -8.0728, -5.9719, -2.5654, -5.6975],\n",
      "        [-5.6710, -8.7720, -5.9884, -2.9374, -3.9688],\n",
      "        [-5.5652, -7.1865, -5.8536, -2.4043, -5.1415]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(655.1451, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(584.2738, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 13 | LR: 0.10 | Total loss: -584.27 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-6.5376, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6307, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5266, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-94.0568, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-289.9560, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-15.9401, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(15.6769, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.0875, -1.1861, -1.8509, -2.1708, -1.5927],\n",
      "        [-1.8592, -0.8952, -1.8327, -1.3396, -1.8906],\n",
      "        [-2.2900, -1.1407, -2.3676, -1.9443, -1.7394],\n",
      "        [-2.2627, -1.7041, -1.8377, -1.7434, -2.1190],\n",
      "        [-1.5234, -2.0981, -2.0976, -1.6132, -2.4304],\n",
      "        [-1.5691, -2.1155, -2.2320, -1.5661, -1.6953],\n",
      "        [-0.7864, -1.2873, -1.5954, -4.6874, -1.0114],\n",
      "        [-2.2527, -1.3703, -1.7939, -1.2399, -1.7446],\n",
      "        [-2.2631, -2.8626, -2.6773, -2.5414, -2.0368],\n",
      "        [-1.8619, -1.9578, -2.8142, -2.9999, -1.9939]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(238.9330, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-5.4396, -9.2223, -4.9689, -2.2788, -5.4037],\n",
      "        [-5.3659, -9.0332, -5.3184, -2.6888, -5.0487],\n",
      "        [-6.0024, -8.5177, -6.2685, -2.2851, -5.6286],\n",
      "        [-4.7434, -9.5963, -6.4314, -2.1971, -5.1722],\n",
      "        [-5.6084, -9.4397, -6.2290, -2.2249, -4.3323],\n",
      "        [-6.1178, -9.4855, -6.2597, -2.3790, -4.9786],\n",
      "        [-4.8669, -8.7009, -3.7177, -2.2042, -5.7448],\n",
      "        [-4.7811, -9.4141, -5.1552, -2.2694, -5.5223],\n",
      "        [-5.2915, -9.0954, -6.2688, -2.6694, -4.4560],\n",
      "        [-5.6558, -8.8928, -5.7998, -2.6929, -3.8563]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(689.3028, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(511.3986, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 14 | LR: 0.10 | Total loss: -511.40 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-6.4998, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6059, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5250, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-62.6096, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-378.1952, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-16.2676, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(18.3051, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.8621, -3.8879, -2.6716, -1.7969, -1.8774],\n",
      "        [-1.0782, -1.1024, -2.0242, -1.5647, -1.5974],\n",
      "        [-1.6891, -1.2412, -1.7077, -0.9770, -1.2479],\n",
      "        [-5.3482, -2.5388, -2.1412, -1.9177, -1.8616],\n",
      "        [-2.1961, -0.3016, -1.3152, -2.1322, -1.3656],\n",
      "        [-2.3167, -1.3068, -2.2302, -1.8296, -1.8702],\n",
      "        [-1.2731, -1.3484, -1.6874, -1.2873, -2.0960],\n",
      "        [-1.2841, -1.5859, -1.8660, -1.9273, -2.4907],\n",
      "        [-0.6178, -1.2477, -1.6392, -1.2762, -1.0562],\n",
      "        [-1.8520, -3.3304, -2.0936, -1.4713, -1.4353]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(224.6588, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-6.4213, -8.5248, -5.1790, -2.5958, -5.8582],\n",
      "        [-5.1831, -7.2395, -5.8153, -2.8153, -5.4053],\n",
      "        [-6.2437, -9.3657, -6.0411, -2.4272, -5.6764],\n",
      "        [-5.7234, -9.9046, -6.3701, -2.6713, -5.8068],\n",
      "        [-5.6271, -6.7466, -5.8010, -3.0006, -5.6958],\n",
      "        [-5.9948, -9.0341, -3.8291, -2.1616, -5.5783],\n",
      "        [-4.7424, -9.7490, -4.0974, -2.1967, -3.5547],\n",
      "        [-5.6750, -5.6134, -6.1713, -2.7030, -5.1774],\n",
      "        [-5.9262, -8.6823, -4.0112, -2.6553, -5.6148],\n",
      "        [-5.0056, -9.6375, -6.8250, -2.5520, -5.2388]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(686.4144, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(437.1807, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 15 | LR: 0.10 | Total loss: -437.18 | Epoch time 0.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(R)    >> tensor(-6.5231, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-59.6747, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-183.5610, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-9.8608, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(5.6736, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-3.1173, -1.0466, -1.9875, -1.5542, -1.7948],\n",
      "        [-2.7722, -2.5369, -2.3722, -2.2305, -1.8618],\n",
      "        [-1.6465, -1.1006, -1.8434, -1.3255, -1.4055],\n",
      "        [-1.6261, -1.5094, -1.7246, -1.8349, -1.9115],\n",
      "        [-1.1579, -2.0521, -1.8683, -1.4193, -1.5538],\n",
      "        [-0.4163, -0.5238, -1.2947, -0.7309, -1.5593],\n",
      "        [-2.0129, -2.6498, -2.4831, -2.0113, -2.4804],\n",
      "        [-1.9057, -1.4349, -2.2418, -2.9497, -1.6255],\n",
      "        [-1.2298, -1.6833, -2.2834, -1.3130, -1.3030],\n",
      "        [-2.8194, -1.5431, -2.1956, -3.7297, -0.9976]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(226.6781, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -6.0392, -10.2244,  -5.4214,  -2.1653,  -6.1539],\n",
      "        [ -5.7790, -10.2662,  -4.8803,  -2.9316,  -4.7565],\n",
      "        [ -6.4104,  -9.7126,  -4.9714,  -2.2776,  -6.2379],\n",
      "        [ -6.4059, -10.5360,  -6.9029,  -2.5608,  -6.1014],\n",
      "        [ -5.9987, -10.0423,  -7.0485,  -2.1679,  -5.7852],\n",
      "        [ -6.4031, -10.1291,  -3.1885,  -2.2690,  -3.9996],\n",
      "        [ -6.3489,  -9.1175,  -6.8605,  -2.2998,  -6.1402],\n",
      "        [ -5.9078,  -8.0937,  -6.0347,  -2.2965,  -5.7736],\n",
      "        [ -4.9493, -10.3833,  -5.1777,  -2.6347,  -5.7883],\n",
      "        [ -6.4643, -10.1346,  -6.1320,  -2.4496,  -5.8932]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(741.6162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(698.3744, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 16 | LR: 0.10 | Total loss: -698.37 | Epoch time 0.30\n",
      "-D_kl(R)    >> tensor(-6.6790, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5241, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-92.4190, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-252.2358, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-13.9915, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(12.0480, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-0.8964, -1.9267, -2.7589, -1.8581, -1.1905],\n",
      "        [-0.6048, -2.3342, -1.6435, -1.1096, -1.6011],\n",
      "        [-1.8559, -1.8049, -2.3275, -1.7808, -2.4179],\n",
      "        [-1.4882, -1.2199, -1.8670, -1.6671, -1.6549],\n",
      "        [-3.8673, -2.4073, -2.5705, -2.2121, -2.2086],\n",
      "        [-1.7827, -3.2661, -1.4612, -0.9271, -1.1861],\n",
      "        [-3.4883, -1.3736, -2.6022, -1.9357, -2.0464],\n",
      "        [-1.7187, -0.7021, -3.1767, -1.2853, -1.7001],\n",
      "        [-2.9442, -1.2818, -2.0255, -1.4426, -1.6135],\n",
      "        [-1.4463, -1.6335, -2.3711, -1.7814, -1.9149]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(235.9518, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -5.8249,  -0.9920,  -6.9573,  -2.2423,  -6.4840],\n",
      "        [ -6.7235,  -5.7803,  -4.7536,  -2.6576,  -6.3647],\n",
      "        [ -6.0670,  -9.1877,  -6.5573,  -2.8017,  -6.1075],\n",
      "        [ -6.4393, -10.8479,  -6.8725,  -2.2784,  -6.2255],\n",
      "        [ -4.8293, -10.2929,  -6.2285,  -2.2809,  -6.3603],\n",
      "        [ -6.2519,  -9.4784,  -7.1395,  -2.5305,  -6.4854],\n",
      "        [ -5.9158,  -8.0408,  -6.7504,  -2.6829,  -6.1268],\n",
      "        [ -5.6184, -10.7624,  -6.6097,  -2.2237,  -6.5038],\n",
      "        [ -6.3802, -10.6033,  -3.6976,  -2.3006,  -4.9218],\n",
      "        [ -5.1242,  -8.7471,  -5.2494,  -2.3935,  -6.4429]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(727.8448, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(588.1655, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 17 | LR: 0.10 | Total loss: -588.17 | Epoch time 0.29\n",
      "-D_kl(R)    >> tensor(-6.8125, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5770, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5250, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-77.9674, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-186.4156, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.0326, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(6.5112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-2.2950, -1.8614, -2.8214, -2.4199, -1.6080],\n",
      "        [-2.3575, -1.3768, -1.6882, -1.2200, -1.4502],\n",
      "        [-1.7140, -1.6259, -2.2745, -2.2151, -1.9409],\n",
      "        [-2.3652, -1.3522, -2.2265, -1.6268, -1.7263],\n",
      "        [-1.1834, -1.0124, -1.9360, -1.4378, -1.7052],\n",
      "        [-2.2430, -0.9410, -1.9347, -1.4224, -1.5619],\n",
      "        [-1.1429, -1.2517, -2.1797, -1.7935, -1.9056],\n",
      "        [-0.8106, -1.7153, -1.5284, -0.9746, -1.5540],\n",
      "        [-1.4016, -2.9072, -2.1526, -2.7515, -2.1826],\n",
      "        [-2.0316, -1.4119, -1.9659, -1.1895, -1.6678]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(220.1559, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -4.7787, -11.3639,  -7.3204,  -2.5787,  -4.9076],\n",
      "        [ -6.8485, -10.6157,  -6.6616,  -2.8641,  -6.5384],\n",
      "        [ -5.1044, -10.6842,  -7.5400,  -2.4281,  -6.5043],\n",
      "        [ -5.5852, -11.1012,  -6.9956,  -2.3871,  -6.3060],\n",
      "        [ -6.6078,  -7.5324,  -6.9899,  -2.2523,  -3.8925],\n",
      "        [ -5.2645, -11.3589,  -4.8111,  -2.3953,  -6.7546],\n",
      "        [ -6.7901,  -8.9029,  -6.3853,  -2.4814,  -6.7282],\n",
      "        [ -6.2535, -11.2122,  -7.2602,  -2.4635,  -6.7968],\n",
      "        [ -6.9850, -10.2135,  -6.5078,  -2.5620,  -6.2713],\n",
      "        [ -5.9649,  -8.4550,  -7.6318,  -2.9535,  -6.6150]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(791.0176, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(719.6541, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 18 | LR: 0.10 | Total loss: -719.65 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-6.6849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5261, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-74.3795, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-310.5632, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.0726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(8.5905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-3.2205, -2.2727, -2.5068, -1.8150, -1.9485],\n",
      "        [-1.3373, -1.4103, -2.4094, -2.1680, -1.7364],\n",
      "        [-0.9775, -1.0022, -1.9787, -0.7565, -0.8528],\n",
      "        [-1.4400, -2.0979, -1.8522, -1.8287, -2.1688],\n",
      "        [-2.3366, -2.5598, -1.8357, -1.5032, -1.6105],\n",
      "        [-1.9217, -1.4649, -2.1529, -2.0484, -1.8592],\n",
      "        [-2.5970, -2.0283, -2.3847, -4.4817, -2.3583],\n",
      "        [-0.9042, -1.2328, -2.5773, -1.2807, -2.4025],\n",
      "        [-0.6637, -1.1756, -1.4312, -1.0653, -1.0983],\n",
      "        [-2.2730, -3.0081, -2.4313, -1.8568, -1.9010]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(235.5623, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -4.6416, -10.7094,  -7.2756,  -2.8399,  -5.3047],\n",
      "        [ -7.2178,  -9.9916,  -6.8458,  -2.3238,  -5.4063],\n",
      "        [ -6.3274,  -9.9369,  -4.7752,  -2.5067,  -6.1342],\n",
      "        [ -6.9797, -11.3703,  -8.0058,  -2.9017,  -6.0862],\n",
      "        [ -5.6107,  -9.6077,  -3.1959,  -2.2680,  -6.5979],\n",
      "        [ -6.7789,  -9.7943,  -7.9326,  -2.4753,  -7.1309],\n",
      "        [ -7.2007, -11.2919,  -5.0504,  -2.6615,  -3.7030],\n",
      "        [ -6.6975, -11.3530,  -7.2823,  -2.6854,  -6.8462],\n",
      "        [ -6.7931, -10.5308,  -3.7184,  -2.6400,  -5.7646],\n",
      "        [ -6.5110, -10.4734,  -5.4623,  -2.9089,  -6.1887]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(786.8389, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(610.4043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 19 | LR: 0.10 | Total loss: -610.40 | Epoch time 0.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(R)    >> tensor(-6.2363, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6127, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5273, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-65.1310, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-192.7416, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-12.0345, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(9.0763, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.0998, -1.3293, -2.4298, -1.5746, -1.5949],\n",
      "        [-2.0974, -3.6211, -2.2102, -2.3247, -2.1124],\n",
      "        [-1.9554, -0.5224, -1.4039, -1.4198, -1.3515],\n",
      "        [-0.8009, -1.1661, -1.6830, -1.1832, -2.4377],\n",
      "        [-0.9916, -1.4656, -1.3329, -1.9417, -1.8886],\n",
      "        [-1.9033, -2.0400, -2.3103, -2.3693, -1.7121],\n",
      "        [-1.1945, -1.2577, -1.8724, -1.5232, -1.8042],\n",
      "        [-2.8941, -1.6173, -1.9776, -2.2019, -1.9030],\n",
      "        [-1.7951, -4.6123, -2.2322, -2.3805, -1.8652],\n",
      "        [-1.1872, -3.3571, -2.0208, -2.6409, -1.7134]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(235.8105, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -7.2389, -10.4107,  -7.1500,  -2.9399,  -5.4408],\n",
      "        [ -6.7605, -11.1406,  -7.0875,  -2.3458,  -6.8457],\n",
      "        [ -7.4171,  -9.6479,  -7.0004,  -2.9729,  -6.8593],\n",
      "        [ -7.3489, -11.5279,  -6.4376,  -2.6399,  -6.6253],\n",
      "        [ -6.2843,  -8.5748,  -7.3369,  -2.4906,  -5.3502],\n",
      "        [ -5.7037, -12.2580,  -7.4590,  -2.7995,  -3.6125],\n",
      "        [ -2.8842, -11.1808,  -7.5650,  -2.9469,  -7.0155],\n",
      "        [ -6.9654, -11.7871,  -7.3960,  -2.4545,  -5.4060],\n",
      "        [ -7.3289, -10.5456,  -6.9841,  -2.3450,  -6.9261],\n",
      "        [ -6.2136, -10.1025,  -7.3277,  -2.3845,  -2.8145]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(815.7023, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(765.0399, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 20 | LR: 0.10 | Total loss: -765.04 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-6.4693, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6001, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-72.7348, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-211.3741, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.9778, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(8.1648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-3.2643, -2.6105, -3.0276, -2.3476, -2.7141],\n",
      "        [-2.6048, -1.1470, -1.9335, -1.4076, -1.7923],\n",
      "        [-2.4234, -1.1749, -2.5699, -1.6267, -1.8289],\n",
      "        [-1.4188, -1.4143, -1.9847, -1.7786, -1.8526],\n",
      "        [-3.3494, -1.1973, -2.1901, -1.6522, -1.9031],\n",
      "        [-1.6376, -0.9990, -1.5717, -1.0689, -1.3623],\n",
      "        [-2.4211, -2.7344, -2.1920, -3.2121, -1.9421],\n",
      "        [-1.1818, -0.8561, -1.6697, -2.7032, -1.4561],\n",
      "        [-1.3626, -0.8377, -1.4625, -2.0168, -1.5656],\n",
      "        [-1.3298, -1.3028, -2.1945, -2.2086, -1.9743]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(236.1937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -6.9134, -12.3501,  -7.9333,  -2.2593,  -7.2410],\n",
      "        [ -7.0271, -11.4360,  -7.8719,  -2.2644,  -6.7806],\n",
      "        [ -5.5881, -12.2815,  -6.0952,  -2.3994,  -6.6989],\n",
      "        [ -7.4782, -11.9373,  -7.5296,  -2.5800,  -6.8834],\n",
      "        [ -7.3494, -12.0270,  -5.3361,  -2.6143,  -6.7697],\n",
      "        [ -5.1805,  -9.5674,  -8.0834,  -2.5650,  -6.6912],\n",
      "        [ -7.5353, -10.5593,  -8.0215,  -2.8187,  -6.9209],\n",
      "        [ -6.8499, -10.9364,  -7.1969,  -2.3610,  -4.1899],\n",
      "        [ -7.4552, -12.2129,  -6.0384,  -2.2819,  -6.4790],\n",
      "        [ -7.6411, -12.5819,  -8.1157,  -2.7574,  -6.8586]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(868.8612, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(793.1797, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 21 | LR: 0.10 | Total loss: -793.18 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-6.4574, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5980, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5332, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-65.7324, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-198.9730, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-13.3486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(10.6254, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.5615, -1.2389, -2.2610, -2.6374, -1.9315],\n",
      "        [-2.0124, -1.5818, -2.2030, -1.9736, -1.8404],\n",
      "        [-1.9787, -1.4592, -1.5404, -2.0355, -1.3687],\n",
      "        [-1.4171, -2.7057, -1.7917, -2.0515, -1.4695],\n",
      "        [-1.4114, -1.0031, -1.9777, -2.8592, -2.0058],\n",
      "        [-1.2291, -1.8673, -2.4026, -2.5187, -1.7458],\n",
      "        [-0.7010, -1.6457, -1.5012, -0.8187, -1.0166],\n",
      "        [-2.9208, -1.0130, -1.9791, -1.5599, -2.0069],\n",
      "        [-1.3068, -1.7753, -2.2237, -2.0981, -1.8424],\n",
      "        [-1.5965, -2.1495, -1.6659, -2.0469, -1.4577]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(223.5150, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -7.8616, -12.4040,  -7.1640,  -2.9146,  -6.7435],\n",
      "        [ -7.7229, -12.9352,  -8.4555,  -2.4817,  -6.1751],\n",
      "        [ -7.7515, -13.2150,  -8.4022,  -2.8156,  -7.1822],\n",
      "        [ -7.6885, -12.3428,  -7.1755,  -2.5533,  -7.4236],\n",
      "        [ -6.6415, -11.3023,  -8.0174,  -2.4118,  -5.8283],\n",
      "        [ -7.2619,  -8.2678,  -8.3935,  -2.8549,  -6.5980],\n",
      "        [ -6.9536, -10.5407,  -8.1742,  -2.4160,  -6.9613],\n",
      "        [ -7.6882,  -7.3969,  -7.1943,  -2.9432,  -7.4136],\n",
      "        [ -7.8739, -11.0733,  -8.3428,  -2.7671,  -7.3575],\n",
      "        [ -7.1776, -11.6152,  -8.4028,  -2.7516,  -5.1734]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(898.0079, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(826.6909, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 22 | LR: 0.10 | Total loss: -826.69 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-6.7578, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5768, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5359, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-59.3837, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-247.8321, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-9.7400, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(8.1815, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-0.6551, -0.6146, -1.5505, -1.5442, -1.8354],\n",
      "        [-1.1530, -1.3473, -1.3596, -1.7629, -1.1625],\n",
      "        [-1.3216, -3.4285, -2.0968, -1.5716, -1.8919],\n",
      "        [-0.3486, -0.5297, -1.2298, -1.4270, -0.8788],\n",
      "        [-1.6734, -2.5915, -2.4418, -1.9367, -3.4165],\n",
      "        [-1.4662, -1.0516, -1.9138, -1.3490, -1.9350],\n",
      "        [-0.7208, -2.7877, -1.5459, -1.1533, -1.8571],\n",
      "        [-1.2506, -1.3043, -1.9964, -2.7625, -1.8567],\n",
      "        [-2.2476, -1.1941, -2.1556, -1.7280, -2.0545],\n",
      "        [-2.6419, -1.8573, -1.6561, -1.5929, -1.7978]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(209.1144, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -8.1855, -13.2407,  -8.3180,  -2.7329,  -7.4720],\n",
      "        [ -8.0954, -12.4448,  -8.4770,  -2.6523,  -7.1671],\n",
      "        [ -6.9110, -11.3249,  -7.8914,  -2.5842,  -5.6295],\n",
      "        [ -8.1915, -11.7380,  -8.7511,  -2.4504,  -6.5675],\n",
      "        [ -7.7744,  -9.8626,  -8.7271,  -2.5366,  -7.4694],\n",
      "        [ -7.7239, -11.6431,  -8.6419,  -2.3091,  -6.1580],\n",
      "        [ -4.6477, -13.5348,  -8.6835,  -2.7426,  -7.7127],\n",
      "        [ -6.0710, -13.4579,  -7.6075,  -2.7664,  -6.6645],\n",
      "        [ -7.6964, -13.4276,  -8.0928,  -2.5238,  -7.3221],\n",
      "        [ -8.1823, -11.5924,  -8.3754,  -2.3849,  -7.6923]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(937.1249, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(812.2237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 23 | LR: 0.10 | Total loss: -812.22 | Epoch time 0.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(R)    >> tensor(-6.6315, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-82.5042, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-262.6206, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-12.5174, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(9.7245, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.7032, -1.1056, -1.9814, -1.8869, -1.8462],\n",
      "        [-1.3657, -2.0395, -2.0821, -1.9767, -2.4437],\n",
      "        [-3.1338, -2.0457, -2.4680, -2.3993, -2.2776],\n",
      "        [-3.6672, -3.6434, -2.5999, -3.9113, -2.8790],\n",
      "        [-0.6456, -0.3574, -1.3173, -1.0382, -1.4655],\n",
      "        [-1.6168, -1.6473, -2.1947, -2.9522, -2.1414],\n",
      "        [-1.4205, -1.8049, -1.8083, -1.2553, -2.4579],\n",
      "        [-2.0406, -1.1916, -2.9273, -2.0318, -2.5433],\n",
      "        [-1.4978, -1.4448, -2.7137, -2.9905, -1.8962],\n",
      "        [-2.8880, -1.1301, -2.0637, -2.3447, -1.9115]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(257.9874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -6.7497, -13.4533,  -8.9928,  -2.3227,  -7.0357],\n",
      "        [ -8.1314, -13.7218,  -9.0352,  -2.7788,  -7.7551],\n",
      "        [ -8.3618, -14.0617,  -8.6367,  -2.8827,  -6.9545],\n",
      "        [ -8.3762, -13.8335,  -7.9013,  -2.7607,  -7.8184],\n",
      "        [ -6.7293, -13.9929,  -8.0287,  -2.6305,  -6.9212],\n",
      "        [ -7.1245, -13.9198,  -6.8515,  -2.4856,  -6.8208],\n",
      "        [ -8.3312, -12.4220,  -7.9532,  -2.3825,  -7.7312],\n",
      "        [ -7.7332, -13.1132,  -8.5446,  -2.4624,  -6.2932],\n",
      "        [ -5.5073, -11.6916,  -8.4484,  -2.9370,  -5.4498],\n",
      "        [ -8.2186, -14.0510,  -8.5017,  -2.4470,  -7.1545]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(971.1059, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(854.5055, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 24 | LR: 0.10 | Total loss: -854.51 | Epoch time 0.29\n",
      "-D_kl(R)    >> tensor(-6.4245, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5929, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5424, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-53.3884, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-226.3452, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-11.1828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(8.8265, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-0.5969, -1.5269, -1.8270, -0.7152, -1.1539],\n",
      "        [-1.0994, -1.8245, -1.8529, -2.6648, -1.5411],\n",
      "        [-2.0360, -1.2931, -2.0618, -1.5038, -2.0792],\n",
      "        [-2.5834, -1.1734, -1.4668, -4.5560, -1.5971],\n",
      "        [-1.0796, -3.3289, -2.7419, -1.5794, -1.8796],\n",
      "        [-1.4130, -1.4296, -1.9533, -1.6407, -1.6978],\n",
      "        [-0.8737, -1.0430, -1.7318, -2.5162, -1.5534],\n",
      "        [-2.7681, -1.9420, -2.7183, -2.4362, -2.6745],\n",
      "        [-2.5347, -3.1607, -2.3593, -1.6451, -2.1232],\n",
      "        [-3.3348, -1.7830, -1.7626, -1.8770, -1.5428]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(240.6928, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -6.0480, -14.1427,  -9.2633,  -2.5091,  -5.8629],\n",
      "        [ -5.5353, -11.7571,  -6.5286,  -2.4004,  -8.3311],\n",
      "        [ -8.5789, -14.2563,  -5.9047,  -2.2901,  -4.8891],\n",
      "        [ -5.6860, -13.6801,  -4.5369,  -2.5216,  -6.3956],\n",
      "        [ -4.8456, -13.6989,  -6.7985,  -2.8627,  -7.2901],\n",
      "        [ -7.3035, -13.1439,  -8.9890,  -2.5503,  -6.3605],\n",
      "        [ -8.7125, -14.5976,  -6.7371,  -2.2794,  -7.5173],\n",
      "        [ -8.3718, -10.6941,  -5.4035,  -2.3251,  -6.7543],\n",
      "        [ -7.7618, -13.2369,  -8.1099,  -2.2726,  -4.9923],\n",
      "        [ -4.0452, -12.6793,  -6.7491,  -2.8743,  -7.9915]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(897.6657, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(830.6930, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 25 | LR: 0.10 | Total loss: -830.69 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-6.5258, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5934, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5448, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-58.6723, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-175.5577, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-8.5985, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(3.1025, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-2.0480, -2.8342, -2.2042, -2.1193, -2.2452],\n",
      "        [-1.7864, -1.2681, -1.8976, -2.6243, -1.6772],\n",
      "        [-1.6232, -3.3749, -2.3781, -2.8807, -3.3126],\n",
      "        [-1.3301, -2.1322, -2.1803, -2.6345, -2.0129],\n",
      "        [-1.4739, -1.3490, -2.4499, -1.8720, -2.1592],\n",
      "        [-1.3689, -3.9368, -1.9852, -1.9539, -1.7647],\n",
      "        [-1.9648, -2.8192, -2.1819, -1.6396, -1.8468],\n",
      "        [-1.0317, -1.1172, -1.7163, -2.8892, -2.4644],\n",
      "        [-1.5827, -2.8545, -2.2068, -1.6521, -2.0397],\n",
      "        [-1.8901, -1.7962, -1.9151, -2.9887, -1.7456]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(263.0501, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -8.0298, -14.8639,  -8.3576,  -2.5706,  -5.5285],\n",
      "        [ -8.4472, -14.9754,  -9.5420,  -2.6100,  -8.2851],\n",
      "        [ -6.8286,  -9.5706,  -9.5125,  -2.2917,  -7.4402],\n",
      "        [ -8.1483, -15.2350,  -6.4823,  -2.3182,  -6.7443],\n",
      "        [ -8.7406, -15.2665,  -8.5613,  -2.5984,  -6.5802],\n",
      "        [ -8.6440, -15.1816,  -7.4761,  -2.7588,  -7.7388],\n",
      "        [ -5.4781, -14.4989,  -9.5224,  -2.5793,  -7.6892],\n",
      "        [ -7.7721, -14.6337,  -8.5412,  -2.5320,  -5.6818],\n",
      "        [ -6.9829, -11.5577,  -9.2627,  -2.4178,  -7.1349],\n",
      "        [ -6.3061, -12.3042,  -9.0430,  -2.6056,  -3.8152]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(979.2176, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(982.5858, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 26 | LR: 0.10 | Total loss: -982.59 | Epoch time 0.29\n",
      "-D_kl(R)    >> tensor(-6.4219, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6155, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5467, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-66.4865, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-185.9183, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.2693, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(7.1997, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.4642, -0.9217, -1.9038, -3.0821, -1.6553],\n",
      "        [-2.6954, -0.8052, -1.9930, -1.1396, -1.8847],\n",
      "        [-1.3996, -1.0748, -2.1362, -1.6508, -1.7056],\n",
      "        [-1.3229, -1.7649, -2.1781, -2.1258, -2.2585],\n",
      "        [-1.1649, -0.7357, -1.5665, -0.9438, -2.3249],\n",
      "        [-0.6508, -1.6882, -1.3921, -0.9322, -1.3484],\n",
      "        [-0.9516, -2.6443, -1.6238, -0.9475, -1.9010],\n",
      "        [-1.8650, -1.3069, -2.4997, -1.9298, -2.2824],\n",
      "        [-4.8385, -1.9799, -2.1724, -2.1521, -1.9788],\n",
      "        [-1.2904, -1.1808, -2.1819, -2.2708, -1.9549]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(219.6552, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -8.3270, -15.0546,  -8.4387,  -2.5767,  -8.2221],\n",
      "        [ -8.8975, -14.5638,  -8.1668,  -2.3542,  -8.0818],\n",
      "        [ -8.7558, -12.8509,  -8.4274,  -2.3201,  -8.2261],\n",
      "        [ -8.4701, -14.7694,  -6.5178,  -2.7757,  -7.3472],\n",
      "        [ -8.7874, -15.2074,  -9.4510,  -2.3435,  -8.4323],\n",
      "        [ -9.0128, -14.9594,  -9.7107,  -2.3716,  -8.3071],\n",
      "        [ -9.0044, -14.8956,  -9.8131,  -2.3578,  -5.4866],\n",
      "        [ -8.8967, -15.1846,  -8.7482,  -2.3825,  -8.4902],\n",
      "        [ -8.6188, -15.7573,  -9.6658,  -2.3116,  -8.5002],\n",
      "        [ -7.9270, -13.0322,  -9.6304,  -2.5834,  -7.8674]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(1062.2018, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1002.4094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 27 | LR: 0.10 | Total loss: -1002.41 | Epoch time 0.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(R)    >> tensor(-6.4690, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6168, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5511, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-45.1636, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-196.3579, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-8.4932, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(4.8784, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.0142, -2.3777, -1.8927, -2.0529, -3.5538],\n",
      "        [-2.0222, -1.7901, -1.9028, -2.2327, -2.1758],\n",
      "        [-1.3047, -1.8004, -1.7510, -2.7845, -1.4965],\n",
      "        [-2.0160, -2.4049, -2.0583, -1.8797, -1.4941],\n",
      "        [-1.3713, -1.7455, -1.7853, -1.1506, -1.5762],\n",
      "        [-2.5490, -1.7961, -2.4386, -3.8367, -1.9010],\n",
      "        [-1.4582, -2.1301, -2.3043, -2.7244, -2.3923],\n",
      "        [-0.9518, -1.2471, -1.0731, -0.2115, -0.8839],\n",
      "        [-2.1585, -1.5391, -2.3822, -1.7902, -2.1571],\n",
      "        [-3.9499, -1.0686, -1.7086, -1.2525, -1.9459]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(238.7112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -7.9970, -15.6921,  -8.2470,  -2.6829,  -7.9860],\n",
      "        [ -8.5849, -15.4330,  -9.6509,  -2.4524,  -8.0907],\n",
      "        [ -9.3669, -16.4363, -10.1560,  -2.4123,  -8.3589],\n",
      "        [ -8.7286, -16.1732, -10.0875,  -2.4589,  -8.8348],\n",
      "        [ -8.8824, -14.2579, -10.1130,  -2.8798,  -7.9917],\n",
      "        [ -8.2946, -15.3564,  -9.6426,  -2.7639,  -6.8440],\n",
      "        [ -8.0529, -15.9235, -10.3512,  -2.4486,  -8.4564],\n",
      "        [ -8.6615, -13.0362,  -7.4960,  -2.3990,  -8.7099],\n",
      "        [ -5.9295, -14.1449, -10.2262,  -2.7256,  -8.0201],\n",
      "        [ -9.2666, -14.2108, -10.0784,  -2.7039,  -8.0416]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(1094.3489, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1066.2192, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 28 | LR: 0.10 | Total loss: -1066.22 | Epoch time 0.29\n",
      "-D_kl(R)    >> tensor(-6.5708, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6312, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5524, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-68.6610, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-252.6667, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.4134, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(7.9891, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-3.2264, -2.3281, -2.0803, -1.4816, -2.6074],\n",
      "        [-2.7596, -0.9298, -2.4271, -1.3335, -2.2256],\n",
      "        [-1.4286, -3.1987, -1.8430, -1.7048, -1.6968],\n",
      "        [-1.3334, -1.0927, -2.2043, -1.7371, -2.5893],\n",
      "        [-3.0423, -2.7646, -2.8052, -2.6697, -2.6975],\n",
      "        [-2.3333, -0.3988, -1.3654, -0.7677, -1.9001],\n",
      "        [-1.8328, -2.7832, -2.4834, -3.7100, -2.4380],\n",
      "        [-1.9770, -1.2598, -2.4831, -1.4266, -2.4067],\n",
      "        [-1.0468, -1.0766, -1.9081, -1.4240, -1.7786],\n",
      "        [-2.1297, -3.8502, -2.3246, -1.9787, -2.4456]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(259.3408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -9.3603, -15.1704,  -9.1714,  -2.8386,  -6.8624],\n",
      "        [ -8.2978, -15.6966,  -9.1691,  -2.7295,  -7.6192],\n",
      "        [ -9.6913, -16.0616,  -8.3713,  -2.4833,  -7.0202],\n",
      "        [ -8.1903, -16.8489,  -7.7035,  -2.7656,  -8.0400],\n",
      "        [ -9.6237, -16.8690,  -7.6567,  -2.3671,  -6.9388],\n",
      "        [ -4.5970, -12.9783,  -9.1526,  -2.6631,  -9.1109],\n",
      "        [ -8.2450, -16.4685,  -9.6707,  -2.5866,  -9.1378],\n",
      "        [ -9.3426, -11.8007,  -8.5146,  -2.5214,  -7.8092],\n",
      "        [ -8.9656, -11.7524,  -8.5216,  -2.4497,  -9.1949],\n",
      "        [ -8.8075, -15.3220, -10.5631,  -2.5898,  -9.1606]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(1073.6813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(984.3373, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 29 | LR: 0.10 | Total loss: -984.34 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-6.3724, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6459, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5564, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-42.0876, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-255.0634, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-7.1277, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(4.2737, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-2.1144, -2.8903, -1.8667, -1.5835, -1.9447],\n",
      "        [-1.6348, -2.8012, -2.7935, -1.4257, -2.1112],\n",
      "        [-3.2913, -0.8771, -2.3827, -1.9217, -1.6677],\n",
      "        [-2.0242, -1.3706, -2.5113, -2.0352, -1.9635],\n",
      "        [-1.7749, -2.9664, -1.7742, -2.1995, -1.6102],\n",
      "        [-1.7770, -1.3738, -2.4314, -1.6365, -1.7877],\n",
      "        [-0.7686, -2.6394, -2.0134, -1.4788, -1.8188],\n",
      "        [-2.9108, -1.6178, -2.0050, -2.4263, -1.7776],\n",
      "        [-1.6545, -2.6564, -1.8521, -1.5710, -2.0741],\n",
      "        [-0.6877, -1.2544, -1.4015, -1.2719, -1.1206]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(238.8591, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -9.9109, -15.3645, -10.6037,  -2.6293,  -8.8897],\n",
      "        [ -9.7897, -16.3491, -10.0470,  -2.3921,  -6.4582],\n",
      "        [ -9.8516, -14.1993,  -8.7292,  -2.9064,  -8.1032],\n",
      "        [ -8.4691, -16.0652, -10.2605,  -2.6768,  -4.4000],\n",
      "        [ -9.0772, -15.1447, -10.7862,  -2.7287,  -7.8981],\n",
      "        [ -9.5341, -13.9230,  -7.3933,  -2.4653,  -9.1751],\n",
      "        [ -9.8142, -17.0665, -10.5777,  -2.3438,  -7.6863],\n",
      "        [ -7.4612, -17.6097, -10.7891,  -2.6736,  -8.7678],\n",
      "        [ -9.8926, -17.7225,  -9.9084,  -2.4779,  -9.3902],\n",
      "        [ -9.5866, -13.9726, -10.2785,  -2.8868,  -8.1551]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(1138.2056, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1056.0220, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 30 | LR: 0.10 | Total loss: -1056.02 | Epoch time 0.29\n",
      "-D_kl(R)    >> tensor(-6.0621, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6832, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5583, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-48.6632, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-278.3765, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-16.0726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(17.7404, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-0.2201, -1.2253, -2.0164, -1.6467, -0.9642],\n",
      "        [-0.9000, -1.0032, -1.9354, -1.3225, -1.7135],\n",
      "        [-1.8378, -0.7848, -1.6637, -1.1739, -1.5520],\n",
      "        [-0.4486, -0.7447, -1.3885, -0.6014, -1.2863],\n",
      "        [-1.5002, -1.0789, -2.0373, -3.4081, -2.2028],\n",
      "        [-2.0611, -1.1384, -1.6247, -2.2497, -1.7446],\n",
      "        [-1.4893, -2.3580, -2.3324, -1.3816, -1.8765],\n",
      "        [-1.2743, -1.7096, -1.6612, -1.8730, -1.5455],\n",
      "        [-1.8268, -2.8089, -2.2722, -1.6237, -2.5551],\n",
      "        [-1.4876, -1.1776, -1.9992, -1.5204, -2.1511]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(200.9975, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -9.6682, -16.5790, -11.3006,  -2.6143,  -9.7366],\n",
      "        [ -9.7413, -17.5468, -11.1209,  -2.7287,  -8.2719],\n",
      "        [ -9.8863, -16.4624, -10.4546,  -2.7579,  -8.2337],\n",
      "        [ -9.6419, -18.1248, -11.2500,  -2.7726,  -9.6765],\n",
      "        [ -8.7954, -18.3942,  -9.3324,  -2.5323,  -5.9668],\n",
      "        [ -9.4797, -18.0067, -10.4565,  -2.5743,  -9.4262],\n",
      "        [ -7.4559, -14.4305,  -6.0023,  -2.5721,  -8.8944],\n",
      "        [-10.3654, -16.9881, -10.0448,  -2.6928,  -8.4738],\n",
      "        [ -9.9536, -18.3361, -10.4182,  -2.4542,  -7.7930],\n",
      "        [ -9.3828, -18.2643,  -7.9511,  -2.6686,  -9.4717]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(1195.3679, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1036.7600, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 31 | LR: 0.10 | Total loss: -1036.76 | Epoch time 0.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(R)    >> tensor(-6.5027, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6492, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5606, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-61.1691, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-171.2237, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-8.4756, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(4.4208, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-3.9678, -1.5582, -1.7752, -1.7722, -1.6835],\n",
      "        [-1.5327, -1.6478, -2.0433, -2.3291, -1.8158],\n",
      "        [-1.1979, -0.6877, -2.1213, -0.9459, -2.2713],\n",
      "        [-2.4733, -1.1888, -2.1933, -1.7657, -2.1953],\n",
      "        [-3.0255, -1.3265, -2.4125, -1.9337, -2.5610],\n",
      "        [-1.6003, -1.3823, -2.0285, -2.4809, -2.5099],\n",
      "        [-3.0214, -0.9047, -1.8518, -1.5833, -1.7271],\n",
      "        [-1.6733, -3.2392, -1.8351, -1.3557, -2.2757],\n",
      "        [-1.9912, -1.5381, -1.7755, -1.7431, -1.6636],\n",
      "        [-2.3516, -1.1133, -1.6048, -1.7469, -1.5074]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(237.3248, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -6.7391, -18.4040,  -9.3838,  -2.8301,  -9.7859],\n",
      "        [ -9.2637, -16.8713, -10.2382,  -2.8742,  -9.5700],\n",
      "        [ -9.4846, -18.2610,  -8.8160,  -2.4766,  -9.2862],\n",
      "        [-10.0378, -17.1305, -11.6474,  -2.4836,  -9.7632],\n",
      "        [-10.2313, -17.1679, -10.2416,  -2.5459,  -8.4739],\n",
      "        [ -6.9261, -13.6980, -10.7622,  -2.3600,  -7.6093],\n",
      "        [ -9.4370, -16.5771, -11.7931,  -2.3590,  -9.5083],\n",
      "        [-10.4899, -18.8025, -11.7647,  -2.3576,  -9.2585],\n",
      "        [ -9.3283, -18.9268, -11.0003,  -2.6279,  -9.6342],\n",
      "        [-10.4713, -18.6838,  -9.5153,  -2.4223,  -7.5600]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(1219.7039, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1199.2584, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 32 | LR: 0.10 | Total loss: -1199.26 | Epoch time 0.29\n",
      "-D_kl(R)    >> tensor(-6.4259, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6622, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5653, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-53.0730, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-192.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-11.2635, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(8.0918, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-0.8926, -0.7845, -2.7174, -2.5478, -1.8545],\n",
      "        [-1.3625, -1.5915, -2.1057, -2.2994, -1.8387],\n",
      "        [-2.2944, -1.1012, -2.2594, -1.7512, -2.3425],\n",
      "        [-2.4410, -1.8028, -2.0527, -2.0759, -2.1791],\n",
      "        [-0.6374, -1.0437, -1.6967, -1.4043, -1.4039],\n",
      "        [-1.0475, -1.7153, -1.7442, -1.6708, -1.9937],\n",
      "        [-1.2617, -2.7550, -2.2025, -2.4775, -2.4183],\n",
      "        [-1.8580, -2.6620, -2.3057, -2.2184, -2.2695],\n",
      "        [-1.4486, -1.8603, -2.3165, -1.5982, -2.2841],\n",
      "        [-1.3728, -0.7881, -2.3185, -1.5102, -2.2039]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(231.9555, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -9.1159, -13.5787,  -7.8944,  -2.5253,  -9.7139],\n",
      "        [ -9.9311, -18.5259, -11.4711,  -2.6435,  -9.9650],\n",
      "        [ -9.2429, -19.2117, -10.2852,  -2.6513,  -9.3347],\n",
      "        [ -9.2213, -17.9150, -12.0407,  -2.5701,  -8.6824],\n",
      "        [ -9.7331, -17.3988, -11.0314,  -2.6039,  -9.7883],\n",
      "        [-10.0977, -18.9141, -12.0013,  -2.5582,  -9.6812],\n",
      "        [ -6.0172, -19.2984, -10.6436,  -2.7255,  -8.7999],\n",
      "        [ -9.4386, -19.6876, -11.6882,  -2.6247,  -9.7709],\n",
      "        [ -9.8542, -19.0424,  -9.8866,  -2.8278,  -9.7130],\n",
      "        [-10.7622, -19.0287, -10.3264,  -2.7480,  -9.4012]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(1261.5330, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1219.6860, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 33 | LR: 0.10 | Total loss: -1219.69 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-6.5155, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6605, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5677, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-52.5336, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-152.3825, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-9.6725, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(5.4615, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.8296, -0.8476, -1.6367, -1.8497, -2.1979],\n",
      "        [-0.9275, -1.6991, -1.1408, -0.7658, -1.5344],\n",
      "        [-1.6876, -1.8553, -2.8245, -2.5309, -2.5764],\n",
      "        [-2.4948, -0.4679, -1.2899, -0.6476, -1.2400],\n",
      "        [-1.4085, -1.9978, -1.9948, -1.6249, -1.9123],\n",
      "        [-1.2004, -1.2764, -1.6523, -1.0330, -1.6487],\n",
      "        [-2.3821, -2.4493, -2.5614, -3.9187, -1.8904],\n",
      "        [-2.1996, -2.4059, -1.7790, -1.7398, -1.7683],\n",
      "        [-1.7690, -3.7622, -2.7710, -2.7984, -2.3682],\n",
      "        [-1.2137, -2.0922, -2.0155, -2.0524, -2.0156]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(234.3648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-10.2788, -17.5565, -10.6156,  -2.7653,  -9.7565],\n",
      "        [-10.9385, -20.1935, -12.3384,  -2.7472, -10.2419],\n",
      "        [-10.9721, -19.9498, -11.4524,  -2.7163, -10.2090],\n",
      "        [-10.8804, -20.2472, -12.3436,  -2.7751,  -6.5200],\n",
      "        [-11.1085, -19.3421, -11.8569,  -2.6145, -10.7762],\n",
      "        [-11.0824, -19.7095, -11.9700,  -2.3519,  -9.2817],\n",
      "        [-11.1117, -19.7893, -12.2517,  -2.6801,  -9.5432],\n",
      "        [ -9.3085, -15.8424, -12.1945,  -2.4697, -10.7633],\n",
      "        [ -9.4984, -20.3786, -10.1494,  -2.6677,  -9.6727],\n",
      "        [-10.8485, -19.5348, -11.6033,  -2.5855, -10.5176]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(1347.5070, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1350.3500, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 34 | LR: 0.10 | Total loss: -1350.35 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-6.6908, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6616, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5708, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-66.7596, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-239.0244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-13.6320, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(11.0785, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-2.7632, -2.0217, -2.4810, -2.0923, -2.4881],\n",
      "        [-1.3394, -1.0133, -2.2029, -1.5542, -1.7886],\n",
      "        [-1.1374, -2.0681, -1.9145, -1.2922, -1.8812],\n",
      "        [-1.5388, -2.6423, -2.1802, -2.6596, -2.0488],\n",
      "        [-1.6388, -2.2796, -2.0380, -2.5411, -1.9636],\n",
      "        [-1.4786, -1.0815, -2.0606, -1.2020, -1.8236],\n",
      "        [-1.1017, -1.0880, -2.4768, -2.3370, -1.8135],\n",
      "        [-3.1665, -5.3908, -1.7756, -1.4861, -2.2229],\n",
      "        [-1.5516, -1.3956, -1.8898, -2.8798, -2.2442],\n",
      "        [-2.0319, -1.5141, -1.7575, -1.0968, -1.9551]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(245.9767, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-11.3410, -18.8546, -12.9515,  -2.6031, -10.8866],\n",
      "        [-11.4676, -20.3961, -12.1616,  -2.6576,  -5.6806],\n",
      "        [-11.3178, -20.3156, -10.6864,  -2.5158,  -8.2318],\n",
      "        [-11.2688, -20.4449, -12.2755,  -2.7134,  -9.5629],\n",
      "        [ -7.9322, -20.0109, -10.3985,  -2.7712,  -8.1884],\n",
      "        [-10.8396, -19.8730, -12.8577,  -2.6637,  -8.6078],\n",
      "        [-10.6777, -20.0961, -11.7941,  -2.5828, -10.9914],\n",
      "        [-11.3914, -19.1647, -12.1283,  -2.4263,  -9.7886],\n",
      "        [-10.1588, -20.8600, -12.1095,  -2.4155,  -7.2687],\n",
      "        [ -9.9991, -20.4619, -12.8106,  -2.5317,  -8.6760]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(1352.0237, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1261.4719, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 35 | LR: 0.10 | Total loss: -1261.47 | Epoch time 0.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(R)    >> tensor(-6.7379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6506, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5766, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-57.2631, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-156.7678, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-7.6244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(2.6465, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.3767, -1.8357, -2.0607, -2.1644, -1.8740],\n",
      "        [-1.5376, -1.3132, -2.3938, -1.8569, -2.1179],\n",
      "        [-1.2732, -1.7874, -3.1198, -1.7117, -2.4709],\n",
      "        [-1.2613, -2.9470, -2.2968, -2.3430, -2.1227],\n",
      "        [-1.8253, -0.9689, -3.3643, -2.5311, -1.8264],\n",
      "        [-1.0977, -0.9215, -1.8082, -1.0756, -1.7791],\n",
      "        [-1.7467, -1.8542, -2.2937, -1.6328, -2.2148],\n",
      "        [-3.3080, -2.9683, -1.5745, -0.9354, -1.7842],\n",
      "        [-1.5664, -1.1381, -2.0703, -1.2910, -2.1394],\n",
      "        [-1.9003, -1.6351, -2.2361, -2.3546, -2.2259]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(239.8316, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-10.1993, -18.1819, -13.1170,  -2.4434,  -8.9360],\n",
      "        [-11.2884, -20.4000, -11.4680,  -2.5388,  -7.1779],\n",
      "        [ -9.4713, -17.1004, -12.2985,  -2.6380,  -8.6867],\n",
      "        [ -9.8863, -20.5482, -11.8159,  -2.6444, -10.2943],\n",
      "        [-11.6946, -20.6164, -12.0174,  -2.4234, -10.8374],\n",
      "        [ -9.3255, -17.1042, -11.8020,  -2.5607, -10.6916],\n",
      "        [-11.5744, -20.5129, -11.6508,  -2.7777,  -9.0461],\n",
      "        [-11.9153, -19.0597, -11.4368,  -2.5374, -10.5677],\n",
      "        [-11.4799, -21.8019, -12.8890,  -2.6292, -10.7064],\n",
      "        [-11.2898, -21.9482, -13.3242,  -2.4990,  -9.7220]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(1373.9411, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1374.9629, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 36 | LR: 0.10 | Total loss: -1374.96 | Epoch time 0.29\n",
      "-D_kl(R)    >> tensor(-6.6449, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6683, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5796, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-58.3154, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-267.4290, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.6090, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(9.7359, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.3879, -2.9993, -2.0383, -2.6109, -2.1402],\n",
      "        [-1.8307, -1.7841, -2.6172, -1.2004, -2.0363],\n",
      "        [-2.6516, -1.3777, -1.7063, -1.3388, -1.6932],\n",
      "        [-2.0652, -2.3373, -2.1861, -3.0492, -2.0191],\n",
      "        [-2.1858, -3.0641, -1.8588, -1.9566, -2.0867],\n",
      "        [-2.5943, -1.2159, -1.9139, -2.0017, -4.1469],\n",
      "        [-1.3011, -2.5125, -2.3948, -3.1537, -2.0415],\n",
      "        [-2.5836, -2.1965, -1.1558, -0.6351, -1.3813],\n",
      "        [-1.5618, -1.9831, -1.6331, -0.9832, -1.7409],\n",
      "        [-1.2054, -1.1967, -1.9237, -2.0707, -2.1308]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(249.6996, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-10.6142, -20.2079, -13.3996,  -2.5962,  -8.8299],\n",
      "        [-12.3488, -22.6253, -10.1434,  -2.6906, -10.7247],\n",
      "        [ -9.1165, -22.7622, -11.0672,  -2.4939,  -9.8734],\n",
      "        [ -9.7097, -22.2225, -12.7943,  -2.4900, -10.4008],\n",
      "        [-12.0099, -19.1399, -10.0831,  -2.7753,  -9.3634],\n",
      "        [-10.9789, -20.5489, -10.3859,  -2.5873, -10.9631],\n",
      "        [-12.0229, -20.2590, -13.5852,  -2.5236, -10.5692],\n",
      "        [-11.2123, -21.6635, -13.2064,  -2.5127,  -9.8917],\n",
      "        [-11.3239, -21.7802, -10.8617,  -2.6529, -10.9739],\n",
      "        [-11.4930, -22.7517, -11.4137,  -2.4754, -10.4959]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(1424.0385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1320.3026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 37 | LR: 0.10 | Total loss: -1320.30 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-6.4311, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5844, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-63.0227, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-200.7403, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-11.4811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(8.5169, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-1.6529, -1.2422, -2.9840, -2.7149, -1.8882],\n",
      "        [-0.7659, -2.1185, -1.6097, -1.5890, -1.8564],\n",
      "        [-2.2710, -1.8896, -1.7281, -1.5077, -1.6285],\n",
      "        [-1.1831, -1.1344, -2.8870, -2.8774, -2.6849],\n",
      "        [-2.6067, -1.6939, -2.3435, -2.2173, -2.7375],\n",
      "        [-2.0434, -1.8014, -2.1561, -3.1769, -3.9481],\n",
      "        [-1.7300, -1.0138, -1.7338, -2.2657, -1.7656],\n",
      "        [-2.8291, -1.4179, -2.8567, -1.7482, -3.4461],\n",
      "        [-1.3215, -1.2738, -2.0579, -4.1556, -2.4598],\n",
      "        [-1.7328, -2.1035, -2.1359, -1.1915, -1.7387]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(259.7908, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[ -9.9414, -23.3069, -12.8500,  -2.6022, -11.5733],\n",
      "        [-10.8400, -22.8303, -11.1349,  -2.6133, -10.2698],\n",
      "        [ -9.5353, -22.6516, -13.3413,  -2.5726, -11.2660],\n",
      "        [ -7.4249, -21.0110, -13.2134,  -2.5153,  -9.9823],\n",
      "        [-10.8306, -17.8219, -12.6645,  -2.4876, -11.5675],\n",
      "        [-11.4405, -18.6707, -12.2208,  -2.6306, -10.7631],\n",
      "        [ -6.0072, -22.7718, -10.1209,  -2.7172, -10.9245],\n",
      "        [ -7.6270, -23.4381, -12.2837,  -2.4861, -10.7551],\n",
      "        [ -9.3903, -22.8498, -10.2374,  -2.5954, -10.2287],\n",
      "        [-12.2333, -22.7303, -12.2619,  -2.5392, -11.2604]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(1420.0795, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1387.7404, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 38 | LR: 0.10 | Total loss: -1387.74 | Epoch time 0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/utils.py:124: UserWarning: cosh_dist has 0 in it!\n",
      "  warnings.warn(str('%s has 0 in it!' % variable))\n",
      "../src/utils.py:124: UserWarning: c has 0 in it!\n",
      "  warnings.warn(str('%s has 0 in it!' % variable))\n",
      "../src/utils.py:124: UserWarning: temp1 has 0 in it!\n",
      "  warnings.warn(str('%s has 0 in it!' % variable))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(R)    >> tensor(-6.4961, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6763, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5877, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-76.5493, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-209.9552, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-6.8279, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(2.6630, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-2.3062, -1.1195, -1.4603, -0.9887, -1.6716],\n",
      "        [-1.7135, -2.6264, -2.2027, -1.6055, -2.4167],\n",
      "        [-1.5832, -2.4147, -2.6407, -1.6719, -3.0941],\n",
      "        [-1.4012, -2.1039, -2.1146, -3.6317, -2.2801],\n",
      "        [-2.5724, -2.6600, -2.1930, -3.1202, -2.8948],\n",
      "        [-1.8902, -2.6840, -2.1430, -1.5417, -1.8539],\n",
      "        [-1.1144, -0.9099, -2.6673, -1.2270, -1.9642],\n",
      "        [-2.2705, -3.8551, -2.1688, -1.8596, -2.1789],\n",
      "        [-1.5150, -1.4434, -2.1017, -1.3181, -1.9174],\n",
      "        [-3.2443, -2.4669, -2.7927, -2.3698, -2.5972]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "P(q_ri)     >> tensor(266.4557, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[-12.2638, -23.2800, -13.4988,  -2.6611, -12.0299],\n",
      "        [-11.6631, -18.1238, -13.5659,  -2.5168, -11.7634],\n",
      "        [-11.0082, -23.8587, -11.7164,  -2.7153, -11.5082],\n",
      "        [-10.8982, -23.2996, -13.4193,  -2.7841, -11.0702],\n",
      "        [-12.3836, -24.4796, -13.8574,  -2.7545, -12.0312],\n",
      "        [-11.8742, -24.3746, -14.2662,  -2.7651, -11.3336],\n",
      "        [-12.4419, -23.4761, -14.0403,  -2.5387,  -9.3584],\n",
      "        [-12.3657, -24.5886, -14.3026,  -2.6255, -11.2744],\n",
      "        [-12.0314, -24.5958, -12.5339,  -2.8026, -11.9430],\n",
      "        [-12.2073, -23.8911, -14.0871,  -2.4510, -11.0987]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "P(q_phii)   >> tensor(1571.0471, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1527.2208, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'PowBackward1' returned nan values in its 1th output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0274d5090b06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git/VIRGMo/src/vi_hrg_approx.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, optimizer, lrs, epochs, momentum, debug)\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                    \u001b[0mcurr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m                    \u001b[0mepoch_counter\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/VIRGMo/src/vi_hrg_approx.py\u001b[0m in \u001b[0;36mtrain_\u001b[0;34m(self, epoch_num, debug)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function 'PowBackward1' returned nan values in its 1th output."
     ]
    }
   ],
   "source": [
    "with autograd.detect_anomaly():\n",
    "    vi.train(dataloader, lrs=0.1, debug=True, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8017, dtype=torch.float64, grad_fn=<ExpBackward>),\n",
       " tensor(0.3026, dtype=torch.float64, grad_fn=<ExpBackward>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.alpha_conc.exp(), vi.alpha_scale.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5000), tensor(0.5000))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_conc_init.exp(), alpha_scale_init.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(10.1540, dtype=torch.float64, grad_fn=<ExpBackward>),\n",
       " tensor(0.8774, dtype=torch.float64, grad_fn=<ExpBackward>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.R_conc.exp(), vi.R_scale.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_mean = Gamma(vi.R_conc.exp(), vi.R_scale.exp().reciprocal()).mean.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([ 1.2968,  1.3679,  0.3714,  1.2190, -0.3822], dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " tensor([1.3827, 1.4053, 1.2405, 1.3211, 1.2795], dtype=torch.float64,\n",
       "        grad_fn=<ExpBackward>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.rs_loc, vi.rs_scale.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_r = Radius(vi.rs_loc, vi.rs_scale.exp(), R_mean.expand([N]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.9966, 7.1012, 5.2726, 6.8772, 3.6138], dtype=torch.float64,\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_r.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.2345, 4.2333, 2.1902, 3.0441, 0.6701], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.8069, -1.6872, -2.0903, -1.8157, -2.1242], dtype=torch.float64,\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_samp = post_r.sample([50])\n",
    "post_r.log_prob(r_samp).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1871, dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_mean.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.8199,  0.0179, -0.0180],\n",
       "         [ 1.5305, -0.0207, -0.0073],\n",
       "         [ 0.8395, -0.0065, -0.0187],\n",
       "         [ 0.0422, -0.2112,  0.1066],\n",
       "         [ 0.8404, -0.0191,  0.0020]], dtype=torch.float64, requires_grad=True),\n",
       " tensor([6.9213, 9.9104, 7.8998, 0.8818, 6.5830], dtype=torch.float64,\n",
       "        grad_fn=<ExpBackward>))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.phis_loc, vi.phis_scale.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "total_loss = 0\n",
    "with autograd.detect_anomaly():\n",
    "    #print(torch.is_anomaly_enabled())\n",
    "    for idx1, idx2, data in dataloader:\n",
    "        loss = - vi.elbo(idx1, idx2, data, debug=True)\n",
    "        vi.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        vi.optimizer.step()\n",
    "        print('>>>>', loss)\n",
    "        total_loss += loss\n",
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hd_ = lambda d,R,T: (1.+((d-R)/(2.*T)).exp()).reciprocal()\n",
    "phd = lambda d,R,T: 0.5 + 0.5*(-(d-R)/(4*T)).tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hd_(torch.tensor(-np.inf),R,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phd(torch.tensor(5.1),R,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([0.1,10.0]).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0.,1.,.01)\n",
    "plt.plot(x, torch.sigmoid(logit(x)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit(torch.tensor(0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, n, m = 3, 4, 5\n",
    "broadcast = torch.ones([l,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(m).expand(n,m).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(n).expand(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(0.).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcosh = lambda x: (torch.clamp(x, min=1.) + (torch.clamp(x, min=1.)**2 - 1).sqrt())\n",
    "arcosh(torch.arange(0.,2., .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.clamp(x, min=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
