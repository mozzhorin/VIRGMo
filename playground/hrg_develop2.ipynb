{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd09a281b50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from vi_hrg_approx import *\n",
    "from utils import c2d, hyperdist, p_hd, polar2cart, warn_tensor\n",
    "from torch import autograd\n",
    "torch.manual_seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_r(x, R, rel_var=0.1, epsilon=1e-4):\n",
    "    rs = torch.distributions.normal.Normal(x, R*rel_var).sample() \n",
    "    return torch.clamp(rs, min=0+epsilon, max=R.item()-epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_phi(x, rel_var=0.1):\n",
    "    phis = torch.distributions.normal.Normal(x, 2*np.pi*rel_var).sample()\n",
    "    return phis % (2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = lambda x: (x/(1-x)).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAF6CAYAAAAUO1/9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAF4hJREFUeJzt3c1vVdd6x/HfMS/GYBsIhkvAYPNiqxlVqtTOkkkiRcosk7bjq/sn9EptJ0vrH+ig43QSVem0k3SUDNMMoqRSdEUSAw4BGwg2xu82fuF08Kyds31ig1/OOfvs/Xw/EopybM7ZOOH5rbX2s9au1et1AQD86in6AgAAxSIIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAMA5ggAAnCMIAGAX58+f763VardqtVpv0dfSbrV6vV70NQBA14gx9s3NzY3euXPn0x9++OHU9PT095L+WK/XXxZ9be1yvOgLAICixRhPSzqffg2sr6//3ebm5qVarTYpaVzSsKT7RV5jOxEEAFyKMZ6RFf5zknol1SVtSDrZ39//9ZMnT35YWVl5W9JfJE0Vd6Xtx9IQADdyxf+8pJOy4r8oaV7SS0k302sTCwsL73z//fdnv/zyy6+rvCwkMSMAUHExxn41iv8JNYr/Y0nzIYTtFBBjkrYlTYQQXsYYV959993VL774otIhIBEEAComxliTlBX/c2oU/wVJLyQthBC2c9/fLwuBTVkIbKQvbUo608FLLwxBAKD0mor/eVlte6VG8V/MF//c7xuUdEt2b2AihLCZ+/KmLEQqjyAAUEqp+A+oMfJvLv4LIYRXr/n9Z2UhsC4Lga2mb9mU1BNjPLZbiFQJQQCgNFLxH1Sj+B+TrevnR/57Fv/c+5yT3Rhek3R3lxCQLAgkmxUQBABQlBhjj3aO/LPiPy8r/kv7Kf6593tL0qikVVkI7FXk80GwfqiLLwmCAEDXScU/G/mf1e+L/2II4cC97zHGC7IQWJZ07w1LPvkgqDSCAEBXSMX/rBrFv0fSlqzwZyP/Q298ijEOSRqRtY7e38csgiAAgHZ7TfF/Liv+y0cp/rnPuSTpmuxewuR+lpLS/oJXIggAoLVijMfUKP6DsuK/qRYX/9znXZZ0VbasNHnA93bRQkoQAGi7VPzPqVH8a7IiOysr/iutLP65z31b0hVJc5IeHOIzNmVHUVQaQQCgLWKMx2XF/5waxX9D0jNJL0IIK23+/KuSLstmGr8cMmg2JZ1u6YV1IYIAQMvkiv95WctnTXaYW0eKf+46rkm6JGkmhPDwCG/F0hAAvEmM8YR2Fn/Jiv+vsuK/2uHruS7poqRnIYRHR3y7DTnYXUwQADiwVPyzDV5Z8V+X9ERW/NcKuKaarD30gqSnIYTpFryti93FBAGAfYkxnlRj5N+fXl5TgcU/d2012UaxtyQ9DiE8adFbu9hdTBAA2FMq/tmJntmRzGuys/xfhBAKL44pBG7KQmo6hPC0hW/vYlMZQQBghxhjrxrLPlnxX5U0LXuQS+HFP5M2pN2U7Ut4FEJ41uKPIAgA+BBjPKXGsk/WLrkiK/4vQghd95SuFAK3ZK2pD0MIM63+DC+7iwkCwKlU/LNln7708orsQe0vck/q6jppg9ot2Y3qByGE5238uMq3kBIEgCMxxj41iv+p9PKypEeyZZ+uLf6ZFAJjspnLzyGEuTZ/JEEAoNxijKfVWPbJiv+SpBnZyH9zr9/bbdKGtTHZDGYyhDDfgY/dVGPGVEkEAVBBqfhnI//e9PKSbIfvfJmKfyaFwLgszO6HEBY69NGbsvsQlUUQABURYzyjRvE/KakuK/5PZcV/t8cxlkLawDYu+3PdCyEsdvDjNyUdizH2HORJaGVCEAAlFmPsV2PZJyv+i7I+/4UyF/9M2sswLlunvxdCWOrwJeRbSLuue6oVCAKgRNLmqfzI/4R2Fv/5Kp2Jk/Y0jMseVXk3hLBcwGVkQXBSBAGAIqTi36/GJq+s+C/IzvJfqFLxz6T21jFZCEx0+vC6nKyTqrKdQwQB0IVS8R9QY9nnuKRXahT/xSoW/0wKgXHZMdY/FXmOkRzsLiYIgC6RK/7ZyL+5+C9U9WZlXtrrMC6b9fxU9JEWHnYXEwRAgVLxH1Sj+B+THXecH/lXvvhnUufTmOxnMNFFR1tUelMZQQB0WDojJyv+Z9Uo/vOy4r/kqfhnUgfUbUlbshDopl3OBAGAw6nVar2ShoeHh6f/9Kc/ZWf7nJPUo53Ff7EdD28vixjjgCwENtV9ISBVfHcxQQC0Sa1W67106dJ/jY2N/c3q6urPa2tr/9bX17cuK/7zss1er2RtiRdijHXZung9vV7f5deer5c1SGKMg7ID5DZkIdCNu54rvbu4Vq+X8v8doKvFGGuff/75325sbPznzZs3j83Ozh67du3av46Pj/8o64Rpl/2Gx4GDptWvhxDqMcazshBYl4VAV26AizFelnRV0v9VcdmOIABaLG2CGl1aWjr/2Wef/cv8/Pzw5cuXn3788cdhcHDwpxDCUrpJnP/V0/Tvh3m9Fe+x1+vtMCDpiuyJZw9lo+5Oh9N+v/f80tLSX3366adzMzMzk/V6vVtuYrcES0NAC8UYL8lGjvWBgYGJJ0+e/L2k4ZGRkWeDg4PXJY3FGH9J5+eXZhSWC65Whc1bsofMP5L0i+xn8ab3OUj4tVLfy5cvR3788cc/1+v1mqS/1Gq1P1YpDJgRAC2QZgEjslHugqRfmte6mx6m8iSE8LjjF9oFYowXZA+aX5KdHdTypZYUXEeZNR2XhdVFSacmJyevfvPNN//86NGjn5eXly9I+sd6vX6/1dddFIIAOKIY40VJw7JR7VQIYfY131uTdF3SkKxb6EEV15z3kn5W12VnI93vtj97amEdkoVATfbEtplPPvlkZWpq6j9kG90mJDEjAPDbqZgjsm6SRdksYF9tjzHGP8jCY0VWELuxU6alcn/mBdlDZboiBNJM7YIsAPpkbb1zkmbyR1tkrcCSpqoUAhJBABxKWt64Jhs1Th3mwekxxnOSbsg2UN0r+Dydtsp13byQPV6y8MKTdjFflO3t6JGF8qykuW4JqU4hCIADSA9IGZHtCF6WLe0cenSYniR2W1aIJjv8wJWOiDFekfS2bJT9oMgQSKP/bO2/T9Yd9FzSbIGnmxaOIAD2Kcb4lmx9uyZpOoTwrEXve1IWBqckPTrM7KJbxRivSrosG2k/LCoE0ug/W/vvkbSqxjObK3uK634RBMAbpGfljsiOhliRjWpbeiJmOn/opmym8Uy23FTqv5wxxmuSLsnW2h8W8PnZ6H9I0mnZ6D9b+3c7+t8NQQC8RozxvGwWcEzStKRn7SrQqaNoWFY8F2Rr6aUcrcYYR2QF+NcQwlSHP/u0bOknG/2vyUb/c2X9ebYbQQDsIs0CrsmKyaqsKHfkXPzUYnlNduzCvS48gG1PKcxGZF04T0MI0x363B411v6z0f8L2eh/pRPXUGYEAdAkdfNcl20qeiIraB39i5IOYrspK2j3yrCUkULghqwL53EI4UkHPvO0Gmv/x2Sj/1lJzxn97x9BACRpTfmabDS7JpsFFNbSmZ7UdVsWSD+HEOaLupY3SSFwU3YfZSqE8GsbPysb/Q9JOqPG6H+2oIfblx5BAOi3EfiorOg+lR0BUfhfjtSuektW8NpaYA+r6Ub3o1Z1U+3yOX1qrP0fky2dZWv/XXlqaVkQBHAtzQKGZaPLddnIu6uWYVKhHZUtuRTahtksXdst2e7qX153vMYR3v+8LADOyI7xyNb+Gf23CEEAt9JTsUZlD4bJZgFdu6M0tzFrSXYsRaFr4ClEb0vql7XUPm/he5+SFf8Laoz+s7V/Rv8tRhDAnTTKHJYVmnVZEStFZ0k62mJE0kvZTeRCzrxJITAm69D5OYTwogXv2SO7x3BRFi7Z6H82hLB01PfH3ggCuJJOlxyV1CvbuDXdzbOA3aQ/w630r/c7vUSSWmvHZEc0TB71JnYa/Q/JRv/HZSE3I0b/HUMQwIU02rwi6Q+yQvOgzGvM6fkHt2WB9iCEMNehzz0hC4FTshBaOOT71GRr/0Oy5zPUZc9xnmH033kEASovnTMzKiteM7Lum1LNAnaTRuY31aEH3aQQGJfdU7l3mIKdAixb+89G/9naf+WP4u5WBAEqK406r8gOPduQdbVU6nTPpp28c7I/Yzue+HVSFgInJN09yGwqXWO29p+N/hdko/9K/fcoK4IAlZR2nI7K1rFnZbOAyu40zZ33vyxbsmnZ2noaxY/Lunfu7vfGevp9Q+nXcVkYz8pu/jL67yIEASoljT7fls0CtmQj5EOtY5dNOiBvVNKmbOnmyGcjpRu547Kjt+++aY9FbvQ/JNtbkI3+ZyUtdsv+B+xEEKAy0s7TUVlL43PZLtfKzgJ2k+6H3FILHnSTfp5jshCYeN1xG2npKFv7PyFG/6VCEKD00ij0smwmsCXbedu15/K0W9ODbh4eZrdvWlobk43oJ3abXaSf+1lZAAymlxdkN+QZ/ZcIQYBSS0sXo7LjB17ICp/73vO04euGrFD/Ktsvsa+/7GlWMSZ7iPtE86a1FDTZ2v8J2VJUNvovzZHZaCAIUEppNHpJdoN0WxYAR97dWiVND7qZl+0Afm1HUdqsdls2s5rICnt6r0HZ6P9s+vZs7X+B0X+5EQQondSNMio7hmBeFgKsQ+8hxnhJdrz2quwm8q4/q3T20m3Z+v5ECGEzjf4vyEb/J8Xov5IIApRKKmpXZWvXDzu1o7bsYoxnZZvPtrXLg27SMdy3ZBu87spuuA/JOoAkaVG29s/ov4IIApRCmgWMyDYkLcjaQpkFHMBeD7pJT2S7KRvtv5Ad/ZCN/p/LRv+FHG6HziAI0PXSM3yHZbOAR6087tibdEzEbUmnp6amnn399ddDH3300bkzZ84cl4VAXTb6n5U0z+jfB4IAXSutT4/IblIuymYBrEsfUYzx5OLi4l9/++23/37ixInhhYWFyffee+/PAwMD02L079Lxoi8A2E2McUg2C6jJ7gXMFHxJpZS6ffpk7bX96Z+9Dx48uLK1tXX51KlTS3fu3Bn47rvvnm9tbU0Xea0oDkGArpKWLkZkLYpLslkAI9R9SieSntHOwt+TvrwpO4toZnt7e/Krr776X9nxEROSpgq4XHQJlobQNWKMb0m6LpsFTLfrIehVkjbUZQW/X7abWLK1/jVZ4V+RtNy8rFar1Xpls66per1O2DpGEKBwaRZwXdaquCybBRz5wLSqSbuFT2tn4T+WvrylVPDTP1eq8MwFdAZBgEKlEzOvywratKRndKqY1DKbX+I5nfvymnKFn+DEURAEKERay74u61lfkT1u0W0xS4/SPK2dhf9E+vK20ihfjcLv6lRVtBdBgI5LG5iuy5oVHkv61dssIC2H5Zd4TsvujUi2u/e3tX1J695+PugsggAdk9a4r8nOrlmVzQL2POO+KnItnPnCfzJ9+ZXsZ5G/qev+9FR0FkGAjkhn3YzIZgFPZQ9br+T/fLkWzqzw51s4N7Tzpu5qVX8OKA+CAG2VZgHDsgPM1mSzgNc+7rBs0hk++cKfb+Fc1c61fXZGo+sQBGibdKzxqGwZ5Kmkx2Uf/aZga96wlW/hzK/tr9LCiTIgCNByqQNmWPYQk3XZLGCl2Ks6nNTCmV/b78t9uXnDFpuyUEoEAVoqPeFqVFKv7BGJj8syKs61cOYLf3YMS9bCmd+wRQsnKoEgQEukInpV9ljEl7JZwHKxV/V66XTT5g1bWQvnunau7Ve+uwl+EQQ4svSw81HZTdIZSVPdNgtILZzNG7byLZzNG7Zo4YQbBAEOLc0C3pZ0WdYW+SCEsFTsVZnUwtm8YSvfwpm/qbtW9pvYwFEQBDiUGONpSTdks4BZ2SygkDXzNNpvPoWzN305a+HM39TlEZdADkGAA0lFN5sFbMlmAYsdvoashTO/YStr4dzU7zdsddUyFdBtCALsW9o4dUPWQvlc9vzgts8C0pn7+cKfb+Fs3rBFCydwQAQB3ijNAi7LZgJbskdHzrfps3r0+w1b+RbO5g1btHACR0QQ4LXSaPyG7GbrnGwW0LKOmtTC2bxhK9/CmV/bd3tMNdBOBAF2lWYBl2R7A7Zls4AXLXjP5g1b2Zn7WQtnfsMWLZxAB/DwevxOmgWMyor1vOzRkQcuyunM/eabuvkz95fUKPy0cAIFYUaAHWKM2SygLpsFzO3z92Vn7ucLf76Fs3nDFi2cQJcgCCDpt8PVRmVFfEE2C9izWOfO3M8X/mzD1qZ+f1OX/9GALkUQQDHGi7LTQuuym8HPd/me5g1b+TP3m0/h5Mx9oEQIAsdSx86IpEFJi7JZwEauhTNf+PNn7jff1GXDFlBiBIFTMcYh2SygJumZbFSfP4Uzs6ada/u0cAIVQxA48/777/f39/e/984776ivr++lrCso80o71/Y5cx9wgCBw5MMPPxxYWlr6n42NjSsbGxsPPvjgg386e/bsCzUK/zo3dQF/CAJHarXarStXrvz3ysrK9PLy8tD29vY/1Ov1+0VfF4BisaHMl6nHjx9/L2lc0k+Spgq+HgBdgBmBM7VarVd2k3iqXq9zUicAggAAvOt587cAAKqMIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHCOIAAA5wgCAHDu/wHUkYJoR3PQjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 5\n",
    "R = torch.tensor([5.0]).double()\n",
    "alpha = .7\n",
    "T = 0.1\n",
    "\n",
    "G = HRG(R=R, alpha=alpha, T=T)\n",
    "r, theta, A = G.generate(N)\n",
    "G.show()\n",
    "G.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_loc_init = logit(noise_r(r, R, rel_var=0.05)/R)*R/5\n",
    "r_scale_init = torch.ones([N]).double().log()\n",
    "phi_loc_init = torch.cat((polar2cart(1, noise_phi(theta, 0.02)),  torch.zeros([N,1]).double()), dim=-1)\n",
    "phi_loc_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8354,  1.9024, -0.4989,  0.5558, -1.4038], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_loc_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.3120, 4.3508, 1.8890, 3.1774, 0.9861], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Radius(r_loc_init, r_scale_init.exp(), R.expand([N])).mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_conc_init = torch.tensor(10.).log()\n",
    "R_scale_init = torch.tensor(1.).log()\n",
    "alpha_conc_init = torch.tensor(.5).log()\n",
    "alpha_scale_init = torch.tensor(.5).log()\n",
    "T_init = torch.tensor([3.,10.]).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0986, 2.3026])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(EdgesDataset(A), batch_size=N**2, shuffle=True, num_workers=0)\n",
    "vi = VI_HRG(N,10, init_values={'rs_loc':r_loc_init,\n",
    "                                'rs_scale':r_scale_init,\n",
    "                              'phis_loc':phi_loc_init,\n",
    "                              'phis_scale':None, \n",
    "                              'R_conc':R_conc_init, \n",
    "                              'R_scale':R_scale_init,\n",
    "                              'alpha_conc':alpha_conc_init,\n",
    "                              'alpha_scale':alpha_scale_init,\n",
    "                              'T':T_init})\n",
    "vi.dataloader = dataloader\n",
    "vi.optimizer = torch.optim.RMSprop(vi.parameters())\n",
    "#vi.optimizer.lr"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "total_loss = 0\n",
    "with autograd.detect_anomaly():\n",
    "    #print(torch.is_anomaly_enabled())\n",
    "    for idx1, idx2, data in dataloader:\n",
    "        loss = - vi.elbo(idx1, idx2, data, debug=True)\n",
    "        vi.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        vi.optimizer.step()\n",
    "        print('>>>>', loss)\n",
    "        total_loss += loss\n",
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>> Start training...\n",
      "-D_kl(R)    >> tensor(-7.4639, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8525, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.8176, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-125.9164, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-464.0568, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-26.1030, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(32.3456, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(204.5961, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(238.9009, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-190.9028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1 | LR: 0.10 | Total loss: 190.90 | Epoch time 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/utils.py:126: UserWarning: cosh_dist has 1 in it!\n",
      "  warnings.warn(str('%s has 1 in it!' % variable))\n",
      "../src/utils.py:126: UserWarning: c has 1 in it!\n",
      "  warnings.warn(str('%s has 1 in it!' % variable))\n",
      "../src/utils.py:126: UserWarning: p_raw has 1 in it!\n",
      "  warnings.warn(str('%s has 1 in it!' % variable))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(R)    >> tensor(-9.5246, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6422, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.7304, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-171.6600, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-232.0563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-11.0497, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(6.3521, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(268.8714, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(310.2925, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(144.3113, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2 | LR: 0.10 | Total loss: -144.31 | Epoch time 0.14\n",
      "-D_kl(R)    >> tensor(-8.0373, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6983, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6649, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-152.1694, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-230.9692, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-11.4421, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(9.0910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(223.8292, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(338.6838, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(149.3423, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 3 | LR: 0.10 | Total loss: -149.34 | Epoch time 0.13\n",
      "-D_kl(R)    >> tensor(-7.1408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7066, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6208, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-114.2788, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-220.4765, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-11.2563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(6.7153, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(221.3695, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(366.2690, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(223.9694, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 4 | LR: 0.10 | Total loss: -223.97 | Epoch time 0.13\n",
      "-D_kl(R)    >> tensor(-6.8621, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7234, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-89.6457, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-427.9668, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-8.8373, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(8.0936, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(233.9135, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(425.7887, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(115.8809, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 5 | LR: 0.10 | Total loss: -115.88 | Epoch time 0.37\n",
      "-D_kl(R)    >> tensor(-5.5839, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7978, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-74.2476, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-264.0706, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-17.2408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(17.8710, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(204.9826, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(454.6444, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(287.9141, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 6 | LR: 0.10 | Total loss: -287.91 | Epoch time 0.16\n",
      "-D_kl(R)    >> tensor(-6.0499, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7282, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5713, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-77.2261, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-187.6648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.8729, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(7.3871, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(211.4205, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(500.7527, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(419.8705, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 7 | LR: 0.10 | Total loss: -419.87 | Epoch time 0.13\n",
      "-D_kl(R)    >> tensor(-6.0874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7197, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5608, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-74.2566, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-187.6821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.0212, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(5.9137, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(219.7832, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(501.5270, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(432.7930, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 8 | LR: 0.10 | Total loss: -432.79 | Epoch time 0.34\n",
      "-D_kl(R)    >> tensor(-6.0972, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7266, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5524, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-86.7457, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-159.6185, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.5177, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(6.3537, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(231.7292, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(570.5077, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(528.7895, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 9 | LR: 0.10 | Total loss: -528.79 | Epoch time 0.13\n",
      "-D_kl(R)    >> tensor(-6.1356, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7222, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5440, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-117.5889, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-229.0313, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-9.1577, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(5.9943, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(232.5486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(546.6060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(406.7854, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 10 | LR: 0.10 | Total loss: -406.79 | Epoch time 0.10\n",
      "-D_kl(R)    >> tensor(-5.5971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7540, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5360, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-71.7822, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-356.0113, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-21.9563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(26.7698, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(204.5076, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(599.8272, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(338.5085, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 11 | LR: 0.10 | Total loss: -338.51 | Epoch time 0.13\n",
      "-D_kl(R)    >> tensor(-6.1465, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6652, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5320, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-69.3110, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-232.7251, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-11.9799, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(9.9569, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(219.6627, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(574.6071, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(463.7207, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 12 | LR: 0.10 | Total loss: -463.72 | Epoch time 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(R)    >> tensor(-6.3563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6537, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5295, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-84.7364, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-185.5512, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-13.6951, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(10.5479, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(229.8405, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(655.1453, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(584.2742, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 13 | LR: 0.10 | Total loss: -584.27 | Epoch time 0.11\n",
      "-D_kl(R)    >> tensor(-6.5376, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6307, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5266, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-94.0569, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-289.9560, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-15.9401, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(15.6769, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(238.9330, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(689.3020, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(511.3977, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 14 | LR: 0.10 | Total loss: -511.40 | Epoch time 0.10\n",
      "-D_kl(R)    >> tensor(-6.4998, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6059, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5250, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-62.6097, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-378.1951, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-16.2676, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(18.3051, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(224.6587, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(686.4142, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(437.1805, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 15 | LR: 0.10 | Total loss: -437.18 | Epoch time 0.10\n",
      "-D_kl(R)    >> tensor(-6.5230, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-59.6746, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-183.5610, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-9.8608, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(5.6737, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(226.6780, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(741.6168, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(698.3749, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 16 | LR: 0.10 | Total loss: -698.37 | Epoch time 0.10\n",
      "-D_kl(R)    >> tensor(-6.6790, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5241, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-92.4189, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-252.2358, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-13.9915, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(12.0480, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(235.9518, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(727.8445, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(588.1652, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 17 | LR: 0.10 | Total loss: -588.17 | Epoch time 0.13\n",
      "-D_kl(R)    >> tensor(-6.8125, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5770, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5250, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-77.9672, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-186.4156, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.0326, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(6.5112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(220.1559, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(791.0171, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(719.6538, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 18 | LR: 0.10 | Total loss: -719.65 | Epoch time 0.11\n",
      "-D_kl(R)    >> tensor(-6.6849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5261, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-74.3794, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-310.5632, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.0726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(8.5905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(235.5622, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(786.8396, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(610.4050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 19 | LR: 0.10 | Total loss: -610.41 | Epoch time 0.13\n",
      "-D_kl(R)    >> tensor(-6.2363, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6127, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5273, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-65.1310, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-192.7416, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-12.0345, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(9.0763, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(235.8106, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(815.7019, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(765.0396, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 20 | LR: 0.10 | Total loss: -765.04 | Epoch time 0.36\n",
      "-D_kl(R)    >> tensor(-6.4693, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6001, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-72.7348, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-211.3742, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.9778, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(8.1648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(236.1937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(868.8610, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(793.1794, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 21 | LR: 0.10 | Total loss: -793.18 | Epoch time 0.11\n",
      "-D_kl(R)    >> tensor(-6.4574, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5980, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5332, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-65.7324, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-198.9730, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-13.3486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(10.6254, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(223.5150, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(898.0081, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(826.6912, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 22 | LR: 0.10 | Total loss: -826.69 | Epoch time 0.10\n",
      "-D_kl(R)    >> tensor(-6.7578, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5768, dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(T)    >> tensor(-0.5359, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-59.3837, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-247.8321, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-9.7400, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(8.1815, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(209.1144, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(937.1250, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(812.2238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 23 | LR: 0.10 | Total loss: -812.22 | Epoch time 0.17\n",
      "-D_kl(R)    >> tensor(-6.6315, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-82.5042, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-262.6206, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-12.5174, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(9.7245, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(257.9874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(971.1058, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(854.5054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 24 | LR: 0.10 | Total loss: -854.51 | Epoch time 0.20\n",
      "-D_kl(R)    >> tensor(-6.4245, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5929, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5424, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-53.3884, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-226.3452, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-11.1828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(8.8265, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(240.6928, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(897.6648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(830.6920, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 25 | LR: 0.10 | Total loss: -830.69 | Epoch time 0.10\n",
      "-D_kl(R)    >> tensor(-6.5258, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.5934, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5448, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-58.6722, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-175.5577, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-8.5985, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(3.1025, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(263.0501, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(979.2178, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(982.5861, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 26 | LR: 0.10 | Total loss: -982.59 | Epoch time 0.11\n",
      "-D_kl(R)    >> tensor(-6.4219, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6155, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5467, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-66.4865, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-185.9183, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.2693, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(7.1997, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(219.6552, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1062.2016, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1002.4092, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 27 | LR: 0.10 | Total loss: -1002.41 | Epoch time 0.10\n",
      "-D_kl(R)    >> tensor(-6.4690, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6168, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5511, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-45.1636, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-196.3579, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-8.4932, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(4.8784, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(238.7112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1094.3489, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1066.2191, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 28 | LR: 0.10 | Total loss: -1066.22 | Epoch time 0.12\n",
      "-D_kl(R)    >> tensor(-6.5708, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6312, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5524, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-68.6610, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-252.6667, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.4134, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(7.9891, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(259.3408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1073.6814, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(984.3373, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 29 | LR: 0.10 | Total loss: -984.34 | Epoch time 0.10\n",
      "-D_kl(R)    >> tensor(-6.3724, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6459, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5564, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-42.0875, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-255.0634, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-7.1277, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(4.2737, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(238.8591, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1138.2060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1056.0225, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 30 | LR: 0.10 | Total loss: -1056.02 | Epoch time 0.13\n",
      "-D_kl(R)    >> tensor(-6.0621, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6832, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5583, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-48.6632, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-278.3765, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-16.0726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(17.7404, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(200.9975, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1195.3681, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1036.7602, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 31 | LR: 0.10 | Total loss: -1036.76 | Epoch time 0.10\n",
      "-D_kl(R)    >> tensor(-6.5027, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6492, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5606, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-61.1693, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-171.2237, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-8.4756, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(4.4208, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(237.3248, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1219.7021, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1199.2564, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 32 | LR: 0.10 | Total loss: -1199.26 | Epoch time 0.11\n",
      "-D_kl(R)    >> tensor(-6.4259, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6622, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5653, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-53.0728, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-192.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-11.2635, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(8.0918, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(231.9555, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1261.5320, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1219.6852, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 33 | LR: 0.10 | Total loss: -1219.69 | Epoch time 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(R)    >> tensor(-6.5155, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6605, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5677, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-52.5331, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-152.3825, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-9.6725, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(5.4615, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(234.3648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1347.5063, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1350.3499, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 34 | LR: 0.10 | Total loss: -1350.35 | Epoch time 0.13\n",
      "-D_kl(R)    >> tensor(-6.6908, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6616, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5708, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-66.7612, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-239.0244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-13.6320, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(11.0785, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(245.9767, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1352.0243, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1261.4709, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 35 | LR: 0.10 | Total loss: -1261.47 | Epoch time 0.10\n",
      "-D_kl(R)    >> tensor(-6.7379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6506, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5766, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-57.2611, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-156.7678, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-7.6244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(2.6465, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(239.8316, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1373.9491, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1374.9730, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 36 | LR: 0.10 | Total loss: -1374.97 | Epoch time 0.29\n",
      "-D_kl(R)    >> tensor(-6.6449, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6683, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5796, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-58.3190, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-267.4289, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-10.6090, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(9.7359, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(249.6996, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1424.0271, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1320.2876, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 37 | LR: 0.10 | Total loss: -1320.29 | Epoch time 0.13\n",
      "-D_kl(R)    >> tensor(-6.4311, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5844, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-63.0126, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-200.7403, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-11.4811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(8.5169, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(259.7903, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1420.1097, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1387.7803, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 38 | LR: 0.10 | Total loss: -1387.78 | Epoch time 0.10\n",
      "-D_kl(R)    >> tensor(-6.4961, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6763, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5877, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-76.5291, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-209.9561, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-6.8279, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(2.6630, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(266.4565, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1571.0663, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(1527.2602, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/utils.py:124: UserWarning: cosh_dist has 0 in it!\n",
      "  warnings.warn(str('%s has 0 in it!' % variable))\n",
      "../src/utils.py:124: UserWarning: c has 0 in it!\n",
      "  warnings.warn(str('%s has 0 in it!' % variable))\n",
      "../src/utils.py:124: UserWarning: temp1 has 0 in it!\n",
      "  warnings.warn(str('%s has 0 in it!' % variable))\n",
      "sys:1: RuntimeWarning: Traceback of forward call that caused the error:\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 378, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 714, in __init__\n",
      "    self.run()\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2880, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/mo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-0274d5090b06>\", line 2, in <module>\n",
      "    vi.train(dataloader, lrs=0.1, debug=True, epochs=50)\n",
      "  File \"../src/vi_hrg_approx.py\", line 438, in train\n",
      "    curr_loss = self.train_(epoch_counter, debug)\n",
      "  File \"../src/vi_hrg_approx.py\", line 374, in train_\n",
      "    loss = - self.elbo(idx1, idx2, data, debug)\n",
      "  File \"../src/vi_hrg_approx.py\", line 310, in elbo\n",
      "    p_raw = p_app_warn(warn_tensor(cosh_dist,'cosh_dist'), R_samples.expand(L,self.num_samples).t(), T_samples.expand(L,self.num_samples).t())\n",
      "  File \"../src/vi_hrg_approx.py\", line 298, in p_app_warn\n",
      "    temp1 = (2* warn_tensor(c, 'c')).pow(1./(2.*T))\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'PowBackward1' returned nan values in its 1th output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0274d5090b06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git/VIRGMo/src/vi_hrg_approx.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, optimizer, lrs, epochs, momentum, debug)\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                    \u001b[0mcurr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m                    \u001b[0mepoch_counter\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/VIRGMo/src/vi_hrg_approx.py\u001b[0m in \u001b[0;36mtrain_\u001b[0;34m(self, epoch_num, debug)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function 'PowBackward1' returned nan values in its 1th output."
     ]
    }
   ],
   "source": [
    "with autograd.detect_anomaly():\n",
    "    vi.train(dataloader, lrs=0.1, debug=True, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi.alpha_conc.exp(), vi.alpha_scale.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi.rs_loc, vi.rs_scale.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_r = Radius(vi.rs_loc, vi.rs_scale.exp(), torch.ones([N]).double()*R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Radius(vi.rs_loc, vi.rs_scale.exp(), torch.ones([N])*R).entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi.r_i_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi.R_conc.exp(), vi.R_scale.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hd_ = lambda d,R,T: (1.+((d-R)/(2.*T)).exp()).reciprocal()\n",
    "phd = lambda d,R,T: 0.5 + 0.5*(-(d-R)/(4*T)).tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hd_(torch.tensor(-np.inf),R,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phd(torch.tensor(5.1),R,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([0.1,10.0]).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0.,1.,.01)\n",
    "plt.plot(x, torch.sigmoid(logit(x)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit(torch.tensor(0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, n, m = 3, 4, 5\n",
    "broadcast = torch.ones([l,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(m).expand(n,m).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(n).expand(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(0.).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcosh = lambda x: (torch.clamp(x, min=1.) + (torch.clamp(x, min=1.)**2 - 1).sqrt())\n",
    "arcosh(torch.arange(0.,2., .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.clamp(x, min=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
