{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f507584e110>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from vi_hrg_approx_vMF2D import *\n",
    "from utils import c2d, hyperdist, p_hd, polar2cart, warn_tensor\n",
    "from torch import autograd\n",
    "torch.manual_seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_r(x, R, rel_var=0.1, epsilon=1e-4):\n",
    "    rs = torch.distributions.normal.Normal(x, R*rel_var).sample() \n",
    "    return torch.clamp(rs, min=0+epsilon, max=R.item()-epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_phi(x, rel_var=0.1):\n",
    "    phis = torch.distributions.normal.Normal(x, 2*np.pi*rel_var).sample()\n",
    "    return phis % (2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = lambda x: (x/(1-x)).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 10\n",
    "R = torch.tensor([5.0]).double()\n",
    "alpha = .7\n",
    "T = 0.1\n",
    "\n",
    "G = HRG(R=R, alpha=alpha, T=T)\n",
    "r, theta, A = G.generate(N)\n",
    "G.show()\n",
    "G.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_loc_init = logit(noise_r(r, R, rel_var=0.1)/R)*R/5\n",
    "r_scale_init = torch.ones([N]).double().log()\n",
    "phi_loc_init = polar2cart(1, noise_phi(theta, 0.1))\n",
    "phi_loc_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.9976,   1.2796,   0.9479,   0.5259, -10.8198,  -0.9847,  10.8198,\n",
       "          1.5026,   3.1051,   2.6276], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_loc_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.6530e+00, 3.9119e+00, 3.6035e+00, 3.1427e+00, 1.0000e-04, 1.3598e+00,\n",
       "        4.9999e+00, 4.0898e+00, 4.7855e+00, 4.6631e+00], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Radius(r_loc_init, r_scale_init.exp(), R.expand([N])).mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_conc_init = torch.tensor(10.).log()\n",
    "R_scale_init = torch.tensor(1.).log()\n",
    "alpha_conc_init = torch.tensor(.5).log()\n",
    "alpha_scale_init = torch.tensor(.5).log()\n",
    "T_init = torch.tensor([3.,10.]).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0986, 2.3026])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(EdgesDataset(A), batch_size=N**2, shuffle=True, num_workers=0)\n",
    "vi = VI_HRG(N,10, init_values={'rs_loc':r_loc_init,\n",
    "                                'rs_scale':r_scale_init,\n",
    "                              'phis_loc':phi_loc_init,\n",
    "                              'phis_scale':None, \n",
    "                              'R_conc':R_conc_init, \n",
    "                              'R_scale':R_scale_init,\n",
    "                              'alpha_conc':alpha_conc_init,\n",
    "                              'alpha_scale':alpha_scale_init,\n",
    "                              'T':T_init})\n",
    "vi.dataloader = dataloader\n",
    "vi.optimizer = torch.optim.RMSprop(vi.parameters())\n",
    "#vi.optimizer.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>> Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/utils.py:126: UserWarning: cd_clamped has 1 in it!\n",
      "  warnings.warn(str('%s has 1 in it!' % variable))\n",
      "../src/utils.py:126: UserWarning: c has 1 in it!\n",
      "  warnings.warn(str('%s has 1 in it!' % variable))\n",
      "../src/utils.py:126: UserWarning: p_raw has 1 in it!\n",
      "  warnings.warn(str('%s has 1 in it!' % variable))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(R)    >> tensor(-7.4639, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8525, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.8176, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-424.8431, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2827.5132, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-33.5444, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(30.9317, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(-64.8759, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1272.0902, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-2075.2675, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1 | LR: 0.00 | Total loss: 2075.27 | Epoch time 0.35\n",
      "-D_kl(R)    >> tensor(-9.5246, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6422, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.7304, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-416.1168, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2875.8924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-31.0127, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(26.9399, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(286.6034, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1332.8845, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-1705.8701, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2 | LR: 0.00 | Total loss: 1705.87 | Epoch time 0.33\n",
      "-D_kl(R)    >> tensor(-9.2496, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6302, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6761, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-264.1168, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-3076.2255, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-15.2133, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(9.0484, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(257.9928, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1375.1924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-1742.2568, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 3 | LR: 0.00 | Total loss: 1742.26 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-7.4120, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7412, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6457, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-231.9702, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-3164.2150, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-32.3303, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(32.7748, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(-5.9122, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1401.8055, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-2027.0250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 4 | LR: 0.00 | Total loss: 2027.03 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-8.5719, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6699, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6264, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-281.8048, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2378.4988, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-22.0447, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(14.5842, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(99.6343, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1427.1573, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-1169.2195, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 5 | LR: 0.00 | Total loss: 1169.22 | Epoch time 0.26\n",
      "-D_kl(R)    >> tensor(-8.9039, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.6781, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6033, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-256.3911, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2363.0960, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-15.1311, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(5.3307, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(293.3139, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1449.6369, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-914.9008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 6 | LR: 0.00 | Total loss: 914.90 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-7.9924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7489, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5904, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-267.9702, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2347.5927, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-19.7053, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(11.8782, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(237.9837, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1468.7544, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-944.3624, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 7 | LR: 0.00 | Total loss: 944.36 | Epoch time 0.27\n",
      "-D_kl(R)    >> tensor(-8.1457, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7658, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5751, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-288.5599, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-1943.4547, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-15.8816, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(4.6648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(189.4531, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1482.8913, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-598.7522, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 8 | LR: 0.00 | Total loss: 598.75 | Epoch time 0.26\n",
      "-D_kl(R)    >> tensor(-8.3051, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8110, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5615, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-253.4986, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2139.0523, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-22.1747, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(13.4626, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(218.7312, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1497.8156, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-712.7727, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 9 | LR: 0.00 | Total loss: 712.77 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-8.9382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8064, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5508, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-239.3928, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2526.2874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-23.7608, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(15.1154, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(369.5129, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1511.4873, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-921.9996, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 10 | LR: 0.00 | Total loss: 922.00 | Epoch time 0.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(R)    >> tensor(-9.1441, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8042, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5439, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-285.2807, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-3498.5047, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-35.0244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(34.4217, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(396.0131, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1524.2676, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-1892.9783, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 11 | LR: 0.00 | Total loss: 1892.98 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-9.4659, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7619, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5370, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-244.0986, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2433.8904, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-19.1673, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(9.6872, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(520.4244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1536.4998, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-659.6885, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 12 | LR: 0.00 | Total loss: 659.69 | Epoch time 0.26\n",
      "-D_kl(R)    >> tensor(-9.1664, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7999, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5310, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-199.8007, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-1866.6445, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-16.8861, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(5.8512, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(282.3088, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1547.9225, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-276.1247, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 13 | LR: 0.00 | Total loss: 276.12 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-9.6619, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8286, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5271, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-273.1310, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2824.8646, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-31.3805, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(26.4334, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(500.1722, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1557.6897, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-1074.4772, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 14 | LR: 0.00 | Total loss: 1074.48 | Epoch time 0.29\n",
      "-D_kl(R)    >> tensor(-10.1809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7928, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5234, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-440.5708, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2784.7948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-33.6623, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(26.0294, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(581.0054, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1567.2204, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-1114.6486, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 15 | LR: 0.00 | Total loss: 1114.65 | Epoch time 0.26\n",
      "-D_kl(R)    >> tensor(-10.0356, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7525, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5195, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-197.9641, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2608.2977, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-11.6324, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(2.4569, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(490.9923, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1576.2998, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-777.8315, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 16 | LR: 0.00 | Total loss: 777.83 | Epoch time 0.26\n",
      "-D_kl(R)    >> tensor(-8.8350, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8305, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5179, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-204.6398, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2102.1601, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-25.2669, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(15.7169, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(566.6779, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1584.6703, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-193.5638, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 17 | LR: 0.00 | Total loss: 193.56 | Epoch time 0.26\n",
      "-D_kl(R)    >> tensor(-9.5740, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8141, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-242.8820, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2469.8589, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-15.9907, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(5.2885, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(254.6629, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1592.8998, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-905.1639, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 18 | LR: 0.00 | Total loss: 905.16 | Epoch time 0.27\n",
      "-D_kl(R)    >> tensor(-9.0840, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8554, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5168, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-173.7278, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2477.9813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-33.2695, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(29.1204, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(492.9285, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1600.6363, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-591.1284, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 19 | LR: 0.00 | Total loss: 591.13 | Epoch time 0.31\n",
      "-D_kl(R)    >> tensor(-10.3259, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8090, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-237.5579, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2289.7076, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-30.0347, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(20.3176, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(373.8009, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1607.8691, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-585.3429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 20 | LR: 0.00 | Total loss: 585.34 | Epoch time 0.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(R)    >> tensor(-11.0530, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.7770, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5165, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-323.7774, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-3036.1121, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-11.6225, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(3.0471, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(656.6024, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1614.5801, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-1128.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 21 | LR: 0.00 | Total loss: 1128.01 | Epoch time 0.26\n",
      "-D_kl(R)    >> tensor(-9.6541, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8509, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5177, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-226.6882, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2561.1849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-26.1807, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(19.4733, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(545.2297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1620.6887, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-658.0637, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 22 | LR: 0.00 | Total loss: 658.06 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-9.8949, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8444, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5192, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-230.2954, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2172.1588, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-19.6809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(7.8080, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(597.8604, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1626.6387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-219.4653, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 23 | LR: 0.00 | Total loss: 219.47 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-10.0000, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8641, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5212, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-252.2489, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2531.8159, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-15.2322, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(6.2236, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(524.6487, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1632.1678, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-666.0208, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 24 | LR: 0.00 | Total loss: 666.02 | Epoch time 0.27\n",
      "-D_kl(R)    >> tensor(-9.6594, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.9049, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5236, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-228.5056, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-1861.5790, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-25.7867, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(12.3682, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(457.6383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1637.5399, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-37.7915, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 25 | LR: 0.00 | Total loss: 37.79 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-10.1791, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8904, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5261, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-281.8110, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2551.4361, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-20.9234, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(9.8142, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(665.9068, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1639.4167, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-569.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 26 | LR: 0.00 | Total loss: 569.01 | Epoch time 0.27\n",
      "-D_kl(R)    >> tensor(-9.9744, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.9170, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5293, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-261.2061, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2517.1995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-23.8410, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(15.5407, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(516.5556, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1644.5171, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-655.4326, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 27 | LR: 0.00 | Total loss: 655.43 | Epoch time 0.30\n",
      "-D_kl(R)    >> tensor(-9.9700, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.9236, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5318, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-170.5627, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2099.9575, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-25.2247, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(16.3910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(440.2556, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1649.5581, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-219.3444, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 28 | LR: 0.00 | Total loss: 219.34 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-10.4811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.9101, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5339, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-302.4210, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-1987.7788, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-31.3008, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(19.8823, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(912.3543, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1654.0849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(234.5171, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 29 | LR: 0.00 | Total loss: -234.52 | Epoch time 0.25\n",
      "-D_kl(R)    >> tensor(-11.0907, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8781, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-224.2515, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2095.0451, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-27.3766, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(14.2766, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(653.9725, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1658.1335, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-51.1766, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 30 | LR: 0.00 | Total loss: 51.18 | Epoch time 0.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(R)    >> tensor(-11.5576, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8680, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5417, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-351.4923, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2042.3238, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-31.4097, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(18.6358, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(710.7897, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1662.4406, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-64.7059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 31 | LR: 0.00 | Total loss: 64.71 | Epoch time 0.26\n",
      "-D_kl(R)    >> tensor(-11.6864, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8412, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5484, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-264.9623, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2798.6493, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-20.3287, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(10.5262, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(835.3273, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1666.4190, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-603.1227, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 32 | LR: 0.00 | Total loss: 603.12 | Epoch time 0.27\n",
      "-D_kl(R)    >> tensor(-11.0000, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8689, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5522, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-198.9005, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-1710.8901, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-25.4348, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(11.1179, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(714.0718, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1670.0870, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(429.2515, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 33 | LR: 0.00 | Total loss: -429.25 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-11.5496, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8600, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5557, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-248.9011, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-1933.0353, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-22.2880, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(8.3410, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(865.6955, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1673.7539, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(312.2219, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 34 | LR: 0.00 | Total loss: -312.22 | Epoch time 0.29\n",
      "-D_kl(R)    >> tensor(-11.5791, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8728, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5606, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-492.5284, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2094.2958, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-24.5427, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(10.2156, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(878.7600, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1677.1905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-76.5919, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 35 | LR: 0.00 | Total loss: 76.59 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-11.3370, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5712, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-261.7867, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2417.2742, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-18.8127, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(8.1558, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(960.4973, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1680.5797, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-79.8101, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 36 | LR: 0.00 | Total loss: 79.81 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-11.0143, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.9123, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5771, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-312.1027, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2502.7075, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-25.4387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(14.9313, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(567.5525, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1683.8581, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-604.7894, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 37 | LR: 0.00 | Total loss: 604.79 | Epoch time 0.29\n",
      "-D_kl(R)    >> tensor(-11.1487, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.9161, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5844, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-349.7181, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-3088.2470, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-31.0843, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(22.9492, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(1008.2658, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1687.1906, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-781.6718, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 38 | LR: 0.00 | Total loss: 781.67 | Epoch time 0.25\n",
      "-D_kl(R)    >> tensor(-10.9534, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.9091, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5940, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-173.6983, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2385.4936, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-30.5948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(23.1515, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(546.4026, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1690.2189, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-360.8488, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 39 | LR: 0.00 | Total loss: 360.85 | Epoch time 0.26\n",
      "-D_kl(R)    >> tensor(-11.5687, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.8830, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.5976, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-231.2877, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-1898.1824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-18.1500, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(5.8456, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(945.5004, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1693.1631, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(465.4610, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 40 | LR: 0.00 | Total loss: -465.46 | Epoch time 0.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D_kl(R)    >> tensor(-11.4564, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.9070, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6028, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-368.8728, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2471.0444, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-23.5225, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(11.1635, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(1078.7999, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1695.9065, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-108.9148, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 41 | LR: 0.00 | Total loss: 108.91 | Epoch time 0.26\n",
      "-D_kl(R)    >> tensor(-11.0703, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.9255, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-233.4323, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-1851.5814, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-23.8625, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(10.8541, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(759.1162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1698.6054, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(328.7138, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 42 | LR: 0.00 | Total loss: -328.71 | Epoch time 0.27\n",
      "-D_kl(R)    >> tensor(-11.4226, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.9240, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6155, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-171.7701, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2302.8091, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-26.5598, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(17.9170, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(545.0926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1701.2021, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-268.2683, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 43 | LR: 0.00 | Total loss: 268.27 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-12.0111, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.9134, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6205, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-320.0740, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2078.1559, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-24.0745, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(11.7111, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(1181.7499, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1703.8694, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(443.1023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 44 | LR: 0.00 | Total loss: -443.10 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-11.8103, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.9245, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6298, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-182.8950, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2559.1428, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-24.6207, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(17.9329, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(770.1652, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1706.3348, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-303.9691, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 45 | LR: 0.00 | Total loss: 303.97 | Epoch time 0.26\n",
      "-D_kl(R)    >> tensor(-11.9692, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.9217, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6331, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-239.8833, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-1723.0717, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-18.2386, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(3.6230, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(977.5849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1708.6469, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(676.7583, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 46 | LR: 0.00 | Total loss: -676.76 | Epoch time 0.26\n",
      "-D_kl(R)    >> tensor(-11.7283, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.9465, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6393, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-178.5143, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-1868.2927, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-21.0349, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(8.1124, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(454.7187, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1710.5036, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(73.8000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 47 | LR: 0.00 | Total loss: -73.80 | Epoch time 0.27\n",
      "-D_kl(R)    >> tensor(-12.1675, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.9517, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6444, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-271.1208, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2054.9388, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-21.4090, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(9.2555, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(644.5104, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1712.7704, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-13.0747, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 48 | LR: 0.00 | Total loss: 13.07 | Epoch time 0.28\n",
      "-D_kl(R)    >> tensor(-11.9486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.9630, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6545, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-207.0209, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2350.3850, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-22.7526, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(10.8354, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(824.5942, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1714.8910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-61.7826, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 49 | LR: 0.00 | Total loss: 61.78 | Epoch time 0.25\n",
      "-D_kl(R)    >> tensor(-11.9355, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(alpha)>> tensor(-0.9774, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "-D_kl(T)    >> tensor(-0.6571, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Prob_edges  >> tensor(-329.8305, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "Alpha_R_ri  >> tensor(-2968.2062, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha       >> tensor(-30.1480, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Alpha_R     >> tensor(21.9980, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_ri)     >> tensor(1004.6174, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "P(q_phii)   >> tensor(1717.4405, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO >>>> tensor(-616.0775, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 50 | LR: 0.00 | Total loss: 616.08 | Epoch time 0.26\n",
      ">>>>>>>>>>>> Training is finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with autograd.detect_anomaly():\n",
    "    vi.train(dataloader, lrs=0.001, debug=True, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7758, dtype=torch.float64, grad_fn=<ExpBackward>),\n",
       " tensor(0.2175, dtype=torch.float64, grad_fn=<ExpBackward>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.alpha_conc.exp(), vi.alpha_scale.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5000), tensor(0.5000))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_conc_init.exp(), alpha_scale_init.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(13.7471, dtype=torch.float64, grad_fn=<ExpBackward>),\n",
       " tensor(1.0407, dtype=torch.float64, grad_fn=<ExpBackward>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.R_conc.exp(), vi.R_scale.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.3068, dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_mean = Gamma(vi.R_conc.exp(), vi.R_scale.exp().reciprocal()).mean.detach()\n",
    "R_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([ 1.5276,  1.6144,  1.4168,  1.2248, -9.4874,  0.1723,  9.4908,  1.6314,\n",
       "          2.1350,  1.8376], dtype=torch.float64, requires_grad=True),\n",
       " tensor([1.4097, 1.4257, 1.3998, 1.2897, 2.5310, 1.4335, 2.9048, 1.3702, 1.6119,\n",
       "         1.6039], dtype=torch.float64, grad_fn=<ExpBackward>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.rs_loc, vi.rs_scale.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_r = Radius(vi.rs_loc, vi.rs_scale.exp(), R_mean.expand([N]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1755e+01, 1.1932e+01, 1.1515e+01, 1.1058e+01, 1.0844e-03, 7.7683e+00,\n",
       "        1.4306e+01, 1.1966e+01, 1.2794e+01, 1.2342e+01], dtype=torch.float64,\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_r.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.2345, 4.2333, 2.1902, 3.0441, 0.6701, 1.5034, 4.9904, 4.8781, 4.3641,\n",
       "        4.9651], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.3453, -2.1402, -2.2616, -2.3085,  3.9304, -2.5784,  4.2820, -2.0061,\n",
       "        -1.8337, -2.3398], dtype=torch.float64, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_samp = post_r.sample([50])\n",
    "post_r.log_prob(r_samp).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6607, dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_mean.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.0184,  1.0672],\n",
       "         [-0.5120,  0.8672],\n",
       "         [ 0.6600, -0.1731],\n",
       "         [-0.6690,  0.7280],\n",
       "         [-1.2407, -0.0380],\n",
       "         [ 0.5744, -0.8756],\n",
       "         [-0.2850, -0.8331],\n",
       "         [ 1.0343,  0.6322],\n",
       "         [-0.0949,  0.6394],\n",
       "         [ 0.7026,  0.7145]], dtype=torch.float64, requires_grad=True),\n",
       " tensor([0.8715, 0.5931, 0.6968, 0.8703, 0.8613, 0.5503, 0.7613, 0.6518, 0.4273,\n",
       "         0.8258], dtype=torch.float64, grad_fn=<ExpBackward>))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.phis_loc, vi.phis_scale.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_phi = VonMisesFisher(vi.phis_loc, vi.phis_scale.exp().unsqueeze(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6717, 1.7554, 1.7266, 1.6721, 1.6751, 1.7662, 1.7072, 1.7395, 1.7937,\n",
       "        1.6867], dtype=torch.float64, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_phi.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5536,  2.1042, -0.2565,  2.3140, -3.1110, -0.9902, -1.9004,  0.5487,\n",
       "         1.7181,  0.7938], dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2d(post_phi.mean.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0038, 1.3498, 5.8199, 2.9752, 3.7382, 4.9988, 4.7971, 1.3427, 1.9266,\n",
       "        0.2422], dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.6425, -1.7351, -2.0042, -1.7161, -1.6295, -1.7950, -1.6320, -1.7962,\n",
       "        -1.8283, -1.6886], dtype=torch.float64, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_samp = post_phi.sample(50)\n",
    "post_phi.log_prob(phi_samp).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.189385332046726"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(2*np.pi)*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6968, dtype=torch.float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Beta(vi.T.exp()[0], vi.T.exp()[1]).sample([50]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "total_loss = 0\n",
    "with autograd.detect_anomaly():\n",
    "    #print(torch.is_anomaly_enabled())\n",
    "    for idx1, idx2, data in dataloader:\n",
    "        loss = - vi.elbo(idx1, idx2, data, debug=True)\n",
    "        vi.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        vi.optimizer.step()\n",
    "        print('>>>>', loss)\n",
    "        total_loss += loss\n",
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hd_ = lambda d,R,T: (1.+((d-R)/(2.*T)).exp()).reciprocal()\n",
    "phd = lambda d,R,T: 0.5 + 0.5*(-(d-R)/(4*T)).tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_hd_(torch.tensor(-np.inf),R,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3775], dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phd(torch.tensor(5.1),R,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.3026,  2.3026])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0.1,10.0]).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.arange(0.,1.,.01)\n",
    "plt.plot(x, torch.sigmoid(logit(x)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-inf)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit(torch.tensor(0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, n, m = 3, 4, 5\n",
    "broadcast = torch.ones([l,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9075, 0.9075, 0.9075, 0.9075],\n",
       "        [0.7914, 0.7914, 0.7914, 0.7914],\n",
       "        [0.6325, 0.6325, 0.6325, 0.6325],\n",
       "        [0.0570, 0.0570, 0.0570, 0.0570],\n",
       "        [0.9939, 0.9939, 0.9939, 0.9939]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(m).expand(n,m).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3],\n",
       "        [0, 1, 2, 3],\n",
       "        [0, 1, 2, 3],\n",
       "        [0, 1, 2, 3],\n",
       "        [0, 1, 2, 3]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(n).expand(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(0.).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.5583, 1.8633, 2.1307, 2.3798, 2.6180, 2.8490, 3.0748,\n",
       "        3.2967, 3.5155])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcosh = lambda x: (torch.clamp(x, min=1.) + (torch.clamp(x, min=1.)**2 - 1).sqrt())\n",
    "arcosh(torch.arange(0.,2., .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(x, min=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6094379124341003"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(20.).cosh().pow(5).reciprocal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000000000.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([inf, 0., 1.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_nan = torch.tensor([np.nan, 0, 1.])\n",
    "torch.where(torch.isnan(has_nan), torch.tensor(np.inf).expand(has_nan.shape), has_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.184705528587072e+21"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e+34"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e+22*1e+12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
